{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### automl efficientdet 다운로드 및 설치","metadata":{"id":"ITh-aCvnbuVC"}},{"cell_type":"code","source":"!git clone --depth 1 https://github.com/google/automl","metadata":{"id":"WvrAFJSvbeMy","executionInfo":{"status":"ok","timestamp":1624696527940,"user_tz":-540,"elapsed":2422,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"cd9526d5-42f2-4acd-f023-478bc7e2985f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/automl/efficientdet; pip install -r requirements.txt","metadata":{"id":"_y03QuHJbe9g","executionInfo":{"status":"ok","timestamp":1624696540020,"user_tz":-540,"elapsed":12084,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"e2b315ee-fd10-4d13-99b0-386fc293a25c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y keras","metadata":{"id":"Iwp3mkT8bfGI","executionInfo":{"status":"ok","timestamp":1624696541415,"user_tz":-540,"elapsed":1411,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"6489bbd8-4d54-4a3a-e72d-cda01fd6c164","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"ura5hJVWbnra","executionInfo":{"status":"ok","timestamp":1624696541416,"user_tz":-540,"elapsed":9,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"e5fa2bbd-e598-4c16-b89a-c2353aa55048","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport tensorflow.compat.v1 as tf\n\nsys.path.append('/kaggle/working/automl/efficientdet')\n\nimport hparams_config\nfrom keras import anchors\nfrom model_inspect import ModelInspector","metadata":{"id":"uYRi19QLb8aq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JzE89QkVcJfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  PASCAL V0C 2007 데이터 세트 다운로드","metadata":{"id":"q9qy48rsbzK-"}},{"cell_type":"code","source":"!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n!tar -xvf VOCtrainval_06-Nov-2007.tar > /dev/null 2>&1","metadata":{"id":"URN9r_u_bfM1","executionInfo":{"status":"ok","timestamp":1624696602802,"user_tz":-540,"elapsed":26525,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"7ba5c36b-e979-4238-ee20-2914e59aec4f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia /kaggle/working/VOCdevkit/VOC2007/Annotations/*.xml| wc -l","metadata":{"id":"fZyP9sthdX5n","executionInfo":{"status":"ok","timestamp":1624696661618,"user_tz":-540,"elapsed":548,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"01f760d0-7091-423a-fb94-a1682b0f0a69","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 학습 데이터와 검증 데이터를 tfrecord 형태로 변환\n* create_pascal_tfrecord.py를 이용하여 XML 포맷의 Annotation을 tfrecord로 변환. \n* create_pascal_tfrecord.py 는 ImageSet 디렉토리에 위치한 train.txt를 읽어서 해당 xml과 image를 train용 tfrecord로 변환. val.txt를 읽어서 valid용 tfrecord로 변환. \n* train과 val용 각각 약 2500여개의 image/xml를 100개씩 하나의 tfrecord로 생성. ","metadata":{"id":"QrCUa5avdUAk"}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/tfrecord/train\n!mkdir -p /kaggle/working/tfrecord/val\n\n# --output_path=/kaggle/working/tfrecord/train/pascal에서 directory는 /kaggle/working/tfrecord/train/ 까지, 뒤의 pascal을 tfrecord파일의 prefix임.. \n!cd /kaggle/working/automl/efficientdet; PYTHONPATH=\"/kaggle/working/automl/efficientdet:$PYTHONPATH\" python dataset/create_pascal_tfrecord.py  \\\n    --data_dir=/kaggle/working/VOCdevkit --year=VOC2007 --set=train --output_path=/kaggle/working/tfrecord/train/pascal\n\n!cd /kaggle/working/automl/efficientdet; PYTHONPATH=\"/kaggle/working/automl/efficientdet:$PYTHONPATH\" python dataset/create_pascal_tfrecord.py  \\\n    --data_dir=/kaggle/working/VOCdevkit --year=VOC2007 --set=val --output_path=/kaggle/working/tfrecord/val/pascal\n","metadata":{"id":"fvQEkxjNb5DN","executionInfo":{"status":"ok","timestamp":1624696876486,"user_tz":-540,"elapsed":10640,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"31b7abef-ade6-42a2-9c35-094476439d32","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train용 config 설정. \n* 학습을 위한 다양한 설정을 config로 저장. model은 efficientdet-d0 로 적용. ","metadata":{"id":"f92TkqIYz_xk"}},{"cell_type":"code","source":"''' kaggle kernel은 google drive로 바로 mount 할 수 없음. \n    아래를 적용하지 않고 /kaggle/working/model_trained 로 설정. \n    \n# epochs시마다 학습된 weight파일을 저장한 디렉토리 Google drive로 설정. \n# Google Drive 접근을 위한 Mount 적용. \nimport os, sys \nfrom google.colab import drive \n\ndrive.mount('/content/gdrive')\n\n# soft link로 Google Drive Directory 연결. \n!ln -s /content/gdrive/My\\ Drive/ /mydrive\n!ls /mydrive\n!mkdir -p /mydrive/model_trained\n'''\n!mkdir /kaggle/working/model_trained","metadata":{"id":"mFRHuC7EpDns","executionInfo":{"status":"ok","timestamp":1624697481070,"user_tz":-540,"elapsed":43097,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"7f9d809f-2879-4746-a9da-27084c40115a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = hparams_config.get_detection_config('efficientdet-d0')\nprint(config)","metadata":{"id":"AjZeIaiH0UW2","executionInfo":{"status":"ok","timestamp":1624697544240,"user_tz":-540,"elapsed":410,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"83b7fc6e-5991-4c50-e53b-2fcd386ea040","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TRAIN_CFG:\n    model_name = 'efficientdet-d0' # efficientdet 모델명\n    strategy = '' # tpu, 여러개의 GPU들, 단일 GPU 일때 학습 strategy 설정. \n    model_dir = '/kaggle/working/model_trained' # 학습된 모델이 저장될 위치\n    pretrained_ckpt = '/kaggle/working/efficientdet-d0' \n    hparams = 'num_classes=20,moving_average_decay=0,mixed_precision=true'\n    use_xla = False\n    use_fake_data = False\n    batch_size = 8\n    eval_samples = 5000 # evaluation image 데이터 갯수\n    steps_per_execution = 1 # ModelCheckPoint의 save_freq 를 숫자로 설정할 경우 사용. \n    num_examples_per_epoch = 2500 # 1 epochs 시 적용하는 examples 개수 \n    num_epochs = 15 # epochs 횟수\n    train_file_pattern = '/kaggle/working/tfrecord/train/pascal-*.tfrecord' # 학습용 tfrecords를 glob 형태로 가져오는 표현식. \n    val_file_pattern = '/kaggle/working/tfrecord/val/pascal-*.tfrecord' # 검증용 tfrecords를 glob 형태로 가져오는 표현식. \n    val_json_file = None # optional coco validation json \n    mode = 'traineval' # train만 적용 또는 train과 eval함께 적용(traineval)\n\n    num_cores = 2 # tpu 8 일때 적용.  \n    tpu = None\n    gcp_project = None\n    tpu_zone = None\n    eval_master = ''\n    eval_name = None\n    tf_random_seed = 2021\n    profile = False\n    debug = False","metadata":{"id":"c5bklgGdf0Q_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.train import setup_model\nimport hparams_config\n\nimport utils\nfrom keras import tfmot\nfrom keras import train_lib\nfrom keras import util_keras\n\nconfig = hparams_config.get_detection_config(TRAIN_CFG.model_name)\nconfig.override(TRAIN_CFG.hparams)\n\nsteps_per_epoch = TRAIN_CFG.num_examples_per_epoch // TRAIN_CFG.batch_size\n\nif tf.config.list_physical_devices('GPU'):\n    ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\nelse:\n    ds_strategy = tf.distribute.OneDeviceStrategy('device:CPU:0')\n\nprint(ds_strategy)\n\n#steps_per_execution은 ModelCheckpoint의 save_freq를 숫자로 설정할 시 적용. num_epochs, steps_per_epoch는 추후에 model.fit()에서 설정되지만, 여기서는 일단 값을 설정해야함. \nparams = dict(\n      profile=TRAIN_CFG.profile,\n      mode = TRAIN_CFG.mode,\n      model_name=TRAIN_CFG.model_name,\n      steps_per_execution=TRAIN_CFG.steps_per_execution,\n      num_epochs = TRAIN_CFG.num_epochs,\n      model_dir=TRAIN_CFG.model_dir,\n      steps_per_epoch=steps_per_epoch,\n      strategy=TRAIN_CFG.strategy,\n      batch_size=TRAIN_CFG.batch_size,\n      tf_random_seed=TRAIN_CFG.tf_random_seed,\n      debug=TRAIN_CFG.debug,\n      val_json_file=TRAIN_CFG.val_json_file,\n      eval_samples=TRAIN_CFG.eval_samples,\n      num_shards=ds_strategy.num_replicas_in_sync\n      )\n\nconfig.override(params, True)\n\n# image size를 tuple 형태로 변환. 512는 (512, 512)로 '1920x880' 은 (1920, 880) 으로 변환.  \nconfig.image_size = utils.parse_image_size(config.image_size)\nprint(config)","metadata":{"id":"Z2ZVTurggZKm","executionInfo":{"status":"ok","timestamp":1624698376406,"user_tz":-540,"elapsed":13,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"56ca918d-53c7-4401-e6f3-176cd52a253f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 생성\n* Config를 기반으로 EfficientDet d0 모델을 생성\n* Coco Pretrained 파일을 다운로드 한 뒤 이 checkpoint파일의 weight를 생성한 d0 모델로 로딩","metadata":{"id":"pFlw575d0yG-"}},{"cell_type":"code","source":"import utils\nfrom keras import tfmot\nfrom keras import train_lib\nfrom keras import util_keras\n# P100 GPU Card에서는 아래 수행하지 말것. V100 GPU 시에는 mixed_float16으로 mixed_precision 설정. \n#precision = utils.get_precision(config.strategy, config.mixed_precision)\n#policy = tf.keras.mixed_precision.Policy(precision)\n#tf.keras.mixed_precision.set_global_policy(policy)","metadata":{"id":"P4Ghv3cZnRsG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL = 'efficientdet-d0' \n\ndef download(m):\n    if m not in os.listdir():\n        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n        !tar zxf {m}.tar.gz\n    ckpt_path = os.path.join(os.getcwd(), m)\n    return ckpt_path\n\n# Download checkpoint.\nckpt_path = download(MODEL)\nprint('Use model in {}'.format(ckpt_path))","metadata":{"id":"gzJmBbCu0-v5","executionInfo":{"status":"ok","timestamp":1624698521194,"user_tz":-540,"elapsed":2203,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"b3f27db0-c2b0-4712-9f6a-dd2477b29978","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import train_lib\nfrom keras import train\n\n# 20개의 class를 가진 efficientdet d0 모델을 생성. \nmodel = train_lib.EfficientDetNetTrain(config=config)\nmodel = train.setup_model(model, config)\n\n# 만약 pretrained 모델이 있으면, 해당 checkpoint weight를 모델로 로딩. 이때 classification layer는 제외. \n#class TRAIN_CFG: pretrained_ckpt = '/kaggle/working/efficientdet-d0' \nif TRAIN_CFG.pretrained_ckpt:\n    ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.pretrained_ckpt)\n    util_keras.restore_ckpt(\n      model,\n      ckpt_path,\n      config.moving_average_decay,\n      exclude_layers=['class_net'])\n\ntrain.init_experimental(config)\n\nmodel.summary()","metadata":{"id":"ee5H613CnUy2","executionInfo":{"status":"ok","timestamp":1624698614610,"user_tz":-540,"elapsed":6718,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"2dc45173-9854-46e6-ab87-500456f584ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 학습과 검증용 Dataset을 생성하고, Train 수행. \n* 학습과 검증 데이터용 dataset 생성을 위한 get_dataset() 함수 생성. ","metadata":{"id":"rMn6nBYQ1HHr"}},{"cell_type":"code","source":"'''\nClass TRAIN_CFG:\n  train_file_pattern = '/kaggle/working/tfrecord/train/pascal-*.tfrecord' # 학습용 tfrecords를 glob 형태로 가져오는 표현식. \n  val_file_pattern = '/kaggle/working/tfrecord/val/pascal-*.tfrecord' # 검증용 tfrecords를 glob 형태로 가져오는 표현식. \n'''\n\nimport dataloader\n\ndef get_dataset(is_training, config):\n    # is_training이 True이면 TRAIN_CFG의 train_file_pattern, 그렇지 아니면 val_file_pattern\n    file_pattern = (\n    TRAIN_CFG.train_file_pattern\n    if is_training else TRAIN_CFG.val_file_pattern)\n    if not file_pattern:\n        raise ValueError('No matching files.')\n\n    return dataloader.InputReader(\n    file_pattern,\n    is_training=is_training,\n    use_fake_data=TRAIN_CFG.use_fake_data,\n    max_instances_per_image=config.max_instances_per_image,\n    debug=TRAIN_CFG.debug)(\n        config.as_dict())","metadata":{"id":"daTGBW0CtowG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n#  train.txt와 val.txt를 읽어서 train과 val 용 image 건수를 구함 \ntrain_df = pd.read_csv('/kaggle/working/VOCdevkit/VOC2007/ImageSets/Main/train.txt', sep=' ', \n                       header=None, names=['file_id'], dtype={'file_id':str})\nval_df = pd.read_csv('/kaggle/working/VOCdevkit/VOC2007/ImageSets/Main/val.txt', sep=' ', \n                       header=None, names=['file_id'], dtype={'file_id':str})\n\ntrain_images_num = train_df.shape[0]\nval_images_num = val_df.shape[0]\nprint(train_images_num, val_images_num)\n\ntrain_df.head()","metadata":{"id":"pks9JJTk5qm4","executionInfo":{"status":"ok","timestamp":1624699311424,"user_tz":-540,"elapsed":19,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9a45cbc6-ed9c-4889-c19d-8b65da50ac2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import train_lib\nfrom keras import train\n\n# config에 기반하여 모델을 생성하고 pretrained weight를 로딩하는 함수 생성. \ndef get_efficientdet_model(config):\n    model = train_lib.EfficientDetNetTrain(config=config)\n    model = train.setup_model(model, config)\n\n    if TRAIN_CFG.pretrained_ckpt:\n        ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.pretrained_ckpt)\n        util_keras.restore_ckpt(model, ckpt_path, config.moving_average_decay, exclude_layers=['class_net'])\n    \n    train.init_experimental(config)\n    return model\n\nmodel = get_efficientdet_model(config)\nmodel.summary()","metadata":{"id":"hMBcEL3iVvL0","executionInfo":{"status":"ok","timestamp":1624699317065,"user_tz":-540,"elapsed":3444,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"aecfef43-3974-434a-d5e0-5d02be587e25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import train\nimport numpy as np\n\n# config에 설정된 steps_per_epoch, num_epochs는 무시하고 여기서 새로 설정. \n# steps_per_epoch는 전체 학습데이터 이미지 건수//batch_size, val_steps_per_epoch는 전체 검증 데이터 이미지 건수//batch_size\ntr_steps_per_epoch = train_images_num//config.batch_size\nval_steps_per_epoch = val_images_num//config.batch_size\nprint('tr_steps_per_epoch:', tr_steps_per_epoch, 'val_steps_per_epoch:', val_steps_per_epoch)\n\n#  config.mode가 traineval 또는 eval일 경우 검증 dataset 생성.\nval_dataset = get_dataset(False, config) if 'eval' in config.mode else None\n#callback은 config에 설정된 구성대로 생성. ModelCheckpoint는 epoch시마다, COCO Evaluation는 5회 epoch시마다 수행됨. \n#config.save_freq = eval;config.map_freq = 5\n# 1 epoch시마다 P100에서 약 3분30초 걸림. 적절한 epochs 수 설정 필요. \nmodel.fit(\n    get_dataset(True, config),\n    epochs=15,\n    steps_per_epoch=tr_steps_per_epoch ,\n    callbacks=train_lib.get_callbacks(config.as_dict(), val_dataset),\n    validation_data=val_dataset,\n    validation_steps=val_steps_per_epoch)\n\ntf.keras.backend.clear_session()","metadata":{"id":"3YeD9OD1slQF","executionInfo":{"status":"ok","timestamp":1624702558942,"user_tz":-540,"elapsed":3241291,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"fea359b8-1557-4602-a0e2-c24f1fba13ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 학습된 모델 파일을 이용하여 Inference 수행. ","metadata":{"id":"lxOF8I65bsoC"}},{"cell_type":"code","source":"import hparams_config\n\ninfer_config = hparams_config.get_efficientdet_config('efficientdet-d0')\nprint(infer_config)","metadata":{"id":"gUytyj8iB5lP","executionInfo":{"status":"ok","timestamp":1624706892934,"user_tz":-540,"elapsed":412,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"e99d7f6d-c0ad-4120-af5c-6d7eb207097e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninfer_config = hparams_config.get_efficientdet_config('efficientdet-d0')\n# config의 특정 항목을 update\ninfer_config.model_name = 'efficientdet-d0'\ninfer_config.model_dir = '/kaggle/working/model_trained'\n# infer_config의 num_classes는 20로 바뀌어야 함. \ninfer_config.num_classes =20\ninfer_config.is_training_bn = False\ninfer_config.nms_configs.score_thresh = 0.4\ninfer_config.nms_configs.max_output_size = 100","metadata":{"id":"IiBgbQE3HgpH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import inference\nfrom keras import efficientdet_keras\n\nmodel = efficientdet_keras.EfficientDetModel(config=infer_config)\nmodel.build((None, None, None, 3))\nprint('#### checkpoint name:', tf.train.latest_checkpoint(infer_config.model_dir))\nmodel.load_weights(tf.train.latest_checkpoint(infer_config.model_dir))\nmodel.summary()","metadata":{"id":"EdTAZz-mx2kk","executionInfo":{"status":"ok","timestamp":1624707002319,"user_tz":-540,"elapsed":7404,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"33f86fbb-2724-40db-f1bd-edf9b022fcfa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nclass ExportModel(tf.Module):\n\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    @tf.function\n    def f(self, imgs):\n        #model(imgs, training=False, post_mode='global')\n        return self.model(imgs, training=False, post_mode='global')\n\nexport_model = ExportModel(model)","metadata":{"id":"Li-k5zj51s-l","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/working/data\n!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg\n!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg","metadata":{"id":"7jp_ySCe1tBh","executionInfo":{"status":"ok","timestamp":1624707041229,"user_tz":-540,"elapsed":1486,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"bc22e822-8b84-4fb7-c78f-8921e4a327f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv2.cvtColor(cv2.imread('/kaggle/working/data/beatles01.jpg'), cv2.COLOR_BGR2RGB)\nimgs= img[np.newaxis, ...]\n\nstart_time = time.time()\nboxes, scores, classes, valid_len = export_model.f(imgs)\n\nprint('elapsed time:', time.time() - start_time)","metadata":{"id":"mFJUeV031wHy","executionInfo":{"status":"ok","timestamp":1624707093557,"user_tz":-540,"elapsed":557,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9adbd363-6136-45db-8903-7c96ae693a60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_names =  {1:'aeroplane', 2:'bicycle', 3:'bird', 4:'boat', 5:'bottle', 6:'bus', 7:'car',\n               8:'cat', 9:'chair', 10:'cow', 11:'diningtable', 12:'dog', 13:'horse',\n               14:'motorbike', 15:'person', 16:'pottedplant', 17:'sheep', 18:'sofa', 19:'train',\n               20:'tvmonitor'}","metadata":{"id":"KdaDV_NN1wKy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_detected_img(export_model, img_array, is_print=True):   \n    # automl efficent은 반환 bbox 좌표값이 원본 이미지 좌표값으로 되어 있으므로 별도의 scaling작업 필요 없음. \n    '''\n    height = img_array.shape[0]\n    width = img_array.shape[1]\n    '''\n    # cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n    draw_img = img_array.copy()\n\n    # bounding box의 테두리와 caption 글자색 지정\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n\n    # cv2로 만들어진 numpy image array를 tensor로 변환\n    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.uint8)[tf.newaxis, ...]\n    #img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)[tf.newaxis, ...]\n\n    # efficientdet 모델을 다운로드 한 뒤 inference 수행. \n    start_time = time.time()\n    # automl efficientdet 모델은 boxes, score, classes, num_detections를 각각 Tensor로 반환. \n    boxes, scores, classes, valid_len = export_model.f(img_tensor)\n    # Tensor값을 시각화를 위해 numpy 로 변환. \n    boxes = boxes.numpy()\n    scores = scores.numpy()\n    classes = classes.numpy()\n    valid_len = valid_len.numpy()\n  \n    # detected 된 object들을 iteration 하면서 정보 추출. detect된 object의 갯수는 100개\n    for i in range(valid_len[0]):\n        # detection score를 iteration시 마다 높은 순으로 추출하고 SCORE_THRESHOLD보다 낮으면 loop 중단. \n        score = scores[0, i]\n    \n        # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n        box = boxes[0, i]\n\n        ''' **** 주의 ******\n        box는 ymin, xmin, ymax, xmax 순서로 되어 있음. 또한 원본 좌표값으로 되어 있음. '''\n        left = box[1]\n        top = box[0] \n        right = box[3] \n        bottom = box[2] \n\n        # class id 추출하고 class 명으로 매핑\n        class_id = classes[0, i]\n        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n        print(caption)\n        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n\n    if is_print:\n        print('Detection 수행시간:',round(time.time() - start_time, 2),\"초\")\n\n    return draw_img","metadata":{"id":"TGhu-oo214y7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimg_array = cv2.cvtColor(cv2.imread('/kaggle/working/data/beatles01.jpg'), cv2.COLOR_BGR2RGB)\n\ndraw_img = get_detected_img(export_model, img_array, is_print=True)\nplt.figure(figsize=(16, 16))\nplt.imshow(draw_img)","metadata":{"id":"G6_6o7Ux19df","executionInfo":{"status":"ok","timestamp":1624707155494,"user_tz":-540,"elapsed":4009,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"0eb418d1-8608-4ed6-f1d7-9cd0ea635e4d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"O6XUy5Vg1_Ks"},"execution_count":null,"outputs":[]}]}