{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### MMDetection 설치","metadata":{"id":"2Jsz-tO0fLvW"}},{"cell_type":"code","source":"!pip install mmcv-full\n!git clone https://github.com/open-mmlab/mmdetection.git\n!cd mmdetection; python setup.py install","metadata":{"id":"pEP0cZDIM532","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 아래를 수행하기 전에 kernel을 restart 해야 함. \nfrom mmdet.apis import init_detector, inference_detector\nimport mmcv","metadata":{"id":"kNPWIavsNLiU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PASCAL VOC형태의 BCCD Dataset를 Download 후 MS-COCO 형태로 변경\n* BCCD Dataset은 백혈구(WBC), 적혈구(RBC), 혈소판(Platelets) 세가지 유형의 Object Class를 가짐.\n* 다운로드 받은 Dataset은 Pascal VOC 형태이므로 이를 별도의 유틸리티를 이용하여 MS-COCO 형태로 변환 \n","metadata":{"id":"0LdQItz6jaYM"}},{"cell_type":"code","source":"!git clone https://github.com/Shenggan/BCCD_Dataset.git","metadata":{"id":"zcrUnqa_MTUW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VOC를 COCO로 변환하는 package적용하기","metadata":{"id":"KgWW0T0LjmqH"}},{"cell_type":"code","source":"!git clone https://github.com/yukkyo/voc2coco.git","metadata":{"id":"tQVIkZibRVGB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# colab 버전은 아래 명령어로 ballnfish_classes.txt 를 수정합니다. \nwith open('/kaggle/working/BCCD_Dataset/BCCD/labels.txt', \"w\") as f:\n    f.write(\"WBC\\n\")\n    f.write(\"RBC\\n\")\n    f.write(\"Platelets\\n\")\n\n!cat /kaggle/working/BCCD_Dataset/BCCD/labels.txt","metadata":{"id":"bhSoTgSKSQ9O","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VOC를 COCO로 변환 수행. 학습/검증/테스트 용 json annotation을 생성. \n%cd voc2coco\n!python voc2coco.py --ann_dir /kaggle/working/BCCD_Dataset/BCCD/Annotations \\\n--ann_ids /kaggle/working/BCCD_Dataset/BCCD/ImageSets/Main/train.txt \\\n--labels /kaggle/working/BCCD_Dataset/BCCD/labels.txt \\\n--output /kaggle/working/BCCD_Dataset/BCCD/train.json \\\n--ext xml\n\n!python voc2coco.py --ann_dir /kaggle/working/BCCD_Dataset/BCCD/Annotations \\\n--ann_ids /kaggle/working/BCCD_Dataset/BCCD/ImageSets/Main/val.txt \\\n--labels /kaggle/working/BCCD_Dataset/BCCD/labels.txt \\\n--output /kaggle/working/BCCD_Dataset/BCCD/val.json \\\n--ext xml\n\n!python voc2coco.py --ann_dir /kaggle/working/BCCD_Dataset/BCCD/Annotations \\\n--ann_ids /kaggle/working/BCCD_Dataset/BCCD/ImageSets/Main/test.txt \\\n--labels /kaggle/working/BCCD_Dataset/BCCD/labels.txt \\\n--output /kaggle/working/BCCD_Dataset/BCCD/test.json \\\n--ext xml","metadata":{"id":"iIb3QT5VRVKZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat /kaggle/working/BCCD_Dataset/BCCD/train.json","metadata":{"id":"1UrOYjGoRVMy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# annotation json 파일을 잘 볼수 있는 jq 유틸리티 셋업. \n!sudo apt-get install jq","metadata":{"id":"_8z002CpRVQu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!jq . /kaggle/working/BCCD_Dataset/BCCD/train.json > output.json\n!tail -100 output.json","metadata":{"id":"XWnJqKB5VJvW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!jq . /kaggle/working/BCCD_Dataset/BCCD/test.json > output.json\n!cat output.json","metadata":{"id":"LT82lxGJrtup","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CocoDataset 클래스를 활용하여 BCCD Dataset을 로딩하기\n* MS-COCO Dataset의 경우 별다른 Custom Code없이 Object들의 Class만 지정해 주면 됨","metadata":{"id":"n47_Oit7LFAt"}},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"id":"NTMeyB7PLYRi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.coco import CocoDataset\n\n@DATASETS.register_module(force=True)\nclass BCCDDataset(CocoDataset):\n    CLASSES = ('WBC', 'RBC', 'Platelets') ","metadata":{"id":"H7OP1Hg0t4YF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Config 설정하고 Checkpoint 파일 다운로드 받기","metadata":{"id":"7ppXjHllMZ4Q"}},{"cell_type":"code","source":"config_file = '/kaggle/working/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\ncheckpoint_file = '/kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'","metadata":{"id":"fYM0nKMuZ2Fd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"id":"gvmYV3h9dDyd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/mmdetection; mkdir checkpoints\n!wget -O /kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth","metadata":{"id":"FMvzP0Uu0q5s","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia /kaggle/working/mmdetection/checkpoints","metadata":{"id":"79xVxc8601k1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmcv import Config\n\ncfg = Config.fromfile(config_file)\nprint(cfg.pretty_text)","metadata":{"id":"OYh8bvyPvLiL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import set_random_seed\n\n# dataset에 대한 환경 파라미터 수정. \ncfg.dataset_type = 'BCCDDataset'\ncfg.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\n\n# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \ncfg.data.train.type = 'BCCDDataset'\ncfg.data.train.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.train.ann_file = 'train.json'\ncfg.data.train.img_prefix = 'JPEGImages'\n\ncfg.data.val.type = 'BCCDDataset'\ncfg.data.val.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.val.ann_file = 'val.json'\ncfg.data.val.img_prefix = 'JPEGImages'\n\ncfg.data.test.type = 'BCCDDataset'\ncfg.data.test.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.test.ann_file = 'test.json'\ncfg.data.test.img_prefix = 'JPEGImages'\n\n# class의 갯수 수정. \ncfg.model.roi_head.bbox_head.num_classes = 3\n# pretrained 모델\ncfg.load_from = '/kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n\n# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \ncfg.work_dir = './tutorial_exps'\n\n# 학습율 변경 환경 파라미터 설정. \ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 10\n\n# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\ncfg.evaluation.metric = 'bbox'\ncfg.evaluation.interval = 12\ncfg.checkpoint_config.interval = 12\n\n# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \ncfg.lr_config.policy='step'\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)","metadata":{"id":"G_OuZ7_hvLmY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cfg.pretty_text)","metadata":{"id":"hy1arJ4mvLrC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset을 만들고, 모델 학습 및 Inference 적용","metadata":{"id":"oabUcL7vM1ao"}},{"cell_type":"code","source":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\n\n# train용 Dataset 생성. \ndatasets = [build_dataset(cfg.data.train)]","metadata":{"id":"3zmEBkHy1Um-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datasets[0])\n# datasets[0].__dict__ 로 모든 self variables의 key와 value값을 볼 수 있음. \ndatasets[0].__dict__.keys()","metadata":{"id":"2b0E31871UqF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets[0].data_infos","metadata":{"id":"3FpMfTqnsNrX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets[0].pipeline","metadata":{"id":"ShA8_UU7qpUl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\nprint(model.CLASSES)","metadata":{"id":"52a6vbgr1UuX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os.path as osp\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n# epochs는 config의 runner 파라미터로 지정됨. 기본 12회 \ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","metadata":{"id":"uGED9DOY4ZTY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\nimg = cv2.imread('/kaggle/working/BCCD_Dataset/BCCD/JPEGImages/BloodImage_00007.jpg')\n\nmodel.cfg = cfg\n\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img, result)","metadata":{"id":"PMQghxYE4ZaD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터 세트에 Inference 및 Evaluation 적용하기\n* 런타임 다시 시작 수행 필요(버그?)\n* tools/test.py 스크립트는 colab에서 오류 발생\n* 테스트용 Dataset과 DataLoader생성하고 single_gpu_test()를 호출하여 inference 결과를 반환. batch_size를 1로 설정하지 않으면 single_gpu_test() 오류 발생. ","metadata":{"id":"myzy42MNTsNL"}},{"cell_type":"code","source":"### 아래는 런타임 다시 시작 후 실행\n\nfrom mmcv import Config\nfrom mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.coco import CocoDataset\nfrom mmdet.apis import set_random_seed\n\n@DATASETS.register_module(force=True)\nclass BCCDDataset(CocoDataset):\n    CLASSES = ('WBC', 'RBC', 'Platelets') \n\nconfig_file = '/kaggle/working/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\ncheckpoint_file = '/kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n\ncfg = Config.fromfile(config_file)\n\n# dataset에 대한 환경 파라미터 수정. \ncfg.dataset_type = 'BCCDDataset'\ncfg.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\n\n# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \ncfg.data.train.type = 'BCCDDataset'\ncfg.data.train.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.train.ann_file = 'train.json'\ncfg.data.train.img_prefix = 'JPEGImages'\n\ncfg.data.val.type = 'BCCDDataset'\ncfg.data.val.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.val.ann_file = 'val.json'\ncfg.data.val.img_prefix = 'JPEGImages'\n\ncfg.data.test.type = 'BCCDDataset'\ncfg.data.test.data_root = '/kaggle/working/BCCD_Dataset/BCCD/'\ncfg.data.test.ann_file = 'test.json'\ncfg.data.test.img_prefix = 'JPEGImages'\n\n# class의 갯수 수정. \ncfg.model.roi_head.bbox_head.num_classes = 3\n# pretrained 모델\ncfg.load_from = '/kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n\n# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \ncfg.work_dir = './tutorial_exps'\n\n# 학습율 변경 환경 파라미터 설정. \ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 10\n\n# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\ncfg.evaluation.metric = 'bbox'\ncfg.evaluation.interval = 12\ncfg.checkpoint_config.interval = 12\n\n# bug(?)로 인해 test용 dataset evaluation 시 1로 설정. data loader에서 GPU갯수별 Batch size 임. \ncfg.data.samples_per_gpu = 1\n\n# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \ncfg.lr_config.policy='step'\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\nprint(cfg.pretty_text)","metadata":{"id":"RhxcmUjXWOYV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dump('/kaggle/working/tutorial_exps/bccd_faster_rcnn_conf.py')","metadata":{"id":"yrTb-eF_d5v_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/working/show_test_output","metadata":{"id":"7QwfJoZ1kG1i","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tools/test.py 는 colab에서 제대로 동작하지 않음. \n%cd /kaggle/working/mmdetection\n!python tools/test.py /kaggle/working/tutorial_exps/bccd_faster_rcnn_conf.py /kaggle/working/tutorial_exps/epoch_12.pth \\\n--eval 'bbox' \\\n--show-dir /kaggle/working/show_test_output","metadata":{"id":"ee5-nx0xjMx6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트용 dataset와 dataloader를 별도로 설정하고 trained된 checkpoint 모델을 로딩하여 test 수행. ","metadata":{"id":"_Hvk9Ut5ji1e"}},{"cell_type":"code","source":"from mmdet.datasets import (build_dataloader, build_dataset,\n                            replace_ImageToTensor)\n\n# test용 Dataset과 DataLoader 생성. \n# build_dataset()호출 시 list로 감싸지 않는 것이 train용 dataset 생성시와 차이. \ndataset = build_dataset(cfg.data.test)\ndata_loader = build_dataloader(\n        dataset,\n        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n        samples_per_gpu=cfg.data.samples_per_gpu,\n        workers_per_gpu=cfg.data.workers_per_gpu,\n        dist=False,\n        shuffle=False)\n\n# 반드시 아래 코드에서 'img' 키값이 tensor로 출력되어야 함. \nnext(iter(data_loader))","metadata":{"id":"TDcbOV6mRlkf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\ncheckpoint_file = '/kaggle/working/tutorial_exps/epoch_12.pth'\n\n# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \nmodel_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')","metadata":{"id":"Y2sJiFuzV9Fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import multi_gpu_test, single_gpu_test\nfrom mmcv.parallel import MMDataParallel, MMDistributedDataParallel\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\nmodel_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. \n# 위에서 만든 /kaggle/working/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨. \noutputs = single_gpu_test(model_ckpt, data_loader, True, '/kaggle/working/show_test_output', 0.3)","metadata":{"id":"h7QFHuCsRln0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### batch 크기를 1보다 키우고 테스트 수행 하려면 \n* 만일 batch size를 1보다 크게 해서 설정하려면 cfg.data.samples_per_gpu 값을 1보다 크게 설정하고 single_gpu_test() 함수의 bug(?) 코드를 수정 필요. \n* 다시 런타임 다시 시작을 실행 후 config 부터 재 설정후 아래 코드 수행 필요. 여기서는 수행하지 않는 걸로 스킵","metadata":{"id":"JfrnSOoOkq1W"}},{"cell_type":"code","source":"'''\nimport os.path as osp\nimport pickle\nimport shutil\nimport tempfile\nimport time\n\nimport mmcv\nimport torch\nimport torch.distributed as dist\nfrom mmcv.image import tensor2imgs\nfrom mmcv.runner import get_dist_info\n\ndef single_gpu_test_batch(model,\n                    data_loader,\n                    show=False,\n                    out_dir=None,\n                    show_score_thr=0.3):\n    model.eval()\n    results = []\n    dataset = data_loader.dataset\n    prog_bar = mmcv.ProgressBar(len(dataset))\n    for i, data in enumerate(data_loader):\n        with torch.no_grad():\n            result = model(return_loss=False, rescale=True, **data)\n\n        batch_size = len(result)\n        if show or out_dir:\n            if batch_size == 1 and isinstance(data['img'][0], torch.Tensor):\n                img_tensor = data['img'][0]\n            else:\n                # 아래 코드를 주석 처리 필요. batch_size가 1보다 클때는 data['img'][0].data[0]가 아니라 data['img'][0].data 가 되어야 함. \n                #img_tensor = data['img'][0].data[0]\n                # 아래는 버그(?) 수정 코드 \n                img_tensor = data['img'][0].data\n                print('img_tensor shape2:', img_tensor.shape)\n            img_metas = data['img_metas'][0].data[0]\n            imgs = tensor2imgs(img_tensor, **img_metas[0]['img_norm_cfg'])\n            assert len(imgs) == len(img_metas)\n\n            for i, (img, img_meta) in enumerate(zip(imgs, img_metas)):\n                h, w, _ = img_meta['img_shape']\n                img_show = img[:h, :w, :]\n\n                ori_h, ori_w = img_meta['ori_shape'][:-1]\n                img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n\n                if out_dir:\n                    out_file = osp.join(out_dir, img_meta['ori_filename'])\n                else:\n                    out_file = None\n\n                model.module.show_result(\n                    img_show,\n                    result[i],\n                    show=show,\n                    out_file=out_file,\n                    score_thr=show_score_thr)\n\n        # encode mask results\n        if isinstance(result[0], tuple):\n            result = [(bbox_results, encode_mask_results(mask_results))\n                      for bbox_results, mask_results in result]\n        results.extend(result)\n\n        for _ in range(batch_size):\n            prog_bar.update()\n    return results\n\nfrom mmdet.apis import multi_gpu_test, single_gpu_test\nfrom mmcv.parallel import MMDataParallel, MMDistributedDataParallel\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\nmodel_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. \noutputs = single_gpu_test(model_ckpt, data_loader, True, '/kaggle/working/tutorial_exps', 0.3)\n'''\n","metadata":{"id":"2ImKrfVdaK0Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 반환된 test용 데이터세트의 inference 적용 결과 확인 및 성능 evaluation 수행. ","metadata":{"id":"Oi7gIuYimGkK"}},{"cell_type":"code","source":"print('결과 outputs type:', type(outputs))\nprint('evalution 된 파일의 갯수:', len(outputs))\nprint('첫번째 evalutation 결과의 type:', type(outputs[0]))\nprint('첫번째 evaluation 결과의 CLASS 갯수:', len(outputs[0]))\nprint('첫번째 evaluation 결과의 CLASS ID 0의 type과 shape', type(outputs[0][0]), outputs[0][0].shape)","metadata":{"id":"6YgUFo2c6pWr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(outputs)","metadata":{"id":"_4qQEOw1hQh4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = dataset.evaluate(outputs, metric='bbox')\nprint(metric)","metadata":{"id":"XMH57XL37DWp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"RkLffJvFwHEL"},"execution_count":null,"outputs":[]}]}