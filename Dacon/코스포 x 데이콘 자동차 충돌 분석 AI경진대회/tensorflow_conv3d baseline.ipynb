{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01028d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WBH\\anaconda3\\envs\\pytorchstudy\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 import\n",
    "#python == 3.7.0\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf # tensorflow == 2.6.0\n",
    "from tensorflow.keras import optimizers, layers, models\n",
    "from tensorflow_addons.metrics import F1Score # tfa == 0.15.0, F1score를 위한 별도 설치 라이브러리, 선택 사항 (필수 x)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46962fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'VIDEO_LENGTH':50, # 10프레임 * 5초\n",
    "    'IMG_SIZE':128,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':4,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc752b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_from_video_file(video_path): # video를 읽어서 50fps에 해당하는 사진으로 반환\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for _ in range(CFG['VIDEO_LENGTH']):\n",
    "        _, img = cap.read()\n",
    "        img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "        img = img / 255.\n",
    "        frames.append(img)\n",
    "\n",
    "    result = np.array(frames)[..., [2,1,0]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class FrameGenerator: # 모든 video를 ram에 적재할 수 없기 때문에 batch 마다 generate 해주기 위한 generator 생성\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __call__(self):\n",
    "        for tp in self.dataframe.itertuples():\n",
    "            video_frames = frames_from_video_file(tp.video_path)\n",
    "            label = tp.label # Encode labels\n",
    "            label = to_categorical(label, 13)\n",
    "\n",
    "            yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaaab892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, stratify=df['label'], random_state=CFG['SEED'])\n",
    "\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(train.label), y=train.label)\n",
    "# unbalance 한 데이터이기 때문에 class weight 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd4a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_gif(images): # 변환된 이미지 gif로 저장해서 확인\n",
    "#     import imageio\n",
    "\n",
    "#     converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "#     imageio.mimsave('./animation.gif', converted_images, fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509d986d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set of frames: (4, 50, 128, 128, 3)\n",
      "Shape of training labels: (4, 13)\n",
      "Shape of validation set of frames: (4, 50, 128, 128, 3)\n",
      "Shape of validation labels: (4, 13)\n"
     ]
    }
   ],
   "source": [
    "# model에 주입하기 위한 dataset 객체 생성\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(13), dtype=tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(train),\n",
    "                                          output_signature=output_signature)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(val),\n",
    "                                          output_signature=output_signature)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "train_ds = train_ds.batch(CFG['BATCH_SIZE'])\n",
    "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.batch(CFG['BATCH_SIZE'])\n",
    "\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21331f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 50, 126, 126, 32)  896       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 126, 126, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 50, 63, 63, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 50, 62, 62, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 62, 62, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 50, 31, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 50, 30, 30, 128)   32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 50, 30, 30, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 50, 15, 15, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 50, 14, 14, 256)   131328    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 50, 14, 14, 256)   1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 50, 7, 7, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 50, 6, 6, 512)     524800    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 50, 6, 6, 512)     2048      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 50, 3, 3, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 50, 2, 2, 1024)    2098176   \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 50, 2, 2, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                13325     \n",
      "=================================================================\n",
      "Total params: 2,817,741\n",
      "Trainable params: 2,813,709\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv3D(32, (1, 3, 3), activation='relu', input_shape=(50, 128, 128, 3)))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.MaxPooling3D((1, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(64, (1, 2, 2), activation='relu'))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.MaxPooling3D((1, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(128, (1, 2, 2), activation='relu'))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.MaxPooling3D((1, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(256, (1, 2, 2), activation='relu'))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.MaxPooling3D((1, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(512, (1, 2, 2), activation='relu'))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.MaxPooling3D((1, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(1024, (1, 2, 2), activation='relu'))\n",
    "model.add(layers.TimeDistributed(layers.BatchNormalization()))\n",
    "model.add(layers.GlobalAveragePooling3D())\n",
    "\n",
    "model.add(layers.Dense(13, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(CFG['LEARNING_RATE']),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',\n",
    "                       F1Score(num_classes=13, average='macro') # 선택 사항, tensorflow-addons 가 없다면 'accuracy'만 적용\n",
    "                       ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c089f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "540/540 [==============================] - 324s 592ms/step - loss: 3.0808 - accuracy: 0.0987 - f1_score: 0.0615 - val_loss: 6.4994 - val_accuracy: 0.0296 - val_f1_score: 0.0227\n",
      "Epoch 2/50\n",
      "540/540 [==============================] - 67s 123ms/step - loss: 1.6719 - accuracy: 0.1951 - f1_score: 0.1448 - val_loss: 4.0721 - val_accuracy: 0.1778 - val_f1_score: 0.1061\n",
      "Epoch 3/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 1.0388 - accuracy: 0.3221 - f1_score: 0.2280 - val_loss: 3.3856 - val_accuracy: 0.1500 - val_f1_score: 0.1124\n",
      "Epoch 4/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.6533 - accuracy: 0.4690 - f1_score: 0.3415 - val_loss: 2.4264 - val_accuracy: 0.3722 - val_f1_score: 0.1616\n",
      "Epoch 5/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.4712 - accuracy: 0.5811 - f1_score: 0.4417 - val_loss: 2.2698 - val_accuracy: 0.4111 - val_f1_score: 0.1535\n",
      "Epoch 6/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.3469 - accuracy: 0.6724 - f1_score: 0.5521 - val_loss: 1.9364 - val_accuracy: 0.5111 - val_f1_score: 0.1976\n",
      "Epoch 7/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.2555 - accuracy: 0.7437 - f1_score: 0.6330 - val_loss: 1.8227 - val_accuracy: 0.5444 - val_f1_score: 0.2132\n",
      "Epoch 8/50\n",
      "540/540 [==============================] - 67s 125ms/step - loss: 0.1850 - accuracy: 0.8114 - f1_score: 0.7234 - val_loss: 1.6562 - val_accuracy: 0.5981 - val_f1_score: 0.2266\n",
      "Epoch 9/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.1254 - accuracy: 0.8698 - f1_score: 0.8291 - val_loss: 1.5107 - val_accuracy: 0.6611 - val_f1_score: 0.2656\n",
      "Epoch 10/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.0834 - accuracy: 0.9166 - f1_score: 0.9077 - val_loss: 1.3137 - val_accuracy: 0.7204 - val_f1_score: 0.2780\n",
      "Epoch 11/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.0674 - accuracy: 0.9398 - f1_score: 0.9423 - val_loss: 1.4694 - val_accuracy: 0.7019 - val_f1_score: 0.2684\n",
      "Epoch 12/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 1.8011 - accuracy: 0.5741 - f1_score: 0.3048 - val_loss: 9.5379 - val_accuracy: 0.1444 - val_f1_score: 0.0764\n",
      "Epoch 13/50\n",
      "540/540 [==============================] - 67s 125ms/step - loss: 1.5912 - accuracy: 0.4421 - f1_score: 0.2342 - val_loss: 1.9188 - val_accuracy: 0.5926 - val_f1_score: 0.1923\n",
      "Epoch 14/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.6238 - accuracy: 0.6279 - f1_score: 0.4138 - val_loss: 2.0422 - val_accuracy: 0.5000 - val_f1_score: 0.2083\n",
      "Epoch 15/50\n",
      "540/540 [==============================] - 67s 124ms/step - loss: 0.2820 - accuracy: 0.7715 - f1_score: 0.6171 - val_loss: 1.6165 - val_accuracy: 0.6185 - val_f1_score: 0.2291\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True)\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[es],\n",
    "                    class_weight={i:weights[i] for i in range(len(weights))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de00b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred and save done.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./test.csv')\n",
    "test_df['label'] = 0\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(test_df),\n",
    "                                          output_signature=output_signature)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.batch(CFG['BATCH_SIZE'])\n",
    "\n",
    "pred = model.predict(test_ds)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = pred\n",
    "submit.to_csv('./submission.csv', index=False)\n",
    "print('pred and save done.')\n",
    "\n",
    "# 참고한 사이트\n",
    "# https://www.tensorflow.org/tutorials/video/video_classification\n",
    "# https://www.tensorflow.org/tutorials/load_data/video?hl=ko\n",
    "# https://bestkcs1234.tistory.com/61  # tensorflow-addons 설치 방법"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
