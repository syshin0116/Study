{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5471bf37-978d-4b72-931e-bc5bab4b9225",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (1.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: decord in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from decord) (1.24.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (1.13.1+cu117)\n",
      "Requirement already satisfied: torchvision in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.14.1+cu117)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (1.24.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.4.2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (0.6.0.post0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (0.11.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (1.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (4.4.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (2023.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorch-lightning) (22.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: pytorchvideo in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: av in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorchvideo) (10.0.0)\n",
      "Requirement already satisfied: parameterized in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorchvideo) (0.8.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorchvideo) (3.0)\n",
      "Requirement already satisfied: fvcore in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorchvideo) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pytorchvideo) (0.1.10)\n",
      "Requirement already satisfied: tabulate in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (1.24.2)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (2.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (4.64.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (9.4.0)\n",
      "Requirement already satisfied: yacs>=0.1.6 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from fvcore->pytorchvideo) (0.1.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from iopath->pytorchvideo) (4.4.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from iopath->pytorchvideo) (2.7.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from portalocker->iopath->pytorchvideo) (305.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from tqdm->fvcore->pytorchvideo) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: scikit-multilearn in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (9.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (4.64.1)\n",
      "Requirement already satisfied: timm==0.6.12 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (0.6.12)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (0.14.1+cu117)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu117)\n",
      "Requirement already satisfied: munch in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from timm==0.6.12->segmentation-models-pytorch) (0.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from tqdm->segmentation-models-pytorch) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (22.0)\n",
      "Requirement already satisfied: six in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: einops in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install decord\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "!pip install pytorch-lightning\n",
    "!pip install pytorchvideo\n",
    "!pip install scikit-learn\n",
    "!pip install scikit-multilearn\n",
    "!pip install segmentation-models-pytorch\n",
    "!pip install transformers\n",
    "!pip install einops\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cac5a52-9eb9-4bb7-aa62-b7c419273eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/XuezheMax/apollo/blob/master/optim/apollo.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class Apollo(Optimizer):\n",
    "    r\"\"\"Implements Atom algorithm.\n",
    "        Arguments:\n",
    "            params (iterable): iterable of parameters to optimize or dicts defining\n",
    "                parameter groups\n",
    "            lr (float): learning rate\n",
    "            beta (float, optional): coefficient used for computing running averages of gradient (default: 0.9)\n",
    "            eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-4)\n",
    "            rebound (str, optional): recified bound for diagonal hessian:\n",
    "                ``'constant'`` | ``'belief'`` (default: None)\n",
    "            warmup (int, optional): number of warmup steps (default: 500)\n",
    "            init_lr (float, optional): initial learning rate for warmup (default: lr/1000)\n",
    "            weight_decay (float, optional): weight decay coefficient (default: 0)\n",
    "            weight_decay_type (str, optional): type of weight decay:\n",
    "                ``'L2'`` | ``'decoupled'`` | ``'stable'`` (default: 'L2')\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr, beta=0.9, eps=1e-4, rebound='constant', warmup=500, init_lr=None, weight_decay=0, weight_decay_type=None):\n",
    "        if not 0.0 < lr:\n",
    "            raise ValueError(\"Invalid learning rate value: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= beta < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(beta))\n",
    "        if rebound not in ['constant', 'belief']:\n",
    "            raise ValueError(\"Invalid recitifed bound: {}\".format(rebound))\n",
    "        if not 0.0 <= warmup:\n",
    "            raise ValueError(\"Invalid warmup updates: {}\".format(warmup))\n",
    "        if init_lr is None:\n",
    "            init_lr = lr / 1000\n",
    "        if not 0.0 <= init_lr <= lr:\n",
    "            raise ValueError(\"Invalid initial learning rate: {}\".format(init_lr))\n",
    "        if not 0.0 <= weight_decay:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if weight_decay_type is None:\n",
    "            weight_decay_type = 'L2' if rebound == 'constant' else 'decoupled'\n",
    "        if weight_decay_type not in ['L2', 'decoupled', 'stable']:\n",
    "            raise ValueError(\"Invalid weight decay type: {}\".format(weight_decay_type))\n",
    "\n",
    "        defaults = dict(lr=lr, beta=beta, eps=eps, rebound=rebound,\n",
    "                        warmup=warmup, init_lr=init_lr, base_lr=lr,\n",
    "                        weight_decay=weight_decay, weight_decay_type=weight_decay_type)\n",
    "        super(Apollo, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Apollo, self).__setstate__(state)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg_grad'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['approx_hessian'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                    # Previous update direction\n",
    "                    state['update'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "\n",
    "                # Calculate current lr\n",
    "                if state['step'] < group['warmup']:\n",
    "                    curr_lr = (group['base_lr'] - group['init_lr']) * state['step'] / group['warmup'] + group['init_lr']\n",
    "                else:\n",
    "                    curr_lr = group['lr']\n",
    "\n",
    "                # Perform optimization step\n",
    "                grad = p.grad\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Atom does not support sparse gradients.')\n",
    "\n",
    "                # Perform step weight decay\n",
    "                if group['weight_decay'] != 0 and group['weight_decay_type'] == 'L2':\n",
    "                    grad = grad.add(p, alpha=group['weight_decay'])\n",
    "\n",
    "                beta = group['beta']\n",
    "                eps = group['eps']\n",
    "                exp_avg_grad = state['exp_avg_grad']\n",
    "                B = state['approx_hessian']\n",
    "                d_p = state['update']\n",
    "\n",
    "                state['step'] += 1\n",
    "                bias_correction = 1 - beta ** state['step']\n",
    "                alpha = (1 - beta) / bias_correction\n",
    "\n",
    "                # calc the diff grad\n",
    "                delta_grad = grad - exp_avg_grad\n",
    "                if group['rebound'] == 'belief':\n",
    "                    rebound = delta_grad.norm(p=np.inf)\n",
    "                else:\n",
    "                    rebound = 0.01\n",
    "                    eps = eps / rebound\n",
    "\n",
    "                # Update the running average grad\n",
    "                exp_avg_grad.add_(delta_grad, alpha=alpha)\n",
    "\n",
    "                denom = d_p.norm(p=4).add(eps)\n",
    "                d_p.div_(denom)\n",
    "                v_sq = d_p.mul(d_p)\n",
    "                delta = delta_grad.div_(denom).mul_(d_p).sum().mul(-alpha) - B.mul(v_sq).sum()\n",
    "\n",
    "                # Update B\n",
    "                B.addcmul_(v_sq, delta)\n",
    "\n",
    "                # calc direction of parameter updates\n",
    "                if group['rebound'] == 'belief':\n",
    "                    denom = torch.max(B.abs(), rebound).add_(eps / alpha)\n",
    "                else:\n",
    "                    denom = B.abs().clamp_(min=rebound)\n",
    "\n",
    "                d_p.copy_(exp_avg_grad.div(denom))\n",
    "\n",
    "                # Perform step weight decay\n",
    "                if group['weight_decay'] != 0 and group['weight_decay_type'] != 'L2':\n",
    "                    if group['weight_decay_type'] == 'stable':\n",
    "                        weight_decay = group['weight_decay'] / denom.mean().item()\n",
    "                    else:\n",
    "                        weight_decay = group['weight_decay']\n",
    "                    d_p.add_(p, alpha=weight_decay)\n",
    "\n",
    "                p.add_(d_p, alpha=-curr_lr)\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8e4a2b-70dd-4bcc-9eca-6af9b217e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/issamemari/pytorch-multilabel-balanced-sampler/blob/master/sampler.py\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class MultilabelBalancedRandomSampler(Sampler):\n",
    "    \"\"\"\n",
    "    MultilabelBalancedRandomSampler: Given a multilabel dataset of length n_samples and\n",
    "    number of classes n_classes, samples from the data with equal probability per class\n",
    "    effectively oversampling minority classes and undersampling majority classes at the\n",
    "    same time. Note that using this sampler does not guarantee that the distribution of\n",
    "    classes in the output samples will be uniform, since the dataset is multilabel and\n",
    "    sampling is based on a single class. This does however guarantee that all classes\n",
    "    will have at least batch_size / n_classes samples as batch_size approaches infinity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, indices=None, class_choice=\"least_sampled\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            labels: a multi-hot encoding numpy array of shape (n_samples, n_classes)\n",
    "            indices: an arbitrary-length 1-dimensional numpy array representing a list\n",
    "            of indices to sample only from\n",
    "            class_choice: a string indicating how class will be selected for every\n",
    "            sample:\n",
    "                \"least_sampled\": class with the least number of sampled labels so far\n",
    "                \"random\": class is chosen uniformly at random\n",
    "                \"cycle\": the sampler cycles through the classes sequentially\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        if self.indices is None:\n",
    "            self.indices = range(len(labels))\n",
    "\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "\n",
    "        # List of lists of example indices per class\n",
    "        self.class_indices = []\n",
    "        for class_ in range(self.num_classes):\n",
    "            lst = np.where(self.labels[:, class_] == 1)[0]\n",
    "            lst = lst[np.isin(lst, self.indices)]\n",
    "            self.class_indices.append(lst)\n",
    "\n",
    "        self.counts = [0] * self.num_classes\n",
    "\n",
    "        assert class_choice in [\"least_sampled\", \"random\", \"cycle\"]\n",
    "        self.class_choice = class_choice\n",
    "        self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.count >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        self.count += 1\n",
    "        return self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        class_ = self.get_class()\n",
    "        class_indices = self.class_indices[class_]\n",
    "        chosen_index = np.random.choice(class_indices)\n",
    "        if self.class_choice == \"least_sampled\":\n",
    "            for class_, indicator in enumerate(self.labels[chosen_index]):\n",
    "                if indicator == 1:\n",
    "                    self.counts[class_] += 1\n",
    "        return chosen_index\n",
    "\n",
    "    def get_class(self):\n",
    "        if self.class_choice == \"random\":\n",
    "            class_ = random.randint(0, self.labels.shape[1] - 1)\n",
    "        elif self.class_choice == \"cycle\":\n",
    "            class_ = self.current_class\n",
    "            self.current_class = (self.current_class + 1) % self.labels.shape[1]\n",
    "        elif self.class_choice == \"least_sampled\":\n",
    "            min_count = self.counts[0]\n",
    "            min_classes = [0]\n",
    "            for class_ in range(1, self.num_classes):\n",
    "                if self.counts[class_] < min_count:\n",
    "                    min_count = self.counts[class_]\n",
    "                    min_classes = [class_]\n",
    "                if self.counts[class_] == min_count:\n",
    "                    min_classes.append(class_)\n",
    "            class_ = np.random.choice(min_classes)\n",
    "        return class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf9651e-e42f-4b43-a52c-54d8b6fb58bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from einops import rearrange\n",
    "from decord import VideoReader\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from segmentation_models_pytorch.losses import FocalLoss\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoConfig\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorchvideo.transforms.transforms_factory import create_video_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2f4247e-f74d-4323-8005-242038d992a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\":2023,\n",
    "    \"model_name\":\"facebook/timesformer-base-finetuned-k400\",\n",
    "    \"batch_size\":3,\n",
    "    \"learning_rate\":1e-5,\n",
    "    \"data_dir\":'./data',\n",
    "    \"checkpoint_dir\":'./checkpoint',\n",
    "    \"submission_dir\":'./submission',\n",
    "    \"n_classes\":(2,3,4,3),\n",
    "    \"label_dict\":{\n",
    "        -1:[-1,-1,-1,-1],\n",
    "        0:[0,0,0,0],\n",
    "        1:[1,1,1,1],\n",
    "        2:[1,1,1,2],\n",
    "        3:[1,1,2,1],\n",
    "        4:[1,1,2,2],\n",
    "        5:[1,1,3,1],\n",
    "        6:[1,1,3,2],\n",
    "        7:[1,2,1,1],\n",
    "        8:[1,2,1,2],\n",
    "        9:[1,2,2,1],\n",
    "        10:[1,2,2,2],\n",
    "        11:[1,2,3,1],\n",
    "        12:[1,2,3,2]\n",
    "    },\n",
    "    \"label_reverse_dict\":{\n",
    "        (0,0,0,0):0,\n",
    "        (1,1,1,1):1,\n",
    "        (1,1,1,2):2,\n",
    "        (1,1,2,1):3,\n",
    "        (1,1,2,2):4,\n",
    "        (1,1,3,1):5,\n",
    "        (1,1,3,2):6,\n",
    "        (1,2,1,1):7,\n",
    "        (1,2,1,2):8,\n",
    "        (1,2,2,1):9,\n",
    "        (1,2,2,2):10,\n",
    "        (1,2,3,1):11,\n",
    "        (1,2,3,2):12,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7430352-4e4d-414b-a180-ec554b3c9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a1692b-89ab-4739-a668-a191d43d85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{config['data_dir']}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{config['data_dir']}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04928136-a408-4278-acbb-6284073c853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sample_id'] = train_df['sample_id'].apply(lambda x: int(x.split('_')[1]))\n",
    "test_df['sample_id'] = test_df['sample_id'].apply(lambda x: int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a728f070-8d8f-4961-9258-bb482aea315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['video_path'] = train_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])\n",
    "test_df['video_path'] = test_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0403f478-2bb1-4ab6-8589-86d1ffc8e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label']=-1\n",
    "test_df['label_split'] = test_df['label'].apply(config['label_dict'].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba29cd0-c1da-43ab-a68c-b09688c70576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_split'] = train_df['label'].apply(config['label_dict'].get)\n",
    "train_label_split = np.array(train_df['label_split'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eac6350-eef7-4f10-b9e1-65ed21fd00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_multi_hot = np.hstack([np.eye(n_class, dtype=np.int32)[train_label_split[:,idx]] for idx, n_class in enumerate(config['n_classes'])])\n",
    "train_df['label_multi_hot'] = train_label_multi_hot.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be86239-8eb6-4a4d-9b7c-08e5ae197ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_for_dataset, _ , val_df_for_dataset, _  = iterative_train_test_split(X=train_df.values, y=train_label_multi_hot, test_size=0.2)\n",
    "test_df_for_dataset = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b69d041-f0d9-4ba9-94df-e70aedb58319",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multi_hot_for_sampler = np.array(train_df_for_dataset[:,4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f4029b-f6e6-4b17-82c3-fb898fcec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df_for_dataset, transform=None):\n",
    "        self.sample_id = df_for_dataset[:,0]\n",
    "        self.video_path = df_for_dataset[:,1]\n",
    "        self.label = df_for_dataset[:,2]\n",
    "        self.label_split = np.array(df_for_dataset[:,3].tolist())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.sample_id[idx]\n",
    "        video_path = self.video_path[idx]\n",
    "        vr = VideoReader(video_path)\n",
    "        video = torch.from_numpy(vr.get_batch(range(50)).asnumpy())\n",
    "        video = rearrange(video, 't h w c -> c t h w')\n",
    "        label = self.label[idx]\n",
    "        label_split = self.label_split[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        video = rearrange(video, 'c t h w -> t c h w')\n",
    "\n",
    "        sample = {\n",
    "            'sample_id':sample_id,\n",
    "            'video':video,\n",
    "            'label':label,\n",
    "            'label_split':label_split\n",
    "        }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d84d5626-6b8b-4ea9-81a8-3320337d93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AutoConfig.from_pretrained(config['model_name'])\n",
    "image_processor_config = AutoImageProcessor.from_pretrained(config['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7612a650-4c4d-4f1a-a7f7-11c22ff6b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = create_video_transform(\n",
    "    mode='train',\n",
    "    num_samples=model_config.num_frames,\n",
    "    video_mean = tuple(image_processor_config.image_mean),\n",
    "    video_std = tuple(image_processor_config.image_std),\n",
    "    crop_size = tuple(image_processor_config.crop_size.values())\n",
    ")\n",
    "\n",
    "val_transform = create_video_transform(\n",
    "    mode='val',\n",
    "    num_samples=model_config.num_frames,\n",
    "    video_mean = tuple(image_processor_config.image_mean),\n",
    "    video_std = tuple(image_processor_config.image_std),\n",
    "    crop_size = tuple(image_processor_config.crop_size.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d1b230d-4ca8-43ce-b7ea-0003c8352f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(train_df_for_dataset, transform=train_transform)\n",
    "val_dataset = VideoDataset(val_df_for_dataset, transform=val_transform)\n",
    "test_dataset = VideoDataset(test_df_for_dataset, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b25026-b607-4f60-a500-49d1ee93fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = MultilabelBalancedRandomSampler(train_multi_hot_for_sampler)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size= config['batch_size'], sampler=train_sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = config['batch_size']*2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = config['batch_size']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69747543-ce8b-4f0c-aa58-de46c616490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLVideoModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.model = AutoModel.from_pretrained(config['model_name'])\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.LazyLinear(n_class) for n_class in config['n_classes']\n",
    "        ])\n",
    "        self.loss = FocalLoss('multiclass')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x).last_hidden_state.mean(dim=1)\n",
    "        x_out = [classifier(x) for classifier in self.classifiers]\n",
    "        return x_out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        loss = sum([self.loss(y_hats[i], batch[\"label_split\"][:,i]) for i in range(len(self.config['n_classes']))])\n",
    "        loss = loss/len(self.config['n_classes'])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        step_output = [*y_hats, label]\n",
    "        return step_output\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        video, _, _ = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        step_output = y_hats\n",
    "        return step_output\n",
    "\n",
    "    def validation_epoch_end(self, step_outputs):\n",
    "        pred1, pred2, pred3, pred4, label = [], [], [], [], []\n",
    "        for step_output in step_outputs:\n",
    "            pred1.append(step_output[0])\n",
    "            pred2.append(step_output[1])\n",
    "            pred3.append(step_output[2])\n",
    "            pred4.append(step_output[3])\n",
    "            label.append(step_output[4])\n",
    "            \n",
    "        pred1 = torch.cat(pred1).argmax(1)\n",
    "        pred2 = torch.cat(pred2).argmax(1)\n",
    "        pred3 = torch.cat(pred3).argmax(1)\n",
    "        pred4 = torch.cat(pred4).argmax(1)\n",
    "        label = torch.cat(label).tolist()\n",
    "\n",
    "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
    "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
    "        \n",
    "        score = f1_score(label,pred, average='macro')\n",
    "        self.log(\"val_score\", score)\n",
    "        return score\n",
    "    \n",
    "    def post_preproc(self, step_outputs):\n",
    "        pred1, pred2, pred3, pred4 = [], [], [], []\n",
    "        for step_output in step_outputs:\n",
    "            pred1.append(step_output[0])\n",
    "            pred2.append(step_output[1])\n",
    "            pred3.append(step_output[2])\n",
    "            pred4.append(step_output[3])\n",
    "            \n",
    "        pred1 = torch.cat(pred1).argmax(1)\n",
    "        pred2 = torch.cat(pred2).argmax(1)\n",
    "        pred3 = torch.cat(pred3).argmax(1)\n",
    "        pred4 = torch.cat(pred4).argmax(1)\n",
    "\n",
    "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
    "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
    "\n",
    "        return pred\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Apollo(self.parameters(), lr=self.learning_rate)\n",
    "        return [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd5dbf9-b7f7-404b-9843-faae40e7eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k400 were not used when initializing TimesformerModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\dust\\Documents\\Dacon\\checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:411: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | TimesformerModel | 121 M \n",
      "1 | classifiers | ModuleList       | 0     \n",
      "2 | loss        | FocalLoss        | 0     \n",
      "-------------------------------------------------\n",
      "121 M     Trainable params\n",
      "0         Non-trainable params\n",
      "121 M     Total params\n",
      "242.518   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760dddc37c20406da685ba26d4dc0fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_score',\n",
    "    dirpath=config['checkpoint_dir'],\n",
    "    filename=f'{config[\"model_name\"]}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
    "    mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"train_loss\",\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "pl_video_model = PLVideoModel(config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator='auto', \n",
    "    precision=16,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback]\n",
    "                    \n",
    ")\n",
    "trainer.fit(pl_video_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "531d95da-c86f-44e5-9a56-b16505bdc5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k400 were not used when initializing TimesformerModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708d856ea4924f1fa6c11c3600742c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl_video_model_pretrained = PLVideoModel.load_from_checkpoint(\n",
    "    \"./checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1318-val_score=0.5356.ckpt\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(accelerator='auto')\n",
    "pred = trainer.predict(pl_video_model_pretrained, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fae171f4-24fe-4428-94e7-e2e920b20b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_post_proc = pl_video_model_pretrained.post_preproc(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53206209-b381-44e9-a27b-815db93db13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(f\"{config['data_dir']}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c14c78f9-1a7a-4a5b-8e32-b768e43ea392",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = pred_post_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3cc42ee-4233-496b-98df-d7b08f0abe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f\"{config['submission_dir']}/testsubmit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a2770-efb1-460a-a9be-f5f81c7311d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
