{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        self.img_path_list = img_path_list\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        images = self.get_frames(self.img_path_list[index])\n",
    "                        \n",
    "        if self.transforms is not None:\n",
    "            res = self.transforms(**images)\n",
    "            images = torch.zeros((len(images), 3, CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"]))\n",
    "            images[0, :, :, :] = res[\"image\"]\n",
    "            for i in range(1, len(images)):\n",
    "                images[i, :, :, :] = res[f\"image{i}\"]\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return images, label\n",
    "        else:\n",
    "            return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list) \n",
    "    \n",
    "    def get_frames(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        imgs = []        \n",
    "        for fidx in range(frames):\n",
    "            _, img = cap.read()            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgs.append(img)\n",
    "        \n",
    "        ret = {f\"image{i}\":imgs[i] for i in range(1, len(imgs))}\n",
    "        ret['image'] = imgs[0]\n",
    "\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    imgs = []        \n",
    "    for fidx in range(frames):\n",
    "        _, img = cap.read()            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        imgs.append(img)\n",
    "    \n",
    "    ret = {f\"image{i}\":imgs[i] for i in range(1, len(imgs))}\n",
    "    ret['image'] = imgs[0]\n",
    "    return ret\n",
    "\n",
    "def aug(transforms, images):\n",
    "    res = transforms(**images)\n",
    "    images = np.zeros((len(images), 180, 320, 3), dtype=np.uint8)\n",
    "    images[0, :, :, :] = res[\"image\"]\n",
    "    for i in range(1, len(images)):\n",
    "        images[i, :, :, :] = res[f\"image{i}\"]\n",
    "    return images, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c56fd7996b4e5288170852f38c6e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', max=49), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(height=180, width=320),\n",
    "    A.VerticalFlip(p=1),\n",
    "], p=1, additional_targets={f\"image{i}\":\"image\" for i in range(1, 50)})\n",
    "\n",
    "frames = get_frames(\"./train/TRAIN_0001.mp4\")\n",
    "frames,res = aug(transforms, frames)\n",
    "\n",
    "@interact(frame=(0, len(frames)-1))\n",
    "def show_frame(frame=0):\n",
    "    plt.imshow(frames[frame,:,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c7a21014fc0903b333c528e26b532495acabffc408f92f7990944da68b6f70a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
