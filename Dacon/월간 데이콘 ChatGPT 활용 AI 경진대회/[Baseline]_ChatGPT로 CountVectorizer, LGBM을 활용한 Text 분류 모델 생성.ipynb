{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5773afe1-1933-4c9b-8f1a-a08c4e37f5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.386409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[1]\tvalid_0's multi_logloss: 1.46008\n",
      "[2]\tvalid_0's multi_logloss: 1.35935\n",
      "[3]\tvalid_0's multi_logloss: 1.276\n",
      "[4]\tvalid_0's multi_logloss: 1.20615\n",
      "[5]\tvalid_0's multi_logloss: 1.14393\n",
      "[6]\tvalid_0's multi_logloss: 1.08876\n",
      "[7]\tvalid_0's multi_logloss: 1.03917\n",
      "[8]\tvalid_0's multi_logloss: 0.995053\n",
      "[9]\tvalid_0's multi_logloss: 0.955987\n",
      "[10]\tvalid_0's multi_logloss: 0.919875\n",
      "[11]\tvalid_0's multi_logloss: 0.887069\n",
      "[12]\tvalid_0's multi_logloss: 0.855921\n",
      "[13]\tvalid_0's multi_logloss: 0.828462\n",
      "[14]\tvalid_0's multi_logloss: 0.803111\n",
      "[15]\tvalid_0's multi_logloss: 0.779036\n",
      "[16]\tvalid_0's multi_logloss: 0.756383\n",
      "[17]\tvalid_0's multi_logloss: 0.735838\n",
      "[18]\tvalid_0's multi_logloss: 0.716171\n",
      "[19]\tvalid_0's multi_logloss: 0.697567\n",
      "[20]\tvalid_0's multi_logloss: 0.680118\n",
      "[21]\tvalid_0's multi_logloss: 0.663795\n",
      "[22]\tvalid_0's multi_logloss: 0.648961\n",
      "[23]\tvalid_0's multi_logloss: 0.634907\n",
      "[24]\tvalid_0's multi_logloss: 0.621961\n",
      "[25]\tvalid_0's multi_logloss: 0.609628\n",
      "[26]\tvalid_0's multi_logloss: 0.597547\n",
      "[27]\tvalid_0's multi_logloss: 0.586251\n",
      "[28]\tvalid_0's multi_logloss: 0.575292\n",
      "[29]\tvalid_0's multi_logloss: 0.564951\n",
      "[30]\tvalid_0's multi_logloss: 0.554989\n",
      "[31]\tvalid_0's multi_logloss: 0.54557\n",
      "[32]\tvalid_0's multi_logloss: 0.536654\n",
      "[33]\tvalid_0's multi_logloss: 0.528375\n",
      "[34]\tvalid_0's multi_logloss: 0.520277\n",
      "[35]\tvalid_0's multi_logloss: 0.512488\n",
      "[36]\tvalid_0's multi_logloss: 0.505391\n",
      "[37]\tvalid_0's multi_logloss: 0.498582\n",
      "[38]\tvalid_0's multi_logloss: 0.491921\n",
      "[39]\tvalid_0's multi_logloss: 0.485613\n",
      "[40]\tvalid_0's multi_logloss: 0.479408\n",
      "[41]\tvalid_0's multi_logloss: 0.473637\n",
      "[42]\tvalid_0's multi_logloss: 0.468074\n",
      "[43]\tvalid_0's multi_logloss: 0.462732\n",
      "[44]\tvalid_0's multi_logloss: 0.457597\n",
      "[45]\tvalid_0's multi_logloss: 0.452497\n",
      "[46]\tvalid_0's multi_logloss: 0.447875\n",
      "[47]\tvalid_0's multi_logloss: 0.443278\n",
      "[48]\tvalid_0's multi_logloss: 0.43902\n",
      "[49]\tvalid_0's multi_logloss: 0.434747\n",
      "[50]\tvalid_0's multi_logloss: 0.430972\n",
      "[51]\tvalid_0's multi_logloss: 0.42706\n",
      "[52]\tvalid_0's multi_logloss: 0.423467\n",
      "[53]\tvalid_0's multi_logloss: 0.419893\n",
      "[54]\tvalid_0's multi_logloss: 0.416011\n",
      "[55]\tvalid_0's multi_logloss: 0.412811\n",
      "[56]\tvalid_0's multi_logloss: 0.409282\n",
      "[57]\tvalid_0's multi_logloss: 0.406366\n",
      "[58]\tvalid_0's multi_logloss: 0.403266\n",
      "[59]\tvalid_0's multi_logloss: 0.39991\n",
      "[60]\tvalid_0's multi_logloss: 0.396674\n",
      "[61]\tvalid_0's multi_logloss: 0.393645\n",
      "[62]\tvalid_0's multi_logloss: 0.39085\n",
      "[63]\tvalid_0's multi_logloss: 0.388286\n",
      "[64]\tvalid_0's multi_logloss: 0.385601\n",
      "[65]\tvalid_0's multi_logloss: 0.383172\n",
      "[66]\tvalid_0's multi_logloss: 0.380603\n",
      "[67]\tvalid_0's multi_logloss: 0.378269\n",
      "[68]\tvalid_0's multi_logloss: 0.376083\n",
      "[69]\tvalid_0's multi_logloss: 0.373762\n",
      "[70]\tvalid_0's multi_logloss: 0.371633\n",
      "[71]\tvalid_0's multi_logloss: 0.369463\n",
      "[72]\tvalid_0's multi_logloss: 0.367458\n",
      "[73]\tvalid_0's multi_logloss: 0.365243\n",
      "[74]\tvalid_0's multi_logloss: 0.363228\n",
      "[75]\tvalid_0's multi_logloss: 0.361205\n",
      "[76]\tvalid_0's multi_logloss: 0.359195\n",
      "[77]\tvalid_0's multi_logloss: 0.357241\n",
      "[78]\tvalid_0's multi_logloss: 0.355393\n",
      "[79]\tvalid_0's multi_logloss: 0.353476\n",
      "[80]\tvalid_0's multi_logloss: 0.351618\n",
      "[81]\tvalid_0's multi_logloss: 0.349785\n",
      "[82]\tvalid_0's multi_logloss: 0.348216\n",
      "[83]\tvalid_0's multi_logloss: 0.346746\n",
      "[84]\tvalid_0's multi_logloss: 0.345334\n",
      "[85]\tvalid_0's multi_logloss: 0.344094\n",
      "[86]\tvalid_0's multi_logloss: 0.342696\n",
      "[87]\tvalid_0's multi_logloss: 0.341221\n",
      "[88]\tvalid_0's multi_logloss: 0.340054\n",
      "[89]\tvalid_0's multi_logloss: 0.338893\n",
      "[90]\tvalid_0's multi_logloss: 0.337736\n",
      "[91]\tvalid_0's multi_logloss: 0.336438\n",
      "[92]\tvalid_0's multi_logloss: 0.335259\n",
      "[93]\tvalid_0's multi_logloss: 0.333974\n",
      "[94]\tvalid_0's multi_logloss: 0.33286\n",
      "[95]\tvalid_0's multi_logloss: 0.331644\n",
      "[96]\tvalid_0's multi_logloss: 0.330615\n",
      "[97]\tvalid_0's multi_logloss: 0.329419\n",
      "[98]\tvalid_0's multi_logloss: 0.328372\n",
      "[99]\tvalid_0's multi_logloss: 0.327188\n",
      "[100]\tvalid_0's multi_logloss: 0.326143\n",
      "Validation F1 score: 0.8309650339129231\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_df['text'], train_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the text data using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(train_data).astype(np.float64)\n",
    "val_features = vectorizer.transform(val_data).astype(np.float64)\n",
    "test_features = vectorizer.transform(test_df['text']).astype(np.float64)\n",
    "\n",
    "# Create a LightGBM classifier and specify its hyperparameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 8,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "\n",
    "# Train the LightGBM model\n",
    "clf.fit(train_features, train_labels, eval_set=[(val_features, val_labels)], early_stopping_rounds=10)\n",
    "\n",
    "# Evaluate the performance of the model on the validation set\n",
    "val_pred = clf.predict(val_features)\n",
    "val_f1_score = f1_score(val_labels, val_pred, average='macro')\n",
    "print('Validation F1 score:', val_f1_score)\n",
    "\n",
    "# Make predictions on the test data and save to a CSV file\n",
    "test_pred = clf.predict(test_features)\n",
    "submission_df = pd.DataFrame({'id': test_df['id'], 'label': test_pred})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
