Deep-Learning Computer-Vision Guide

1. Object Detection, Segmentation에 대한 깊이 있는 이론 설명
2. 실습
	구현패키지:
	a) MMDetection
	b) Ultralytics YOLO V3
	c) AutoML EfficientDet
	
	범용 인터페이스 API:
	a) OpenCV
	b) TensorFlow Hub

Colab, Kaggle Kernel 사용


Object Detection과 Segmentation 이해

Object Detection - Deep learning 기반으로 발전
2012년에 AlexNet이 PASCAL VOC 대회에서 DeepLearning 기반의 CNN으로 우승하면서 발전이 가속화됨

Localization / Detection / Segmentation
	- Classification > Localization > Detection > Segmentation

Detect할 대상: Object

하나의 Object가 하나의 Image에 있는 형태: Localization

여러 Object를 bounding box로 Detect: Detection

Bounding box 가 아닌 정밀하게 Pixel 단위로 detect: Segmentation

2012년 기준으로:
Traditional Detection Methods > 2012 > Deep LEarning based Detection Methods

Deep Learning based Detection Methods:
	One-stage detector
		- YOLO(2015), SSD, Retina-Net, EfficientDet
	Two-stage detector: object의 대략적인 위치를 잡고 시작
		- RCNN
		- 실시간 적용이 어려움 (video)

Object Detection의 주요 구성 요소:
- Region Proposal 				- 영역추정
- Feature Extraction & FPN & Network Prediction	- Detection을 위한 Deep Learning 네트웍 구성
- IOU, NMS, mAP, Anchor box			- Detection을 구성하는 기타 요소

일반적인 Object Detection 모델:
- Backbone: ResNet
- Neck: FPN(Feature Pyramid Network)
- Head: classification, bbox regression

Object Detection의 난제:
- Classification + Regression을 동시에
	- 이미지에서 여러 개의 물체를 classficiation함과 동시에 위치를 찾아야 함
- 다양한 크기와 유형의 오브젝트가 섞여 있음
	- 크기가 서로 다르고, 생김새가 다양한 오브젝트가 섞여 있는 이미지에서 이들을 Detect함
- 중요한 Detect 시간
	- Detect 시간이 중요한 실시간 영상 기반에서 Detectgodi gksms dyrntkgkd wmdeo
- 명확하지 않은 이미지
	- 오브젝트 이미지가 명확하지 않은 경우가 많음. 또한 ㅓㄴ체 이미지에서 Detect할 오브젝트가 차지하는 비중이 높지 않음(배경이 대부분을 차지하는 경우가 많음)
- 데이터 세트의 부족
	- 훈련 가능한 데이터 세트가 부족(Ms Coco dataset 80개, Google Open Image 500개) 하며 annotation을 만들어야 하므로 훈련 뎅터 세트를 생성하기가 상대적으로 어려움

## Object Localization과 Detection의 이해

Object Localization 개요
Object Localization: 하나의 이미지에 하나의 객체





FC Layer: Fully Connected Layer

Label 와 유사하게 Annotation파일을 사용
	- Bounding Box의 꼭지점 좌표값을 포함하고 있음
	- Yolo의 경우 Bounding Box의 중앙점 좌표값 사용

Bounding Box Regression을 함께 진행
Feature Map에서 특정 특성이 나오면 진행할 Regression을 지정

Object Localization - Bounding box 학습



Class Confidence Score : ex) 객체가 Car일 확률이 0.9

Object Detection - 두개 이상의 Object를 검출
Bounding Box만 모델에 넣으면 inference 자체가 어려워짐 (예측하는 것이 어려워짐)

-> Object가 있을만한 위치를 먼저 찾은 후에 해당 영역의 Object를 예측하는 방법 사용
Region Proposal: 객체가 있을만한 위치

## Region Proposal(영역 추정)의 이해와 슬라이딩 윈도우와의 비교

원본 이미지 -> Feature Extract Layer(추상화된 Feature Layer가 만들어짐)

### Slide in Window 방식
Slide in Window 방식:
	- 다양한 형태의 윈도우를 한칸씩 움직이면서 윈도우 내에서의 객체를 찾음 -> Bounding Box 예측
	- 왼쪽 상단에서부터 오른쪽 하단까지
	- 단점: 윈도우 사이즈와 객체 사이즈, 형태에 따라 Detect가 어려울 수 있다, 오래걸림
	Opt1: 다양한 형태의 Window를 각각 sliding 시키는 방식 (Window를 변형)
	Opt2: Window Scale 은 고정하고 scale 을 변경한 여러 이미지를 사용 (이미지를 변형)
	- Opt1, Opt1를 합쳐서도 사용
	- Object Detection의 초기 기법으로 활용
	- 오브젝트 없는 영역도 무조건 슬라이딩 하여야 하며 여러 형태의 Window와 여러 Scale을 가진 이미지를 스캔하면서 검출해야 하므로 수행 시간이 오래 걸리고 검출 성능이 상대적으로 낮음
	- Region Proposal(영역추정) 기법의 등장으로 활용도는 떨어졌지만 Object Detection 발전을 위한 기술적 토대 제공
		- Region Proposal의 Anchor Box에서 유사한 박싱방식이 사용됨
		- SSD -> + FPN

### 이미지 Scale 조정에 따른 여러 크기의 Object Detection
* Window 가 커서 객체가 Window안에 다 들어가지 않을 수 있다 -> 윈도우 사이즈는 그대로 둔 체로 이미지 사이즈를 줄인다
	* Window 안에 여러 객체가 포함되면 기존 이슈가 동일하게 발생할 가능성이 있다

## Region Proposal(영역 추정) - Selective Search 기법

### Region Proposal(영역 추정) 방식:

#### “Object가 있을 만한 후보 영역을 찾자”



## Selective Search - Region Proposal의 대표 방법

* 빠른 Detection과 높은 Recall 예측 성능을 동시에 만족하는 알고리즘
* 컬러(Color), 무늬(Texture), 크기(Size), 형태(Shape)에 다라 유사한 Region을 계층적 그루핑 방법으로 계산
* Selective Search는 최초에는 Pixel Intensity 기반판 graph-based segment 기법에 따라 Over Segmentation을 수행

