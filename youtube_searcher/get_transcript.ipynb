{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.youtube.com/watch?v=snZI5ojuMRc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_youtube_id(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts YouTube video ID from a given URL.\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:v=|be/)([a-zA-Z0-9_-]{11})\"\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snZI5ojuMRc'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_url = extract_youtube_id(URL)\n",
    "extracted_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "extracted_transcript = YouTubeTranscriptApi.get_transcript(\n",
    "    extracted_url, languages=[\"en\", \"ko\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Hi all, Will here. This week we are\\xa0\\nexcited to launch the LangMem SDK—a\\xa0\\xa0',\n",
       "  'start': 0.04,\n",
       "  'duration': 4.36},\n",
       " {'text': 'library of utilities to help you build\\xa0\\nagents that learn and adapt as they go.',\n",
       "  'start': 4.4,\n",
       "  'duration': 4.36},\n",
       " {'text': 'As part of the release, we wanted to\\xa0\\nreview the high-level concepts driving\\xa0\\xa0',\n",
       "  'start': 8.76,\n",
       "  'duration': 3.44},\n",
       " {'text': 'the development of the library, as well as\\xa0\\nshare a mental framework you can use to more\\xa0\\xa0',\n",
       "  'start': 12.2,\n",
       "  'duration': 3.92},\n",
       " {'text': 'effectively leverage memory to build\\xa0\\nmore reliable and personalized agents.',\n",
       "  'start': 16.12,\n",
       "  'duration': 4.36},\n",
       " {'text': 'Memory is a broad concept, and we believe\\xa0\\nthat rather than building a generic,\\xa0\\xa0',\n",
       "  'start': 20.48,\n",
       "  'duration': 4.08},\n",
       " {'text': 'general-purpose memory layer,\\xa0\\nmost successful AI applications\\xa0\\xa0',\n",
       "  'start': 24.56,\n",
       "  'duration': 3.72},\n",
       " {'text': 'today will benefit from leveraging domain\\xa0\\nspecificity to accomplish concrete goals.',\n",
       "  'start': 28.28,\n",
       "  'duration': 5.24},\n",
       " {'text': 'If you think about the specific capabilities\\xa0\\nand knowledge your agent needs in order to\\xa0\\xa0',\n",
       "  'start': 33.52,\n",
       "  'duration': 3.96},\n",
       " {'text': 'successfully accomplish its tasks, you can\\xa0\\ntypically map these onto distinct memory types.',\n",
       "  'start': 37.48,\n",
       "  'duration': 6.2},\n",
       " {'text': 'One analogy I find useful is thinking about\\xa0\\nhow computers represent information. Computers\\xa0\\xa0',\n",
       "  'start': 43.68,\n",
       "  'duration': 5.08},\n",
       " {'text': 'typically distinguish between data, which\\xa0\\nis static or dynamic information, and code,\\xa0\\xa0',\n",
       "  'start': 48.76,\n",
       "  'duration': 4.72},\n",
       " {'text': 'which consists of instructions and procedures.\\xa0\\nWe can think of agent memory in similar terms.',\n",
       "  'start': 53.48,\n",
       "  'duration': 5.56},\n",
       " {'text': '**Semantic memory** acts as the data\\xa0\\nstore. It stores important knowledge,\\xa0\\xa0',\n",
       "  'start': 59.04,\n",
       "  'duration': 4.44},\n",
       " {'text': 'relationships, entities, and other\\xa0\\ninformation that is useful to ground\\xa0\\xa0',\n",
       "  'start': 63.48,\n",
       "  'duration': 4.36},\n",
       " {'text': 'the responses the agent might have\\xa0\\nto the user. **Procedural memory**,\\xa0\\xa0',\n",
       "  'start': 67.84,\n",
       "  'duration': 3.16},\n",
       " {'text': 'on the other hand, acts more like\\xa0\\ncode. It encodes the rules, behaviors,\\xa0\\xa0',\n",
       "  'start': 71.0,\n",
       "  'duration': 5.32},\n",
       " {'text': 'and other information needed for the agent to\\xa0\\nknow how to respond and act in a given situation.',\n",
       "  'start': 76.32,\n",
       "  'duration': 6.4},\n",
       " {'text': '**Episodic memory** sits somewhere in between\\xa0\\nthe two. It stores information about past\\xa0\\xa0',\n",
       "  'start': 82.72,\n",
       "  'duration': 3.72},\n",
       " {'text': 'events in the form of few-shot examples.\\xa0\\nThese examples instruct the agent how to\\xa0\\xa0',\n",
       "  'start': 86.44,\n",
       "  'duration': 4.44},\n",
       " {'text': 'respond—similar to procedural memory—based\\xa0\\non prior attempts, while also encoding a lot\\xa0\\xa0',\n",
       "  'start': 90.88,\n",
       "  'duration': 5.56},\n",
       " {'text': 'of information about what the agent did\\xa0\\nin the past, similar to semantic memory.',\n",
       "  'start': 96.44,\n",
       "  'duration': 4.52},\n",
       " {'text': 'Taken together, semantic, procedural,\\xa0\\nand episodic memories tell the agent\\xa0\\xa0',\n",
       "  'start': 100.96,\n",
       "  'duration': 4.96},\n",
       " {'text': 'both what to do and how to act in a given\\xa0\\nsituation. If implemented effectively,\\xa0\\xa0',\n",
       "  'start': 105.92,\n",
       "  'duration': 5.24},\n",
       " {'text': \"these combine with the language model's\\xa0\\nunderlying reasoning abilities and your\\xa0\\xa0\",\n",
       "  'start': 111.16,\n",
       "  'duration': 3.88},\n",
       " {'text': 'own code to accomplish whatever task\\xa0\\nyou might need in your application.',\n",
       "  'start': 115.04,\n",
       "  'duration': 4.28},\n",
       " {'text': \"Let's go a step further by grounding\\xa0\\neach of these memory types with examples.\",\n",
       "  'start': 119.32,\n",
       "  'duration': 4.96},\n",
       " {'text': 'Semantic memory encodes facts, knowledge,\\xa0\\xa0',\n",
       "  'start': 124.8,\n",
       "  'duration': 3.76},\n",
       " {'text': 'and relationships into some underlying\\xa0\\nstorage. This is typically what most people\\xa0\\xa0',\n",
       "  'start': 128.56,\n",
       "  'duration': 5.4},\n",
       " {'text': 'think of when they consider long-term\\xa0\\nmemory. People often jump straight to\\xa0\\xa0',\n",
       "  'start': 133.96,\n",
       "  'duration': 3.8},\n",
       " {'text': 'knowledge graphs or vector databases—both of\\xa0\\nwhich are valid ways to store information.',\n",
       "  'start': 137.76,\n",
       "  'duration': 5.52},\n",
       " {'text': 'In our experience, we’ve seen two\\xa0\\nrepresentations be the most common:\\xa0\\xa0',\n",
       "  'start': 143.28,\n",
       "  'duration': 4.04},\n",
       " {'text': '**collections** and **profiles**.',\n",
       "  'start': 147.32,\n",
       "  'duration': 1.16},\n",
       " {'text': '- **Collections:** These refer\\xa0\\nto storing memories as distinct\\xa0\\xa0',\n",
       "  'start': 148.48,\n",
       "  'duration': 3.2},\n",
       " {'text': 'records in some sort of database. In\\xa0\\nthe context of LangMem and LangGraph,\\xa0\\xa0',\n",
       "  'start': 151.68,\n",
       "  'duration': 3.72},\n",
       " {'text': 'these are typically stored in LangGraph’s\\xa0\\nlong-term memory storage layer—the base\\xa0\\xa0',\n",
       "  'start': 155.4,\n",
       "  'duration': 3.88},\n",
       " {'text': 'store. New memories are formed by extracting new\\xa0\\nrecords in the database. Each memory can either\\xa0\\xa0',\n",
       "  'start': 159.28,\n",
       "  'duration': 5.32},\n",
       " {'text': 'be an unstructured string or take on some level\\xa0\\nof structure based on the schema you provide.\\xa0\\xa0',\n",
       "  'start': 164.6,\n",
       "  'duration': 5.56},\n",
       " {'text': 'These schemas can model the specific domain\\xa0\\nof your application if you find that useful.\\xa0\\xa0',\n",
       "  'start': 170.16,\n",
       "  'duration': 4.76},\n",
       " {'text': 'Memories are consolidated and synthesized\\xa0\\neither by taking existing memories and using\\xa0\\xa0',\n",
       "  'start': 174.92,\n",
       "  'duration': 4.64},\n",
       " {'text': 'them to inform new ones or by updating existing\\xa0\\nrecords. These collections can be unbounded and\\xa0\\xa0',\n",
       "  'start': 179.56,\n",
       "  'duration': 9.32},\n",
       " {'text': 'are typically searched using vector search,\\xa0\\nfull-text search, or a combination of both.',\n",
       "  'start': 190.0,\n",
       "  'duration': 4.12},\n",
       " {'text': 'For example, LangMem created a semantic memory\\xa0\\nmanager that, when passed a list of messages\\xa0\\xa0',\n",
       "  'start': 194.12,\n",
       "  'duration': 6.08},\n",
       " {'text': 'from a conversation, extracted the following\\xa0\\nmemories: we learned that the user prefers\\xa0\\xa0',\n",
       "  'start': 200.2,\n",
       "  'duration': 5.12},\n",
       " {'text': '“Lex” (short for Alex) and appreciates\\xa0\\na casual and witty communication style.\\xa0\\xa0',\n",
       "  'start': 205.32,\n",
       "  'duration': 4.88},\n",
       " {'text': 'We also learned specific information about\\xa0\\nLex—such as his proficiency in Python programming\\xa0\\xa0',\n",
       "  'start': 210.2,\n",
       "  'duration': 4.76},\n",
       " {'text': 'and his competitive speedcubing—and additional\\xa0\\npersonality traits that may be recalled later.',\n",
       "  'start': 214.96,\n",
       "  'duration': 8.28},\n",
       " {'text': '- **Profiles:** A profile compresses all\\xa0\\nthe information into a particular schema or\\xa0\\xa0',\n",
       "  'start': 227.92,\n",
       "  'duration': 6.8},\n",
       " {'text': 'a one-pager about a particular user. These are\\xa0\\ncommon in user-facing chatbots where you have\\xa0\\xa0',\n",
       "  'start': 234.72,\n",
       "  'duration': 5.28},\n",
       " {'text': 'specific details such as a user’s name, age,\\xa0\\nfriends, or other key details. New memories\\xa0\\xa0',\n",
       "  'start': 240.0,\n",
       "  'duration': 8.52},\n",
       " {'text': 'are formed by continuously updating this\\xa0\\nsingle representation. This approach helps\\xa0\\xa0',\n",
       "  'start': 248.52,\n",
       "  'duration': 4.8},\n",
       " {'text': 'reduce irrelevant content, though it may also\\xa0\\nresult in the loss of information that wasn’t\\xa0\\xa0',\n",
       "  'start': 253.32,\n",
       "  'duration': 9.0},\n",
       " {'text': 'modeled in the profile. A pragmatic use case\\xa0\\nfor profiles is that they’re easy to render\\xa0\\xa0',\n",
       "  'start': 262.32,\n",
       "  'duration': 7.56},\n",
       " {'text': 'in a UI. If you have a user-facing chatbot, the\\xa0\\nagent can display what it knows about the user,\\xa0\\xa0',\n",
       "  'start': 269.88,\n",
       "  'duration': 6.68},\n",
       " {'text': 'and the user can collaborate on\\xa0\\nthe memory. For example, if the\\xa0\\xa0',\n",
       "  'start': 276.56,\n",
       "  'duration': 2.72},\n",
       " {'text': 'agent assumes you prefer your name to be\\xa0\\n“Tom” but you actually prefer “Thomas,”\\xa0\\xa0',\n",
       "  'start': 279.28,\n",
       "  'duration': 4.96},\n",
       " {'text': 'you can directly modify the profile, and the\\xa0\\nagent will immediately update its behavior.',\n",
       "  'start': 284.24,\n",
       "  'duration': 4.64},\n",
       " {'text': 'Procedural memory tells the agent how to respond.\\xa0\\nIn our experience, this typically takes the form\\xa0\\xa0',\n",
       "  'start': 288.88,\n",
       "  'duration': 5.76},\n",
       " {'text': 'of a subset of the system prompt in your LLM.\\xa0\\nThis prompt fragment can encode user preferences,\\xa0\\xa0',\n",
       "  'start': 294.64,\n",
       "  'duration': 5.0},\n",
       " {'text': 'core agent behavior, and other conditionals and\\xa0\\nrules that the agent should know to accomplish\\xa0\\xa0',\n",
       "  'start': 300.56,\n",
       "  'duration': 4.92},\n",
       " {'text': 'its task. A common example is the response\\xa0\\nstyle: if you ask ChatGPT today to draft a\\xa0\\xa0',\n",
       "  'start': 305.48,\n",
       "  'duration': 8.12},\n",
       " {'text': 'blog post about memory, the output might\\xa0\\nnot reflect your preferred style. Rather\\xa0\\xa0',\n",
       "  'start': 313.6,\n",
       "  'duration': 6.0},\n",
       " {'text': 'than manually writing and restarting the\\xa0\\nsystem prompt for every new conversation,\\xa0\\xa0',\n",
       "  'start': 319.6,\n",
       "  'duration': 7.12},\n",
       " {'text': 'the agent should learn over time\\xa0\\nthat you prefer a particular voice.',\n",
       "  'start': 326.72,\n",
       "  'duration': 3.16},\n",
       " {'text': 'A simpler example is having it remember that\\xa0\\nyou prefer writing with proper TypeScript rather\\xa0\\xa0',\n",
       "  'start': 329.88,\n",
       "  'duration': 6.32},\n",
       " {'text': 'than raw JavaScript, or that you favor front-end\\xa0\\ndevelopment over back-end. It can even infer that,\\xa0\\xa0',\n",
       "  'start': 336.2,\n",
       "  'duration': 6.8},\n",
       " {'text': \"since you are now an expert in AI, it doesn't\\xa0\\nneed to rehash all the beginner-level content\\xa0\\xa0\",\n",
       "  'start': 343.0,\n",
       "  'duration': 5.44},\n",
       " {'text': 'before diving into advanced concepts. LangMem\\xa0\\nexposes this through prompt optimization,\\xa0\\xa0',\n",
       "  'start': 348.44,\n",
       "  'duration': 8.48},\n",
       " {'text': 'which is designed to learn online from feedback\\xa0\\nor natural conversational examples. We go into\\xa0\\xa0',\n",
       "  'start': 356.92,\n",
       "  'duration': 6.28},\n",
       " {'text': 'more detail in our walkthrough on how to use\\xa0\\nthe prompt optimizers in a separate video.',\n",
       "  'start': 363.2,\n",
       "  'duration': 4.92},\n",
       " {'text': 'Episodic memory stores information from past\\xa0\\nexperiences. It encodes both how the agent\\xa0\\xa0',\n",
       "  'start': 369.32,\n",
       "  'duration': 5.12},\n",
       " {'text': 'should respond and what happened in the past.\\xa0\\nThis usually relies on feedback—either from\\xa0\\xa0',\n",
       "  'start': 374.44,\n",
       "  'duration': 6.12},\n",
       " {'text': 'explicit user signals, such as a thumbs up, or\\xa0\\nfrom auto-evaluation by analyzing interactions\\xa0\\xa0',\n",
       "  'start': 380.56,\n",
       "  'duration': 5.88},\n",
       " {'text': 'and recognizing successful outcomes. The agent can\\xa0\\nsave the trajectory of the input along with the\\xa0\\xa0',\n",
       "  'start': 386.44,\n",
       "  'duration': 6.28},\n",
       " {'text': 'expected output to the store. In future rounds,\\xa0\\nit can fetch these memories semantically based\\xa0\\xa0',\n",
       "  'start': 392.72,\n",
       "  'duration': 4.6},\n",
       " {'text': 'on similarities, thereby achieving similarly good\\xa0\\nbehavior and avoiding divergence on hard examples.',\n",
       "  'start': 397.32,\n",
       "  'duration': 5.68},\n",
       " {'text': 'In conclusion, memory is an exciting topic\\xa0\\nand a core component in building adaptive,\\xa0\\xa0',\n",
       "  'start': 403.0,\n",
       "  'duration': 5.8},\n",
       " {'text': 'personalized, and self-improving\\xa0\\nagents. For the foreseeable future,\\xa0\\xa0',\n",
       "  'start': 408.8,\n",
       "  'duration': 3.6},\n",
       " {'text': 'we believe that most successful applications\\xa0\\nof memory will be application-specific.\\xa0\\xa0',\n",
       "  'start': 412.4,\n",
       "  'duration': 4.24},\n",
       " {'text': 'Engineers who start by thinking about\\xa0\\nthe type of information an agent needs\\xa0\\xa0',\n",
       "  'start': 416.64,\n",
       "  'duration': 4.84},\n",
       " {'text': 'to learn in order to know what to do and\\xa0\\nhow to act will find the most success.',\n",
       "  'start': 421.48,\n",
       "  'duration': 4.68},\n",
       " {'text': 'While this video is purely conceptual,\\xa0\\xa0',\n",
       "  'start': 426.16,\n",
       "  'duration': 2.16},\n",
       " {'text': 'we encourage you to check out the LangMem\\xa0\\ndocs as well as our other videos on how to\\xa0\\xa0',\n",
       "  'start': 428.32,\n",
       "  'duration': 4.84},\n",
       " {'text': 'apply LangMem and these memory concepts in your\\xa0\\nagents. Thank you again, and see you next time.',\n",
       "  'start': 433.16,\n",
       "  'duration': 4.88}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseTemplate:\n",
    "    timestamp: str = \"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube-searcher-Ud_v7a-T-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
