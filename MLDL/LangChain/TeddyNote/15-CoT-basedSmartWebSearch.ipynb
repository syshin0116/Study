{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT Based Smart Web Search\n",
    "\n",
    "- Author: [syshin0116](https://github.com/syshin0116)\n",
    "- Design: \n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/07-Agent/15-CoT-basedSmartWebSearch.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/07-Agent/15-CoT-basedSmartWebSearch.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates a chain-of-thought (CoT) based Smart Web Search approach to build a plan-and-execute style QA chatbot. We will also explore the LLMCompiler method for speed optimization.\n",
    "\n",
    "### Key Features\n",
    "- Chain-of-Thought guided query expansion and reasoning\n",
    "- Dynamic plan-and-execute system for multi-step web search\n",
    "- Integration with LLMCompiler for accelerated pipeline\n",
    "\n",
    "\n",
    "\n",
    "## LLM Compiler\n",
    "\n",
    "- Proposed by Kim et al. as a high-speed, execution-oriented agent architecture\n",
    "- Core Components\n",
    "    - **Planner**\n",
    "        - Generates tasks in a DAG (Directed Acyclic Graph) format via streaming\n",
    "    - **Task Fetching Unit**\n",
    "        - Consumes the Planner’s list of tasks, executing each as soon as dependencies are met\n",
    "        - Supports parallel execution\n",
    "    - **Joiner**\n",
    "        - Collects results from all tasks and decides whether to produce a final answer or replan\n",
    "- Key Characteristics\n",
    "    - Allows streaming of tasks so certain tasks can be executed even before the Planner finishes building out the full plan\n",
    "    - Executes all dependency-free tasks in parallel to reduce overall runtime\n",
    "    - Provides fast responses with minimal large-model usage\n",
    "\n",
    "\n",
    "### What is a DAG?\n",
    "\n",
    "A **DAG (Directed Acyclic Graph)** is a common structure in computing and data processing\n",
    "\n",
    "- **Directed**\n",
    "    - Every edge in the graph has a direction\n",
    "    - For instance, A → B means you can only move from A to B\n",
    "- **Acyclic**\n",
    "    - The graph contains no cycles\n",
    "    - There is no path that starts at one node and eventually returns to it\n",
    "- **Graph**\n",
    "    - Composed of nodes and edges\n",
    "    - Nodes represent data or tasks, and edges define how they relate to or depend on each other\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [...](#...)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models](https://arxiv.org/abs/2310.04406)\n",
    "- [Building (and Breaking) WebLangChain](https://blog.langchain.dev/weblangchain/)\n",
    "- [Plan-and-Execute Agents](https://blog.langchain.dev/planning-agents/)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setting up your environment is the first step. See the [Environment Setup](https://wikidocs.net/257836) guide for more details.\n",
    "\n",
    "\n",
    "**[Note]**\n",
    "\n",
    "The langchain-opentutorial is a package of easy-to-use environment setup guidance, useful functions and utilities for tutorials.\n",
    "Check out the  [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리뷰어님들을 위한 설명\n",
    "\n",
    "### 튜토리얼 주요 목적\n",
    "- Perplexity와 유사한 CoT 기반 검색 QA(Chatbot) 구현\n",
    "- Plan-Execute 방식을 바탕으로 LLMCompiler를 추가 적용하여 속도 최적화 시도\n",
    "\n",
    "### 현재 코드 상태\n",
    "- 코드가 두 부분으로 나뉘어 있음 (LLMCompiler 방식 / Plan & Schedule 방식)\n",
    "\n",
    "### 추가 예정 항목\n",
    "- Plan & Schedule 방식에 LLM Compiler 코드 통합\n",
    "- LangChain 공식 Config 설정 방식으로 변경\n",
    "- 설명, 주석 추가\n",
    "- Prompt 수정\n",
    "- Summarizer, Output Parser 고도화 및 최종 QA 결과 최적화\n",
    "- LangSmith 오류 해결\n",
    "\n",
    "    `Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)`\n",
    "\n",
    "### 추가 가능성 항목\n",
    "- VectorDB 검색, Knowledge Graph 검색, Web Search API 등 툴 추가\n",
    "- 이미지 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain-anthropic\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\"duckduckgo-search\"],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"COT-based-smart-websearch\",\n",
    "        \"TAVILY_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for asynchronous tasks\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Compiler\n",
    "\n",
    "LLMCompiler is an agent architecture designed to speed up the execution of agentic tasks by eagerly-executed tasks within a DAG. It also saves costs on redundant token usage by reducing the number of calls to the LLM. Below is an overview of its computational graph:\n",
    "\n",
    "![LLM Compiler](./assets/15-CoT-basedSmartWebSearch-01.png)\n",
    "\n",
    "It has 3 main components:\n",
    "\n",
    "Planner: stream a DAG of tasks.\n",
    "Task Fetching Unit: schedules and executes the tasks as soon as they are executable\n",
    "Joiner: Responds to the user or triggers a second plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = TavilySearchResults(\n",
    "    max_results=1,\n",
    "    description='tavily_search_results_json(query=\"the search query\") - a search engine.',\n",
    ")\n",
    "\n",
    "# from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "# search = DuckDuckGoSearchResults(\n",
    "#     description='duckduckgo_search_results_json(query=\"the search query\") - a search engine.',\n",
    "# )\n",
    "\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Seoul', 'region': '', 'country': 'South Korea', 'lat': 37.5664, 'lon': 126.9997, 'tz_id': 'Asia/Seoul', 'localtime_epoch': 1737893172, 'localtime': '2025-01-26 21:06'}, 'current': {'last_updated_epoch': 1737892800, 'last_updated': '2025-01-26 21:00', 'temp_c': 5.0, 'temp_f': 41.0, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 3.6, 'wind_kph': 5.8, 'wind_degree': 109, 'wind_dir': 'ESE', 'pressure_mb': 1022.0, 'pressure_in': 30.18, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 48, 'cloud': 0, 'feelslike_c': 3.8, 'feelslike_f': 38.8, 'windchill_c': 1.6, 'windchill_f': 34.8, 'heatindex_c': 3.1, 'heatindex_f': 37.5, 'dewpoint_c': -5.9, 'dewpoint_f': 21.5, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.0, 'gust_mph': 5.5, 'gust_kph': 8.8}}\"}]\n"
     ]
    }
   ],
   "source": [
    "print(search.invoke(\"weather in seoul\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "from typing import (\n",
    "    Any,\n",
    "    Dict,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers.transform import BaseTransformOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import BaseTool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "THOUGHT_PATTERN = r\"Thought: ([^\\n]*)\"\n",
    "ACTION_PATTERN = r\"\\n*(\\d+)\\. (\\w+)\\((.*)\\)(\\s*#\\w+\\n)?\"\n",
    "# $1 or ${1} -> 1\n",
    "ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
    "END_OF_PLAN = \"<END_OF_PLAN>\"\n",
    "\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "\n",
    "def _ast_parse(arg: str) -> Any:\n",
    "    try:\n",
    "        return ast.literal_eval(arg)\n",
    "    except:  # noqa\n",
    "        return arg\n",
    "\n",
    "\n",
    "def _parse_llm_compiler_action_args(args: str, tool: Union[str, BaseTool]) -> list[Any]:\n",
    "    \"\"\"Parse arguments from a string.\"\"\"\n",
    "    if args == \"\":\n",
    "        return ()\n",
    "    if isinstance(tool, str):\n",
    "        return ()\n",
    "    extracted_args = {}\n",
    "    tool_key = None\n",
    "    prev_idx = None\n",
    "    for key in tool.args.keys():\n",
    "        # Split if present\n",
    "        if f\"{key}=\" in args:\n",
    "            idx = args.index(f\"{key}=\")\n",
    "            if prev_idx is not None:\n",
    "                extracted_args[tool_key] = _ast_parse(\n",
    "                    args[prev_idx:idx].strip().rstrip(\",\")\n",
    "                )\n",
    "            args = args.split(f\"{key}=\", 1)[1]\n",
    "            tool_key = key\n",
    "            prev_idx = 0\n",
    "    if prev_idx is not None:\n",
    "        extracted_args[tool_key] = _ast_parse(\n",
    "            args[prev_idx:].strip().rstrip(\",\").rstrip(\")\")\n",
    "        )\n",
    "    return extracted_args\n",
    "\n",
    "\n",
    "def default_dependency_rule(idx, args: str):\n",
    "    matches = re.findall(ID_PATTERN, args)\n",
    "    numbers = [int(match) for match in matches]\n",
    "    return idx in numbers\n",
    "\n",
    "\n",
    "def _get_dependencies_from_graph(\n",
    "    idx: int, tool_name: str, args: Dict[str, Any]\n",
    ") -> dict[str, list[str]]:\n",
    "    \"\"\"Get dependencies from a graph.\"\"\"\n",
    "    if tool_name == \"join\":\n",
    "        return list(range(1, idx))\n",
    "    return [i for i in range(1, idx) if default_dependency_rule(i, str(args))]\n",
    "\n",
    "\n",
    "class Task(TypedDict):\n",
    "    idx: int\n",
    "    tool: BaseTool\n",
    "    args: list\n",
    "    dependencies: Dict[str, list]\n",
    "    thought: Optional[str]\n",
    "\n",
    "\n",
    "def instantiate_task(\n",
    "    tools: Sequence[BaseTool],\n",
    "    idx: int,\n",
    "    tool_name: str,\n",
    "    args: Union[str, Any],\n",
    "    thought: Optional[str] = None,\n",
    ") -> Task:\n",
    "    if tool_name == \"join\":\n",
    "        tool = \"join\"\n",
    "    else:\n",
    "        try:\n",
    "            tool = tools[[tool.name for tool in tools].index(tool_name)]\n",
    "        except ValueError as e:\n",
    "            raise OutputParserException(f\"Tool {tool_name} not found.\") from e\n",
    "    tool_args = _parse_llm_compiler_action_args(args, tool)\n",
    "    dependencies = _get_dependencies_from_graph(idx, tool_name, tool_args)\n",
    "\n",
    "    return Task(\n",
    "        idx=idx,\n",
    "        tool=tool,\n",
    "        args=tool_args,\n",
    "        dependencies=dependencies,\n",
    "        thought=thought,\n",
    "    )\n",
    "\n",
    "\n",
    "class LLMCompilerPlanParser(BaseTransformOutputParser[dict], extra=\"allow\"):\n",
    "    \"\"\"Planning output parser.\"\"\"\n",
    "\n",
    "    tools: List[BaseTool]\n",
    "\n",
    "    def _transform(self, input: Iterator[Union[str, BaseMessage]]) -> Iterator[Task]:\n",
    "        texts = []\n",
    "        # TODO: Cleanup tuple state tracking here.\n",
    "        thought = None\n",
    "        for chunk in input:\n",
    "            # Assume input is str. TODO: support vision/other formats\n",
    "            text = chunk if isinstance(chunk, str) else str(chunk.content)\n",
    "            for task, thought in self.ingest_token(text, texts, thought):\n",
    "                yield task\n",
    "        # Final possible task\n",
    "        if texts:\n",
    "            task, _ = self._parse_task(\"\".join(texts), thought)\n",
    "            if task:\n",
    "                yield task\n",
    "\n",
    "    def parse(self, text: str) -> List[Task]:\n",
    "        return list(self._transform([text]))\n",
    "\n",
    "    def stream(\n",
    "        self,\n",
    "        input: str | BaseMessage,\n",
    "        config: RunnableConfig | None = None,\n",
    "        **kwargs: Any | None,\n",
    "    ) -> Iterator[Task]:\n",
    "        yield from self.transform([input], config, **kwargs)\n",
    "\n",
    "    def ingest_token(\n",
    "        self, token: str, buffer: List[str], thought: Optional[str]\n",
    "    ) -> Iterator[Tuple[Optional[Task], str]]:\n",
    "        buffer.append(token)\n",
    "        if \"\\n\" in token:\n",
    "            buffer_ = \"\".join(buffer).split(\"\\n\")\n",
    "            suffix = buffer_[-1]\n",
    "            for line in buffer_[:-1]:\n",
    "                task, thought = self._parse_task(line, thought)\n",
    "                if task:\n",
    "                    yield task, thought\n",
    "            buffer.clear()\n",
    "            buffer.append(suffix)\n",
    "\n",
    "    def _parse_task(self, line: str, thought: Optional[str] = None):\n",
    "        task = None\n",
    "        if match := re.match(THOUGHT_PATTERN, line):\n",
    "            # Optionally, action can be preceded by a thought\n",
    "            thought = match.group(1)\n",
    "        elif match := re.match(ACTION_PATTERN, line):\n",
    "            # if action is parsed, return the task, and clear the buffer\n",
    "            idx, tool_name, args, _ = match.groups()\n",
    "            idx = int(idx)\n",
    "            task = instantiate_task(\n",
    "                tools=self.tools,\n",
    "                idx=idx,\n",
    "                tool_name=tool_name,\n",
    "                args=args,\n",
    "                thought=thought,\n",
    "            )\n",
    "            thought = None\n",
    "        # Else it is just dropped\n",
    "        return task, thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following \u001b[33;1m\u001b[1;3m{num_tools}\u001b[0m types:\n",
      "\u001b[33;1m\u001b[1;3m{tool_descriptions}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{num_tools}\u001b[0m. join(): Collects and combines results from prior actions.\n",
      "\n",
      " - An LLM agent is called upon invoking join() to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{messages}\u001b[0m\n",
      "\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Remember, ONLY respond with the task list in the correct format! E.g.:\n",
      "idx. tool(arg_name=args)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = hub.pull(\"wfh/llm-compiler\")\n",
    "print(prompt.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_planner(\n",
    "    llm: BaseChatModel, tools: Sequence[BaseTool], base_prompt: ChatPromptTemplate\n",
    "):\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"{i+1}. {tool.description}\\n\"\n",
    "        for i, tool in enumerate(\n",
    "            tools\n",
    "        )  # +1 to offset the 0 starting index, we want it count normally from 1.\n",
    "    )\n",
    "    planner_prompt = base_prompt.partial(\n",
    "        replan=\"\",\n",
    "        num_tools=len(tools)\n",
    "        + 1,  # Add one because we're adding the join() tool at the end.\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "    replanner_prompt = base_prompt.partial(\n",
    "        replan=' - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results '\n",
    "        \"(given as Observation) of each plan and a general thought (given as Thought) about the executed results.\"\n",
    "        'You MUST use these information to create the next plan under \"Current Plan\".\\n'\n",
    "        ' - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\\n'\n",
    "        \" - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\\n\"\n",
    "        \" - You must continue the task index from the end of the previous one. Do not repeat task indices.\",\n",
    "        num_tools=len(tools) + 1,\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "\n",
    "    def should_replan(state: list):\n",
    "        # Context is passed as a system message\n",
    "        return isinstance(state[-1], SystemMessage)\n",
    "\n",
    "    def wrap_messages(state: list):\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    def wrap_and_get_last_index(state: list):\n",
    "        next_task = 0\n",
    "        for message in state[::-1]:\n",
    "            if isinstance(message, FunctionMessage):\n",
    "                next_task = message.additional_kwargs[\"idx\"] + 1\n",
    "                break\n",
    "        state[-1].content = state[-1].content + f\" - Begin counting at : {next_task}\"\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    return (\n",
    "        RunnableBranch(\n",
    "            (should_replan, wrap_and_get_last_index | replanner_prompt),\n",
    "            wrap_messages | planner_prompt,\n",
    "        )\n",
    "        | llm\n",
    "        | LLMCompilerPlanParser(tools=tools)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# This is the primary \"agent\" in our application\n",
    "planner = create_planner(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TavilySearchResults(description='tavily_search_results_json(query=\"the search query\") - a search engine.', max_results=1, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))\n",
      "---\n",
      "'join'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "example_question = \"What's the temperature in SF raised to the 3rd power?\"\n",
    "\n",
    "for task in planner.stream([HumanMessage(content=example_question)]):\n",
    "    # print(task[\"tool\"], task[\"args\"])\n",
    "    pprint(task['tool'])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Fetching Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from typing import Any, Dict, Iterable, List, Union\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    chain as as_runnable,\n",
    ")\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "def _get_observations(messages: List[BaseMessage]) -> Dict[int, Any]:\n",
    "    # Get all previous tool responses\n",
    "    results = {}\n",
    "    for message in messages[::-1]:\n",
    "        if isinstance(message, FunctionMessage):\n",
    "            results[int(message.additional_kwargs[\"idx\"])] = message.content\n",
    "    return results\n",
    "\n",
    "\n",
    "class SchedulerInput(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    tasks: Iterable[Task]\n",
    "\n",
    "\n",
    "def _execute_task(task, observations, config):\n",
    "    tool_to_use = task[\"tool\"]\n",
    "    if isinstance(tool_to_use, str):\n",
    "        return tool_to_use\n",
    "    args = task[\"args\"]\n",
    "    try:\n",
    "        if isinstance(args, str):\n",
    "            resolved_args = _resolve_arg(args, observations)\n",
    "        elif isinstance(args, dict):\n",
    "            resolved_args = {\n",
    "                key: _resolve_arg(val, observations) for key, val in args.items()\n",
    "            }\n",
    "        else:\n",
    "            # This will likely fail\n",
    "            resolved_args = args\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.)\"\n",
    "            f\" Args could not be resolved. Error: {repr(e)}\"\n",
    "        )\n",
    "    try:\n",
    "        return tool_to_use.invoke(resolved_args, config)\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.\"\n",
    "            + f\" Args resolved to {resolved_args}. Error: {repr(e)})\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _resolve_arg(arg: Union[str, Any], observations: Dict[int, Any]):\n",
    "    # $1 or ${1} -> 1\n",
    "    ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
    "\n",
    "    def replace_match(match):\n",
    "        # If the string is ${123}, match.group(0) is ${123}, and match.group(1) is 123.\n",
    "\n",
    "        # Return the match group, in this case the index, from the string. This is the index\n",
    "        # number we get back.\n",
    "        idx = int(match.group(1))\n",
    "        return str(observations.get(idx, match.group(0)))\n",
    "\n",
    "    # For dependencies on other tasks\n",
    "    if isinstance(arg, str):\n",
    "        return re.sub(ID_PATTERN, replace_match, arg)\n",
    "    elif isinstance(arg, list):\n",
    "        return [_resolve_arg(a, observations) for a in arg]\n",
    "    else:\n",
    "        return str(arg)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_task(task_inputs, config):\n",
    "    task: Task = task_inputs[\"task\"]\n",
    "    observations: Dict[int, Any] = task_inputs[\"observations\"]\n",
    "    try:\n",
    "        observation = _execute_task(task, observations, config)\n",
    "    except Exception:\n",
    "        import traceback\n",
    "\n",
    "        observation = traceback.format_exception()  # repr(e) +\n",
    "    observations[task[\"idx\"]] = observation\n",
    "\n",
    "\n",
    "def schedule_pending_task(\n",
    "    task: Task, observations: Dict[int, Any], retry_after: float = 0.2\n",
    "):\n",
    "    while True:\n",
    "        deps = task[\"dependencies\"]\n",
    "        if deps and (any([dep not in observations for dep in deps])):\n",
    "            # Dependencies not yet satisfied\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        schedule_task.invoke({\"task\": task, \"observations\": observations})\n",
    "        break\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_tasks(scheduler_input: SchedulerInput) -> List[FunctionMessage]:\n",
    "    \"\"\"Group the tasks into a DAG schedule.\"\"\"\n",
    "    # For streaming, we are making a few simplifying assumption:\n",
    "    # 1. The LLM does not create cyclic dependencies\n",
    "    # 2. That the LLM will not generate tasks with future deps\n",
    "    # If this ceases to be a good assumption, you can either\n",
    "    # adjust to do a proper topological sort (not-stream)\n",
    "    # or use a more complicated data structure\n",
    "    tasks = scheduler_input[\"tasks\"]\n",
    "    args_for_tasks = {}\n",
    "    messages = scheduler_input[\"messages\"]\n",
    "    # If we are re-planning, we may have calls that depend on previous\n",
    "    # plans. Start with those.\n",
    "    observations = _get_observations(messages)\n",
    "    task_names = {}\n",
    "    originals = set(observations)\n",
    "    # ^^ We assume each task inserts a different key above to\n",
    "    # avoid race conditions...\n",
    "    futures = []\n",
    "    retry_after = 0.25  # Retry every quarter second\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for task in tasks:\n",
    "            deps = task[\"dependencies\"]\n",
    "            task_names[task[\"idx\"]] = (\n",
    "                task[\"tool\"] if isinstance(task[\"tool\"], str) else task[\"tool\"].name\n",
    "            )\n",
    "            args_for_tasks[task[\"idx\"]] = task[\"args\"]\n",
    "            if (\n",
    "                # Depends on other tasks\n",
    "                deps\n",
    "                and (any([dep not in observations for dep in deps]))\n",
    "            ):\n",
    "                futures.append(\n",
    "                    executor.submit(\n",
    "                        schedule_pending_task, task, observations, retry_after\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # No deps or all deps satisfied\n",
    "                # can schedule now\n",
    "                schedule_task.invoke(dict(task=task, observations=observations))\n",
    "                # futures.append(executor.submit(schedule_task.invoke, dict(task=task, observations=observations)))\n",
    "\n",
    "        # All tasks have been submitted or enqueued\n",
    "        # Wait for them to complete\n",
    "        wait(futures)\n",
    "    # Convert observations to new tool messages to add to the state\n",
    "    new_observations = {\n",
    "        k: (task_names[k], args_for_tasks[k], observations[k])\n",
    "        for k in sorted(observations.keys() - originals)\n",
    "    }\n",
    "    tool_messages = [\n",
    "        FunctionMessage(\n",
    "            name=name,\n",
    "            content=str(obs),\n",
    "            additional_kwargs={\"idx\": k, \"args\": task_args},\n",
    "            tool_call_id=k,\n",
    "        )\n",
    "        for k, (name, task_args, obs) in new_observations.items()\n",
    "    ]\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def plan_and_schedule(state):\n",
    "    messages = state[\"messages\"]\n",
    "    tasks = planner.stream(messages)\n",
    "    # Begin executing the planner immediately\n",
    "    try:\n",
    "        tasks = itertools.chain([next(tasks)], tasks)\n",
    "    except StopIteration:\n",
    "        # Handle the case where tasks is empty.\n",
    "        tasks = iter([])\n",
    "    scheduled_tasks = schedule_tasks.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"tasks\": tasks,\n",
    "        }\n",
    "    )\n",
    "    return {\"messages\": scheduled_tasks}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n"
     ]
    }
   ],
   "source": [
    "tool_messages = plan_and_schedule.invoke(\n",
    "    {\"messages\": [HumanMessage(content=example_question)]}\n",
    ")[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionMessage(content=\"[{'url': 'https://www.wunderground.com/weather/us/ca/san-francisco', 'content': 'San Francisco, CA Weather Conditions | Weather Underground San Francisco, CA Weather Conditions_star_rate__home_ 56\\\\xa0°F South of Market Station|Report Report Station You are about to report this weather station for bad data. Personal Weather Station Nearby Weather Stations Nearby Weather Stations The time period when the sun is no more than 6 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 6 and 12 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 12 and 18 degrees below the horizon at either sunrise or sunset. The sun does not contribute to the illumination of the sky before this time in the morning, or after this time in the evening.'}]\", additional_kwargs={'idx': 1, 'args': {'query': 'current temperature in San Francisco'}}, response_metadata={}, name='tavily_search_results_json', tool_call_id=1),\n",
       " FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, response_metadata={}, name='join', tool_call_id=2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"The final response/answer.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Replan(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"Analysis of the previous attempts and recommendations on what needs to be fixed.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JoinOutputs(BaseModel):\n",
    "    \"\"\"Decide whether to replan or whether you can return the final response.\"\"\"\n",
    "\n",
    "    thought: str = Field(\n",
    "        description=\"The chain of thought reasoning for the selected action\"\n",
    "    )\n",
    "    action: Union[FinalResponse, Replan]\n",
    "\n",
    "\n",
    "joiner_prompt = hub.pull(\"wfh/llm-compiler-joiner\").partial(\n",
    "    examples=\"\"\n",
    ")  # You can optionally add examples\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "runnable = joiner_prompt | llm.with_structured_output(\n",
    "    JoinOutputs, method=\"function_calling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_joiner_output(decision: JoinOutputs) -> List[BaseMessage]:\n",
    "    response = [AIMessage(content=f\"Thought: {decision.thought}\")]\n",
    "    if isinstance(decision.action, Replan):\n",
    "        return {\n",
    "            \"messages\": response\n",
    "            + [\n",
    "                SystemMessage(\n",
    "                    content=f\"Context from last attempt: {decision.action.feedback}\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        return {\"messages\": response + [AIMessage(content=decision.action.response)]}\n",
    "\n",
    "\n",
    "def select_recent_messages(state) -> dict:\n",
    "    messages = state[\"messages\"]\n",
    "    selected = []\n",
    "    for msg in messages[::-1]:\n",
    "        selected.append(msg)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            break\n",
    "    return {\"messages\": selected[::-1]}\n",
    "\n",
    "\n",
    "joiner = select_recent_messages | runnable | _parse_joiner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [HumanMessage(content=example_question)] + tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"Thought: The temperature in San Francisco is reported as 56°F. To answer the user's question, this value needs to be raised to the 3rd power.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The temperature in San Francisco, raised to the 3rd power, is 56^3 = 175,616°F.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joiner.invoke({\"messages\": input_messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 1.  Define vertices\n",
    "# We defined plan_and_schedule above already\n",
    "# Assign each node to a state variable to update\n",
    "graph_builder.add_node(\"plan_and_schedule\", plan_and_schedule)\n",
    "graph_builder.add_node(\"join\", joiner)\n",
    "\n",
    "\n",
    "## Define edges\n",
    "graph_builder.add_edge(\"plan_and_schedule\", \"join\")\n",
    "\n",
    "### This condition determines looping logic\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage):\n",
    "        return END\n",
    "    return \"plan_and_schedule\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"join\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "graph_builder.add_edge(START, \"plan_and_schedule\")\n",
    "chain = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "# Visualize the compiled StateGraph as a Mermaid diagram\n",
    "display(\n",
    "    Image(\n",
    "        chain.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': {'messages': [FunctionMessage(content='[{\\'url\\': \\'https://usafacts.org/answers/what-is-the-gross-domestic-product-gdp/state/new-york/\\', \\'content\\': \"What is the gross domestic product (GDP) in New York? What is the gross domestic product (GDP) in New York? Gross domestic product (GDP) measures the value of goods and services a country or state produces — it’s the sum of consumer spending, business investment, government spending, and net exports. As of 2023, the real GDP was $1.8 trillion. Real GDP in New York, adjusted for inflation (chained 2017 dollars) GDP and the economic experience vary by location due to factors like cost of living, population density, workforce education, and the area’s main industries. In 2023, New York\\'s real (that is, inflation-adjusted) GDP per person was 1st out of all 50 states. In 2023, New York ranked 1st in state GDP per person.\"}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York 2023'}}, response_metadata={}, name='tavily_search_results_json', id='90cb062b-899f-4fcd-b171-0419818d07b3', tool_call_id=1), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, response_metadata={}, name='join', id='bc4ab4f7-b1aa-48aa-b1eb-b6badba9cec3', tool_call_id=2)]}}\n",
      "---\n",
      "{'join': {'messages': [AIMessage(content=\"Thought: The information provided clearly states the GDP of New York in 2023, which is $1.8 trillion. This is sufficient to answer the user's question.\", additional_kwargs={}, response_metadata={}, id='91e96c08-6979-4abf-a50d-711f5cc9bed8'), AIMessage(content='The GDP of New York in 2023 is $1.8 trillion.', additional_kwargs={}, response_metadata={}, id='65b33cb0-e410-4833-bb47-69da80ec7e3f')]}}\n",
      "---\n",
      "The GDP of New York in 2023 is $1.8 trillion.\n"
     ]
    }
   ],
   "source": [
    "for step in chain.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"What's the GDP of New York?\")]}\n",
    "):\n",
    "    print(step)\n",
    "    print(\"---\")\n",
    "\n",
    "# Final answer\n",
    "print(step[\"join\"][\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-hop question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': {'messages': [FunctionMessage(content=\"[{'url': 'https://www.reptileknowledge.com/reptile-pedia/what-is-the-oldest-living-bird-in-2023', 'content': 'What is the longest living pet bird? In general, the smaller the bird, the shorter its lifespan. The smaller psittacines, like budgies, parakeets, and cockatiels, generally only live 8-15 years, while the larger birds, like macaws and grey parrots, can live 25-50 years. The oldest known parrot was a cockatoo, at least 82 years old at its death. Takedown request View complete answer on'}]\", additional_kwargs={'idx': 1, 'args': {'query': 'oldest parrot alive 2023'}}, response_metadata={}, name='tavily_search_results_json', id='b6e06cec-056a-4e03-b66a-6910f02061a2', tool_call_id=1), FunctionMessage(content=\"[{'url': 'https://www.herebird.com/how-long-do-parrots-live/', 'content': 'Discover the average lifespan of a parrot from our research into 64 parrot lifespans. Plus uncover the reason why do parrots live so long. ... The average life expectancy for conures can range from 10 to 30 years. They come with relatively long tails and need lots of attention. Their natural habitat is in the Western Hemisphere, in particular'}]\", additional_kwargs={'idx': 2, 'args': {'query': 'average lifespan of a parrot'}}, response_metadata={}, name='tavily_search_results_json', id='cfdf049f-8f36-426e-9e50-db993f80161a', tool_call_id=2), FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, response_metadata={}, name='join', id='09539847-09bd-4d73-8286-49b71210cc5f', tool_call_id=3)]}}\n",
      "---\n",
      "{'join': {'messages': [AIMessage(content=\"Thought: The information needed to answer the user's question is partially found. The oldest known parrot was a cockatoo, at least 82 years old at its death. However, the average lifespan of parrots provided does not specify a single number but a range for a specific type (conures, 10 to 30 years), which may not accurately represent the average lifespan of all parrot species.\", additional_kwargs={}, response_metadata={}, id='a3e5f499-c408-438c-ad73-9825c21dab56'), SystemMessage(content='Context from last attempt: The information found provides the age of the oldest known parrot but does not give a clear average lifespan for parrots in general, only for a specific type (conures). A more comprehensive average lifespan across different parrot species would be needed to accurately answer how much longer the oldest parrot lived compared to the average.', additional_kwargs={}, response_metadata={}, id='a6bcceb7-d440-4e19-9827-7a0418f2b42f')]}}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': {'messages': [FunctionMessage(content=\"[{'url': 'https://pets.thenest.com/average-lifespan-parrots-6518.html', 'content': 'African grey parrots, which are renowned for their speaking ability, have a lifespan of about 40 years, and some African greys live beyond the age of 60. Amazon parrots, which include yellow-headed and blue-fronted Amazons, have an average lifespan between 25 and 50 years. Macaws also have an average lifespan of 25 to 50 years.'}]\", additional_kwargs={'idx': 4, 'args': {'query': 'average lifespan of parrots'}}, response_metadata={}, name='tavily_search_results_json', id='d4cff0fa-ad9c-47d6-9452-a21fd03893d8', tool_call_id=4), FunctionMessage(content='join', additional_kwargs={'idx': 5, 'args': ()}, response_metadata={}, name='join', id='4058511d-4f16-4616-8359-f6d0a10fcf37', tool_call_id=5)]}}\n",
      "---\n",
      "{'join': {'messages': [AIMessage(content=\"Thought: The information now includes specific lifespan data for several parrot species, including African grey parrots (40-60 years), Amazon parrots (25-50 years), and Macaws (25-50 years). This data, combined with the age of the oldest known parrot (a cockatoo at least 82 years old), allows us to answer the question. However, it doesn't directly state a single 'average' lifespan for all parrots, but we can use the provided lifespan ranges to estimate a general average.\", additional_kwargs={}, response_metadata={}, id='6a1ac580-669f-419d-9451-239ba06442a9'), AIMessage(content='The oldest known parrot was a cockatoo, at least 82 years old at its death. While specific lifespan data varies by species—African grey parrots can live 40-60 years, Amazon parrots and Macaws 25-50 years—these figures suggest that the oldest parrot lived significantly longer than the average lifespan of various parrot species, which ranges broadly from 25 to 60 years depending on the species. Thus, the oldest parrot lived at least 22 years longer than the higher end of the average lifespan for many parrot species.', additional_kwargs={}, response_metadata={}, id='8aa083d2-27b9-4da8-a75d-508dacfe0fcc')]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "steps = chain.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"What's the oldest parrot alive, and how much longer is that than the average?\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"recursion_limit\": 100,\n",
    "    },\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oldest known parrot was a cockatoo, at least 82 years old at its death. While specific lifespan data varies by species—African grey parrots can live 40-60 years, Amazon parrots and Macaws 25-50 years—these figures suggest that the oldest parrot lived significantly longer than the average lifespan of various parrot species, which ranges broadly from 25 to 60 years depending on the species. Thus, the oldest parrot lived at least 22 years longer than the higher end of the average lifespan for many parrot species.\n"
     ]
    }
   ],
   "source": [
    "# Final answer\n",
    "print(step[\"join\"][\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n",
      "Failed to use model_dump to serialize <class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': {'messages': [FunctionMessage(content='[{\\'url\\': \\'https://www.financecharts.com/stocks/MSFT/summary/market-cap\\', \\'content\\': \"The current market cap or net worth for Microsoft (MSFT) stock is $3.178T as of Tuesday, January 21 2025. It\\'s decreased by 1.80% over the past 30 days. MSFT has improved its market cap by 7.84% over the past 12 months.\"}]', additional_kwargs={'idx': 1, 'args': {'query': 'Microsoft current market cap 2023'}}, response_metadata={}, name='tavily_search_results_json', id='8600fad5-05bf-4d09-a60c-e3e996c675e2', tool_call_id=1),\n",
      "                                    FunctionMessage(content=\"[{'url': 'https://www.statmuse.com/money/ask/apple-market-cap-in-2023', 'content': 'On December 29, Apple (AAPL) had a market capitalization of $3T, based on 15.58B shares at a price of $191.80.'}]\", additional_kwargs={'idx': 2, 'args': {'query': 'Apple current market cap 2023'}}, response_metadata={}, name='tavily_search_results_json', id='7e5b78aa-5051-4bda-b059-983eb00add23', tool_call_id=2),\n",
      "                                    FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, response_metadata={}, name='join', id='ac6bda19-9342-46ba-a9dd-685163d56edc', tool_call_id=3)]}}\n",
      "{'join': {'messages': [AIMessage(content=\"Thought: The task requires calculating the difference in market capitalization between Microsoft and Apple to determine how much Microsoft's market cap needs to increase to exceed Apple's. The market cap for Microsoft is $3.178T and for Apple is $3T. With this information, we can compute the required increase.\", additional_kwargs={}, response_metadata={}, id='0f1670e1-8f05-49c9-a992-0958dd804255'),\n",
      "                       AIMessage(content=\"Microsoft's market cap needs to increase by $178 billion to exceed Apple's market cap, since Microsoft's current market cap is $3.178T and Apple's is $3T.\", additional_kwargs={}, response_metadata={}, id='694733ba-c238-4402-bcaf-f86921a0317d')]}}\n"
     ]
    }
   ],
   "source": [
    "for step in chain.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    pprint(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "\n",
    "from typing import List, TypedDict, Optional\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class Step(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents a step taken in the research process.\n",
    "    \"\"\"\n",
    "\n",
    "    id: str\n",
    "    description: str\n",
    "    status: str\n",
    "    type: str\n",
    "    description: str\n",
    "    search_result: Optional[str]\n",
    "    result: Optional[str]\n",
    "    updates: Optional[List[str]]\n",
    "\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    This is the state of the agent.\n",
    "    It is a subclass of the MessagesState class from langgraph.\n",
    "    \"\"\"\n",
    "\n",
    "    model: str = \"openai\"\n",
    "    steps: List[Step]\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "from typing import List, Optional, Any, Union, Dict, Callable\n",
    "import asyncio\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.callbacks.manager import adispatch_custom_event\n",
    "from typing import TypedDict\n",
    "from enum import Enum\n",
    "from typing_extensions import NotRequired\n",
    "\n",
    "\n",
    "class IntermediateStateConfig(TypedDict):\n",
    "    \"\"\"Intermediate state config\"\"\"\n",
    "\n",
    "    state_key: str\n",
    "    tool: str\n",
    "    tool_argument: NotRequired[str]\n",
    "\n",
    "\n",
    "def copilotkit_customize_config(\n",
    "    base_config: Optional[RunnableConfig] = None,\n",
    "    *,\n",
    "    emit_tool_calls: Optional[Union[bool, str, List[str]]] = None,\n",
    "    emit_messages: Optional[bool] = None,\n",
    "    emit_all: Optional[bool] = None,\n",
    "    emit_intermediate_state: Optional[List[IntermediateStateConfig]] = None\n",
    ") -> RunnableConfig:\n",
    "    \"\"\"\n",
    "    Configure for LangChain for use in CopilotKit\n",
    "    \"\"\"\n",
    "    metadata = base_config.get(\"metadata\", {}) if base_config else {}\n",
    "\n",
    "    if emit_all is True:\n",
    "        metadata[\"copilotkit:emit-tool-calls\"] = True\n",
    "        metadata[\"copilotkit:emit-messages\"] = True\n",
    "    else:\n",
    "        if emit_tool_calls is not None:\n",
    "            metadata[\"copilotkit:emit-tool-calls\"] = emit_tool_calls\n",
    "        if emit_messages is not None:\n",
    "            metadata[\"copilotkit:emit-messages\"] = emit_messages\n",
    "\n",
    "    if emit_intermediate_state:\n",
    "        metadata[\"copilotkit:emit-intermediate-state\"] = emit_intermediate_state\n",
    "\n",
    "    base_config = base_config or {}\n",
    "\n",
    "    return {**base_config, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "\n",
    "def get_model(state: AgentState) -> BaseChatModel:\n",
    "    \"\"\"\n",
    "    Get a model based on the environment variable.\n",
    "    \"\"\"\n",
    "    model = state.get(\"model\")\n",
    "\n",
    "    if model == \"openai\":\n",
    "        from langchain_openai import (\n",
    "            ChatOpenAI,\n",
    "        )  # pylint: disable=import-outside-toplevel\n",
    "\n",
    "        return ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    if model == \"anthropic\":\n",
    "        from langchain_anthropic import (\n",
    "            ChatAnthropic,\n",
    "        )  # pylint: disable=import-outside-toplevel\n",
    "\n",
    "        return ChatAnthropic(temperature=0, model=\"claude-3-5-sonnet-20240620\")\n",
    "    if model == \"google_genai\":\n",
    "        from langchain_google_genai import (\n",
    "            ChatGoogleGenerativeAI,\n",
    "        )  # pylint: disable=import-outside-toplevel\n",
    "\n",
    "        return ChatGoogleGenerativeAI(temperature=0, model=\"gemini-1.5-pro\")\n",
    "\n",
    "    raise ValueError(\"Invalid model specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class SearchStep(BaseModel):\n",
    "    \"\"\"Model for a search step\"\"\"\n",
    "\n",
    "    id: str = Field(\n",
    "        description=\"The id of the step. This is used to identify the step in the state. Just make sure it is unique.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description='The description of the step, i.e. \"search for information about the latest AI news\"'\n",
    "    )\n",
    "    status: str = Field(\n",
    "        description='The status of the step. Always \"pending\".', enum=[\"pending\"]\n",
    "    )\n",
    "    type: str = Field(description=\"The type of step.\", enum=[\"search\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "def SearchTool(steps: List[SearchStep]):  # pylint: disable=invalid-name,unused-argument\n",
    "    \"\"\"\n",
    "    Break the user's query into smaller steps.\n",
    "    Use step type \"search\" to search the web for information.\n",
    "    Make sure to add all the steps needed to answer the user's query.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "async def steps_node(state: AgentState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    The steps node is responsible for building the steps in the research process.\n",
    "    \"\"\"\n",
    "\n",
    "    config = copilotkit_customize_config(\n",
    "        config,\n",
    "        emit_intermediate_state=[\n",
    "            {\"state_key\": \"steps\", \"tool\": \"SearchTool\", \"tool_argument\": \"steps\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    instructions = f\"\"\"\n",
    "You are a search assistant. Your task is to help the user with complex search queries by breaking the down into smaller steps.\n",
    "\n",
    "These steps are then executed serially. In the end, a final answer is produced in markdown format.\n",
    "\n",
    "The current date is {datetime.now().strftime(\"%Y-%m-%d\")}.\n",
    "\"\"\"\n",
    "\n",
    "    response = (\n",
    "        await get_model(state)\n",
    "        .bind_tools([SearchTool], tool_choice=\"SearchTool\")\n",
    "        .ainvoke(\n",
    "            [\n",
    "                state[\"messages\"][0],\n",
    "                HumanMessage(content=instructions),\n",
    "            ],\n",
    "            config,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if len(response.tool_calls) == 0:\n",
    "        steps = []\n",
    "    else:\n",
    "        steps = response.tool_calls[0][\"args\"][\"steps\"]\n",
    "\n",
    "    if len(steps) != 0:\n",
    "        steps[0][\"updates\"] = [\"Searching the web...\"]\n",
    "\n",
    "    return {\n",
    "        \"steps\": steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "\n",
    "async def search_node(state: AgentState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    The search node is responsible for searching the internet for information.\n",
    "    \"\"\"\n",
    "    tavily_tool = TavilySearchResults(\n",
    "        max_results=3,\n",
    "        search_depth=\"advanced\",\n",
    "        include_answer=True,\n",
    "        include_raw_content=True,\n",
    "        include_images=True,\n",
    "    )\n",
    "\n",
    "    current_step = next(\n",
    "        (step for step in state[\"steps\"] if step[\"status\"] == \"pending\"), None\n",
    "    )\n",
    "\n",
    "    if current_step is None:\n",
    "        raise ValueError(\"No step to search for\")\n",
    "\n",
    "    if current_step[\"type\"] != \"search\":\n",
    "        raise ValueError(\"Current step is not a search step\")\n",
    "\n",
    "    instructions = f\"\"\"\n",
    "This is a step in a series of steps that are being executed to answer the user's query.\n",
    "These are all of the steps: {json.dumps(state[\"steps\"])}\n",
    "\n",
    "You are responsible for carrying out the step: {json.dumps(current_step)}\n",
    "\n",
    "The current date is {datetime.now().strftime(\"%Y-%m-%d\")}.\n",
    "\n",
    "This is what you need to search for, please come up with a good search query: {current_step[\"description\"]}\n",
    "\"\"\"\n",
    "    model = get_model(state).bind_tools([tavily_tool], tool_choice=tavily_tool.name)\n",
    "\n",
    "    response = await model.ainvoke([HumanMessage(content=instructions)], config)\n",
    "\n",
    "    tool_msg = tavily_tool.invoke(response.tool_calls[0])\n",
    "\n",
    "    current_step[\"search_result\"] = json.loads(tool_msg.content)\n",
    "    current_step[\"updates\"] = [*current_step[\"updates\"], \"Extracting information...\"]\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "async def extract_node(state: AgentState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    The extract node is responsible for extracting information from a tavily search.\n",
    "    \"\"\"\n",
    "\n",
    "    current_step = next(\n",
    "        (step for step in state[\"steps\"] if step[\"status\"] == \"pending\"), None\n",
    "    )\n",
    "\n",
    "    if current_step is None:\n",
    "        raise ValueError(\"No current step\")\n",
    "\n",
    "    if current_step[\"type\"] != \"search\":\n",
    "        raise ValueError(\"Current step is not of type search\")\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "This step was just executed: {json.dumps(current_step)}\n",
    "\n",
    "This is the result of the search:\n",
    "\n",
    "Please summarize ONLY the result of the search and include all relevant information from the search and reference links.\n",
    "DO NOT INCLUDE ANY EXTRA INFORMATION. ALL OF THE INFORMATION YOU ARE LOOKING FOR IS IN THE SEARCH RESULTS.\n",
    "\n",
    "DO NOT answer the user's query yet. Just summarize the search results.\n",
    "\n",
    "Use markdown formatting and put the references inline and the links at the end.\n",
    "Like this:\n",
    "This is a sentence with a reference to a source [source 1][1] and another reference [source 2][2].\n",
    "[1]: http://example.com/source1 \"Title of Source 1\"\n",
    "[2]: http://example.com/source2 \"Title of Source 2\"\n",
    "\"\"\"\n",
    "\n",
    "    response = await get_model(state).ainvoke(\n",
    "        [state[\"messages\"][0], HumanMessage(content=system_message)], config\n",
    "    )\n",
    "\n",
    "    current_step[\"result\"] = response.content\n",
    "    current_step[\"search_result\"] = None\n",
    "    current_step[\"status\"] = \"complete\"\n",
    "    current_step[\"updates\"] = [*current_step[\"updates\"], \"Done.\"]\n",
    "\n",
    "    next_step = next(\n",
    "        (step for step in state[\"steps\"] if step[\"status\"] == \"pending\"), None\n",
    "    )\n",
    "    if next_step:\n",
    "        next_step[\"updates\"] = [\"Searching the web...\"]\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Reference(BaseModel):\n",
    "    \"\"\"Model for a reference\"\"\"\n",
    "\n",
    "    title: str = Field(description=\"The title of the reference.\")\n",
    "    url: str = Field(description=\"The url of the reference.\")\n",
    "\n",
    "\n",
    "class SummarizeInput(BaseModel):\n",
    "    \"\"\"Input for the summarize tool\"\"\"\n",
    "\n",
    "    markdown: str = Field(\n",
    "        description=\"\"\"\n",
    "                          The markdown formatted summary of the final result.\n",
    "                          If you add any headings, make sure to start at the top level (#).\n",
    "                          \"\"\"\n",
    "    )\n",
    "    references: list[Reference] = Field(description=\"A list of references.\")\n",
    "\n",
    "\n",
    "@tool(args_schema=SummarizeInput)\n",
    "def SummarizeTool(\n",
    "    summary: str, references: list[Reference]\n",
    "):  # pylint: disable=invalid-name,unused-argument\n",
    "    \"\"\"\n",
    "    Summarize the final result. Make sure that the summary is complete and\n",
    "    includes all relevant information and reference links.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "async def summarize_node(state: AgentState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    The summarize node is responsible for summarizing the information.\n",
    "    \"\"\"\n",
    "\n",
    "    config = copilotkit_customize_config(\n",
    "        config,\n",
    "        emit_intermediate_state=[\n",
    "            {\n",
    "                \"state_key\": \"answer\",\n",
    "                \"tool\": \"SummarizeTool\",\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "The system has performed a series of steps to answer the user's query.\n",
    "These are all of the steps: {json.dumps(state[\"steps\"])}\n",
    "\n",
    "Please summarize the final result and include all relevant information and reference links.\n",
    "\"\"\"\n",
    "\n",
    "    response = (\n",
    "        await get_model(state)\n",
    "        .bind_tools([SummarizeTool], tool_choice=\"SummarizeTool\")\n",
    "        .ainvoke(\n",
    "            [\n",
    "                HumanMessage(content=system_message),\n",
    "            ],\n",
    "            config,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"answer\": response.tool_calls[0][\"args\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "def route(state):\n",
    "    \"\"\"Route to research nodes.\"\"\"\n",
    "    if not state.get(\"steps\", None):\n",
    "        return END\n",
    "\n",
    "    current_step = next(\n",
    "        (step for step in state[\"steps\"] if step[\"status\"] == \"pending\"), None\n",
    "    )\n",
    "\n",
    "    if not current_step:\n",
    "        return \"summarize_node\"\n",
    "\n",
    "    if current_step[\"type\"] == \"search\":\n",
    "        return \"search_node\"\n",
    "\n",
    "    raise ValueError(f\"Unknown step type: {current_step['type']}\")\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"steps_node\", steps_node)\n",
    "workflow.add_node(\"search_node\", search_node)\n",
    "workflow.add_node(\"summarize_node\", summarize_node)\n",
    "workflow.add_node(\"extract_node\", extract_node)\n",
    "# Chatbot\n",
    "workflow.set_entry_point(\"steps_node\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"steps_node\", route, [\"summarize_node\", \"search_node\", END]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"search_node\", \"extract_node\")\n",
    "\n",
    "workflow.add_conditional_edges(\"extract_node\", route, [\"summarize_node\", \"search_node\"])\n",
    "\n",
    "workflow.add_edge(\"summarize_node\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "# # Visualize the compiled StateGraph as a Mermaid diagram\n",
    "# display(\n",
    "#     Image(\n",
    "#         graph.get_graph().draw_mermaid_png(\n",
    "#             draw_method=MermaidDrawMethod.API,\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'pending', 'type': 'search', 'updates': ['Searching the web...']}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'pending', 'type': 'search'}], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'pending', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...'], 'search_result': [{'url': 'https://www.financecharts.com/stocks/MSFT/summary/market-cap', 'content': \"The current market cap or net worth for Microsoft (MSFT) stock is $3.178T as of Tuesday, January 21 2025. It's decreased by 1.80% over the past 30 days. MSFT has improved its market cap by 7.84% over the past 12 months.\"}, {'url': 'https://tradingeconomics.com/msft:us:market-capitalization', 'content': 'Microsoft reported $3.17T in Market Capitalization this January of 2025, considering the latest stock price and the number of outstanding shares.Data for Microsoft | MSFT - Market Capitalization including historical, tables and charts were last updated by Trading Economics this last January in 2025.'}, {'url': 'https://stockanalysis.com/stocks/msft/market-cap/', 'content': \"Microsoft (MSFT) Market Cap & Net Worth - Stock Analysis Stocks Stock Screener Top Stocks IPOs IPO Statistics IPO News Market Newsletter Market Cap Microsoft Market Cap Microsoft has a market cap or net worth of $3.10 trillion as of November 18, 2024. Its market cap has increased by 19.60% in one year. Market Cap Market Cap Chart Since December 1, 1998, Microsoft's market cap has increased from $322.92B to $3.10T, an increase of 858.84%. Market Cap History | Date | Market Cap | % Change | Market capitalization, also called net worth, is the total value of all of a company's outstanding shares. Formula: Market Cap = Stock Price * Shares Outstanding | Company | Market Cap | Market Cap Rankings Stocks IPOs Market Newsletter\"}]}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'pending', 'type': 'search'}], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Microsoft (MSFT) is reported to be approximately $3.178 trillion as of January 21, 2025 [source 1][1]. Another source states it as $3.17 trillion for the same date [source 2][2], while a different report mentions a market cap of $3.10 trillion as of November 18, 2024 [source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/MSFT/summary/market-cap \"Market Cap Summary for Microsoft\"\\n[2]: https://tradingeconomics.com/msft:us:market-capitalization \"Microsoft Market Capitalization Data\"\\n[3]: https://stockanalysis.com/stocks/msft/market-cap/ \"Microsoft Market Cap & Net Worth - Stock Analysis\"'}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'pending', 'type': 'search', 'updates': ['Searching the web...']}], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Microsoft (MSFT) is reported to be approximately $3.178 trillion as of January 21, 2025 [source 1][1]. Another source states it as $3.17 trillion for the same date [source 2][2], while a different report mentions a market cap of $3.10 trillion as of November 18, 2024 [source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/MSFT/summary/market-cap \"Market Cap Summary for Microsoft\"\\n[2]: https://tradingeconomics.com/msft:us:market-capitalization \"Microsoft Market Capitalization Data\"\\n[3]: https://stockanalysis.com/stocks/msft/market-cap/ \"Microsoft Market Cap & Net Worth - Stock Analysis\"'}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'pending', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...'], 'search_result': [{'url': 'https://www.financecharts.com/stocks/AAPL/summary/market-cap', 'content': \"The current market cap or net worth for Apple (AAPL) stock is $3.474T as of Friday, January 17 2025. It's decreased by 7.36% over the past 30 days. AAPL has improved its market cap by 22.98% over the past 12 months.\"}, {'url': 'https://companiesmarketcap.com/eur/apple/marketcap/', 'content': \"As of January 2025 Apple has a market cap of €3.362 Trillion. This makes Apple the world's most valuable company according to our data.\"}, {'url': 'https://www.statmuse.com/money/ask/appl-market-cap-in-2025', 'content': 'Today, Apple (AAPL) had a market capitalization of $3.5T, based on 15.53B shares at a price of $223.83.'}]}], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Microsoft (MSFT) is reported to be approximately $3.178 trillion as of January 21, 2025 [source 1][1]. Another source states it as $3.17 trillion for the same date [source 2][2], while a different report mentions a market cap of $3.10 trillion as of November 18, 2024 [source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/MSFT/summary/market-cap \"Market Cap Summary for Microsoft\"\\n[2]: https://tradingeconomics.com/msft:us:market-capitalization \"Microsoft Market Capitalization Data\"\\n[3]: https://stockanalysis.com/stocks/msft/market-cap/ \"Microsoft Market Cap & Net Worth - Stock Analysis\"'}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Apple (AAPL) is approximately $3.5 trillion as of January 2025, based on various sources. This figure reflects a decrease of 7.36% over the past 30 days and an improvement of 22.98% over the past 12 months. The market cap is based on 15.53 billion shares at a price of $223.83 [source 1][1][source 2][2][source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/AAPL/summary/market-cap \"Market Cap Summary for Apple\"\\n[2]: https://companiesmarketcap.com/eur/apple/marketcap/ \"Apple Market Cap Overview\"\\n[3]: https://www.statmuse.com/money/ask/appl-market-cap-in-2025 \"Apple Market Capitalization Data\"'}], 'answer': None}\n",
      "{'messages': [HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='2cc8f7de-8234-45aa-9e77-8224abbe5a56'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='60a23e4c-83dc-48ae-8e2e-44829bf8eabc'), HumanMessage(content='How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?', additional_kwargs={}, response_metadata={}, id='1af7c5d1-dbe6-4749-90c8-addc8ca2147b')], 'model': 'openai', 'steps': [{'id': '1', 'description': 'search for the current market cap of Microsoft', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Microsoft (MSFT) is reported to be approximately $3.178 trillion as of January 21, 2025 [source 1][1]. Another source states it as $3.17 trillion for the same date [source 2][2], while a different report mentions a market cap of $3.10 trillion as of November 18, 2024 [source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/MSFT/summary/market-cap \"Market Cap Summary for Microsoft\"\\n[2]: https://tradingeconomics.com/msft:us:market-capitalization \"Microsoft Market Capitalization Data\"\\n[3]: https://stockanalysis.com/stocks/msft/market-cap/ \"Microsoft Market Cap & Net Worth - Stock Analysis\"'}, {'id': '2', 'description': 'search for the current market cap of Apple', 'status': 'complete', 'type': 'search', 'updates': ['Searching the web...', 'Extracting information...', 'Done.'], 'search_result': None, 'result': 'The current market cap for Apple (AAPL) is approximately $3.5 trillion as of January 2025, based on various sources. This figure reflects a decrease of 7.36% over the past 30 days and an improvement of 22.98% over the past 12 months. The market cap is based on 15.53 billion shares at a price of $223.83 [source 1][1][source 2][2][source 3][3].\\n\\n[1]: https://www.financecharts.com/stocks/AAPL/summary/market-cap \"Market Cap Summary for Apple\"\\n[2]: https://companiesmarketcap.com/eur/apple/marketcap/ \"Apple Market Cap Overview\"\\n[3]: https://www.statmuse.com/money/ask/appl-market-cap-in-2025 \"Apple Market Capitalization Data\"'}], 'answer': {'markdown': '# Current Market Capitalization of Microsoft and Apple\\n\\n## Microsoft (MSFT)\\n- **Market Cap**: Approximately $3.178 trillion as of January 21, 2025.\\n- Other reported figures include:\\n  - $3.17 trillion [source 2]\\n  - $3.10 trillion as of November 18, 2024 [source 3].\\n\\n### References:\\n1. [Market Cap Summary for Microsoft](https://www.financecharts.com/stocks/MSFT/summary/market-cap)\\n2. [Microsoft Market Capitalization Data](https://tradingeconomics.com/msft:us:market-capitalization)\\n3. [Microsoft Market Cap & Net Worth - Stock Analysis](https://stockanalysis.com/stocks/msft/market-cap/)\\n\\n## Apple (AAPL)\\n- **Market Cap**: Approximately $3.5 trillion as of January 2025.\\n- Notable changes:\\n  - Decrease of 7.36% over the past 30 days.\\n  - Improvement of 22.98% over the past 12 months.\\n- Based on 15.53 billion shares at a price of $223.83.\\n\\n### References:\\n1. [Market Cap Summary for Apple](https://www.financecharts.com/stocks/AAPL/summary/market-cap)\\n2. [Apple Market Cap Overview](https://companiesmarketcap.com/eur/apple/marketcap/)\\n3. [Apple Market Capitalization Data](https://www.statmuse.com/money/ask/appl-market-cap-in-2025)', 'references': [{'title': 'Market Cap Summary for Microsoft', 'url': 'https://www.financecharts.com/stocks/MSFT/summary/market-cap'}, {'title': 'Microsoft Market Capitalization Data', 'url': 'https://tradingeconomics.com/msft:us:market-capitalization'}, {'title': 'Microsoft Market Cap & Net Worth - Stock Analysis', 'url': 'https://stockanalysis.com/stocks/msft/market-cap/'}, {'title': 'Market Cap Summary for Apple', 'url': 'https://www.financecharts.com/stocks/AAPL/summary/market-cap'}, {'title': 'Apple Market Cap Overview', 'url': 'https://companiesmarketcap.com/eur/apple/marketcap/'}, {'title': 'Apple Market Capitalization Data', 'url': 'https://www.statmuse.com/money/ask/appl-market-cap-in-2025'}]}}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 1,  # temporary thread ID for testing\n",
    "    },\n",
    "}\n",
    "\n",
    "inputs = AgentState(\n",
    "    model=\"openai\",\n",
    "    messages=[\n",
    "        HumanMessage(\n",
    "            content=\"How much does Microsoft’s market cap need to increase to exceed Apple’s market cap?\"\n",
    "        )\n",
    "    ],\n",
    "    steps=[],\n",
    "    answer=None,\n",
    ")\n",
    "\n",
    "async for chunk in graph.astream(inputs, config=config, stream_mode=\"values\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current Market Capitalization of Microsoft and Apple\n",
      "\n",
      "## Microsoft (MSFT)\n",
      "- **Market Cap**: Approximately $3.178 trillion as of January 21, 2025.\n",
      "- Other reported figures include:\n",
      "  - $3.17 trillion [source 2]\n",
      "  - $3.10 trillion as of November 18, 2024 [source 3].\n",
      "\n",
      "### References:\n",
      "1. [Market Cap Summary for Microsoft](https://www.financecharts.com/stocks/MSFT/summary/market-cap)\n",
      "2. [Microsoft Market Capitalization Data](https://tradingeconomics.com/msft:us:market-capitalization)\n",
      "3. [Microsoft Market Cap & Net Worth - Stock Analysis](https://stockanalysis.com/stocks/msft/market-cap/)\n",
      "\n",
      "## Apple (AAPL)\n",
      "- **Market Cap**: Approximately $3.5 trillion as of January 2025.\n",
      "- Notable changes:\n",
      "  - Decrease of 7.36% over the past 30 days.\n",
      "  - Improvement of 22.98% over the past 12 months.\n",
      "- Based on 15.53 billion shares at a price of $223.83.\n",
      "\n",
      "### References:\n",
      "1. [Market Cap Summary for Apple](https://www.financecharts.com/stocks/AAPL/summary/market-cap)\n",
      "2. [Apple Market Cap Overview](https://companiesmarketcap.com/eur/apple/marketcap/)\n",
      "3. [Apple Market Capitalization Data](https://www.statmuse.com/money/ask/appl-market-cap-in-2025)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"# Current Market Capitalization of Microsoft and Apple\\n\\n## Microsoft (MSFT)\\n- **Market Cap**: Approximately $3.178 trillion as of January 21, 2025.\\n- Other reported figures include:\\n  - $3.17 trillion [source 2]\\n  - $3.10 trillion as of November 18, 2024 [source 3].\\n\\n### References:\\n1. [Market Cap Summary for Microsoft](https://www.financecharts.com/stocks/MSFT/summary/market-cap)\\n2. [Microsoft Market Capitalization Data](https://tradingeconomics.com/msft:us:market-capitalization)\\n3. [Microsoft Market Cap & Net Worth - Stock Analysis](https://stockanalysis.com/stocks/msft/market-cap/)\\n\\n## Apple (AAPL)\\n- **Market Cap**: Approximately $3.5 trillion as of January 2025.\\n- Notable changes:\\n  - Decrease of 7.36% over the past 30 days.\\n  - Improvement of 22.98% over the past 12 months.\\n- Based on 15.53 billion shares at a price of $223.83.\\n\\n### References:\\n1. [Market Cap Summary for Apple](https://www.financecharts.com/stocks/AAPL/summary/market-cap)\\n2. [Apple Market Cap Overview](https://companiesmarketcap.com/eur/apple/marketcap/)\\n3. [Apple Market Capitalization Data](https://www.statmuse.com/money/ask/appl-market-cap-in-2025)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List, Callable, Union\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "import asyncio\n",
    "from typing import Any, Dict, List, Callable\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "\n",
    "async def astream_graph(\n",
    "    graph: CompiledStateGraph,\n",
    "    inputs: Dict[str, Any],\n",
    "    config: RunnableConfig,\n",
    "    node_names: List[str] = [],\n",
    "    callback: Callable[[Dict[str, str]], None] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LangGraph의 실행 결과를 비동기 방식으로 스트리밍하여 출력하는 함수입니다\n",
    "\n",
    "    매개변수:\n",
    "    - graph (CompiledStateGraph): 실행할 컴파일된 LangGraph 객체\n",
    "    - inputs (dict): 그래프에 전달할 입력값 딕셔너리\n",
    "    - config (RunnableConfig): 실행 설정\n",
    "    - node_names (List[str], optional): 출력할 노드 이름 목록 (빈 리스트면 모든 노드 출력)\n",
    "    - callback (Callable[[Dict[str, str]], None], optional): 각 청크 처리를 위한 콜백 함수 (기본값: None)\n",
    "      콜백 함수는 {\"node\": str, \"content\": str} 형태의 딕셔너리를 인자로 받습니다\n",
    "\n",
    "    반환값:\n",
    "    - None: 함수는 스트리밍 결과를 출력만 하고 반환값은 없습니다\n",
    "    \"\"\"\n",
    "    prev_node = \"\"\n",
    "    async for chunk_msg, metadata in graph.astream(\n",
    "        inputs, config, stream_mode=\"messages\"\n",
    "    ):\n",
    "        curr_node = metadata[\"langgraph_node\"]\n",
    "\n",
    "        # node_names가 비어있거나 현재 노드가 node_names에 포함된 경우에만 처리\n",
    "        if not node_names or curr_node in node_names:\n",
    "            if callback:\n",
    "                # 콜백 함수가 있는 경우\n",
    "                callback({\"node\": curr_node, \"content\": chunk_msg.content})\n",
    "            else:\n",
    "                # 콜백이 없는 경우 기본 출력\n",
    "                if curr_node != prev_node:\n",
    "                    print(\"\\n\" + \"=\" * 50)\n",
    "                    print(f\"🔄 Node: \\033[1;36m{curr_node}\\033[0m 🔄\")\n",
    "                    print(\"- \" * 25)\n",
    "                print(chunk_msg.content, end=\"\", flush=True)\n",
    "\n",
    "            prev_node = curr_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'astream_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_opentutorial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stream_graph\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mastream_graph\u001b[49m(graph, inputs, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'astream_graph' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_opentutorial.messages import stream_graph\n",
    "await astream_graph(graph, inputs, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-F0L5SJfm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
