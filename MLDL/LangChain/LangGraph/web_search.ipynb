{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'Nvidia 주가 하락 원인'},\n",
       "  'id': 'call_lZpSuT7Fy08MyDWAV7Ei2AS2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema for structured output\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "\n",
    "class SearchQuries(BaseModel):\n",
    "    search_query: list = Field(\n",
    "        None, description=\"List of Queries that are optimized for web search.\"\n",
    "    )\n",
    "    justification: list = Field(\n",
    "        None, description=\"Why each query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "structured_llm = llm.with_structured_output(SearchQuries)\n",
    "\n",
    "# Invoke the augmented LLM\n",
    "output = structured_llm.invoke(\"How does Calcium CT score relate to high cholesterol?\")\n",
    "\n",
    "\n",
    "# Define a tool\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    ")\n",
    "\n",
    "# Augment the LLM with tools\n",
    "llm_with_tools = llm.bind_tools([tavily_tool])\n",
    "\n",
    "# Invoke the LLM with input that triggers the tool call\n",
    "msg = llm_with_tools.invoke(\n",
    "    \"nvidia 주가 하락의 원인이 된 대상 이름이 뭐야?그리고 그 대상에 대한 정보 알려줘\"\n",
    ")\n",
    "\n",
    "# Get the tool call\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "class SearchQury(BaseModel):\n",
    "    search_query: str = Field(\n",
    "        None, description=\"Query that is optimized for web search.\"\n",
    "    )\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Reference(BaseModel):\n",
    "    \"\"\"Model for a reference\"\"\"\n",
    "\n",
    "    title: str = Field(description=\"The title of the reference.\")\n",
    "    url: str = Field(description=\"The url of the reference.\")\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    search_queries: list[SearchQury]\n",
    "\n",
    "    combined_output: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "\n",
    "\n",
    "# Schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"Sections of the report.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.constants import Send\n",
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str  # Report topic\n",
    "    sections: list[Section]  # List of report sections\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # All workers write to this key in parallel\n",
    "    final_report: str  # Final report\n",
    "\n",
    "\n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"sections\": report_sections.sections}\n",
    "\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    # Generate section\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a report section following the provided name and description. Include no preamble for each section. Use markdown formatting.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}\n",
    "\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # Kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'orchestrator': {'sections': [Section(name='Introduction to LLM Scaling Laws', description='This section will provide an overview of what LLM scaling laws are, their significance in the development of large language models, and a brief history of their discovery and evolution.'), Section(name='Mathematical Foundations', description='Discuss the mathematical theories and principles underlying LLM scaling laws, including key equations and models used to predict the performance of language models based on their size and training data.'), Section(name='Empirical Evidence', description='Present empirical studies and experiments that have validated LLM scaling laws, highlighting specific cases and outcomes that demonstrate the laws in action.'), Section(name='Applications and Implications', description='Analyze how LLM scaling laws impact the design and deployment of language models, including practical applications in AI systems and potential implications for future model development.'), Section(name='Challenges and Limitations', description='Identify the challenges and limitations associated with LLM scaling laws, such as computational costs, energy consumption, and diminishing returns on performance as models scale.'), Section(name='Future Directions', description='Explore potential future research directions in the area of LLM scaling laws, including innovations that could address current limitations and further improve model efficiency.'), Section(name='Conclusion', description='Summarize the key points discussed in the report, reflecting on the importance of LLM scaling laws in the field of AI and their potential to shape future advancements.')]}})\n",
      "('updates', {'llm_call': {'completed_sections': ['## Introduction to LLM Scaling Laws\\n\\nLarge Language Model (LLM) scaling laws are a set of principles that describe how the performance and capabilities of large language models improve as they are scaled in size. These laws provide a theoretical framework for understanding how increasing the number of parameters and the amount of training data in language models leads to enhanced performance in a variety of tasks. The significance of LLM scaling laws lies in their ability to guide researchers and developers in efficiently designing and deploying more powerful language models, thereby pushing the boundaries of what these models can achieve.\\n\\nThe concept of scaling laws was first introduced in the context of neural networks and machine learning as researchers sought to understand the relationship between model size and performance. Initially, scaling laws were applied to relatively simple models, and their implications were limited to specific tasks and datasets. However, with the advent of transformers and the subsequent development of large language models, the scope and applicability of these laws have expanded significantly.\\n\\nThe discovery of LLM scaling laws can be traced back to the early 2010s, with foundational work on neural network scaling. Notably, in 2019, researchers at OpenAI published a seminal paper on scaling laws for neural language models, which demonstrated that the performance of these models followed predictable patterns as they were scaled up in terms of parameters, data, and compute resources. This work laid the groundwork for further exploration into the scalability of language models.\\n\\nAs language models grew in size, from millions to billions of parameters, the understanding of scaling laws evolved. Researchers discovered that certain performance metrics, such as perplexity and accuracy on downstream tasks, improved logarithmically with increases in model scale. These findings have been crucial in the development of state-of-the-art models like GPT-3, which exemplify the practical application of scaling laws in producing highly capable language models.\\n\\nIn conclusion, LLM scaling laws have played a pivotal role in advancing the field of natural language processing by providing a roadmap for building larger and more efficient models. Their discovery and continued refinement have enabled researchers to optimize model architectures and training regimes, ultimately leading to breakthroughs in the capabilities of language models across diverse applications.']}})\n",
      "('updates', {'llm_call': {'completed_sections': ['## Conclusion\\n\\nIn conclusion, this report has explored the significant role of Large Language Model (LLM) scaling laws in the field of artificial intelligence. The scaling laws, which describe how performance metrics such as accuracy and efficiency improve with increased model size, dataset size, and computational power, are pivotal in guiding the development of more advanced AI systems.\\n\\nKey points highlighted in this report include the observation that larger models consistently outperform smaller ones, provided there is sufficient data and compute resources. This scaling behavior underscores the importance of continuing to invest in expanding the datasets and computational capabilities available for training AI models. Moreover, LLM scaling laws have opened new avenues for research, fostering a better understanding of how model capabilities evolve and how to optimize resource allocation during the training process.\\n\\nThe implications of LLM scaling laws extend beyond mere performance improvements. They offer insights into the theoretical underpinnings of AI, helping researchers predict the potential boundaries of model capabilities. This understanding is crucial for setting realistic expectations for AI advancements and for planning long-term research and investment strategies.\\n\\nAs AI continues to integrate into various sectors, driving innovations and efficiencies, the role of LLM scaling laws will only grow in importance. They provide a roadmap for achieving breakthroughs in AI performance, enabling the creation of more intelligent, versatile, and capable systems. The potential of these laws to shape future advancements in AI is vast, promising developments that could redefine the landscape of technology and its applications across industries.\\n\\nBy harnessing the insights offered by LLM scaling laws, the AI community can strategically focus its efforts on areas with the highest potential for impact, ensuring that future advancements are both significant and sustainable. As we look ahead, the continued exploration and application of these scaling laws will be instrumental in unlocking the next wave of AI innovations, driving progress and setting the stage for a future enriched by intelligent technologies.']}})\n",
      "('updates', {'llm_call': {'completed_sections': [\"## Future Directions\\n\\nAs the field of large language models (LLMs) continues to evolve, several promising avenues for future research have emerged that could address existing limitations and enhance model efficiency. These directions not only aim to push the boundaries of what LLMs can achieve but also to make them more accessible and sustainable.\\n\\n### 1. Efficient Training Algorithms\\n\\nDeveloping more efficient training algorithms is crucial for reducing the computational overhead associated with LLMs. Future research could focus on optimizing training processes through techniques such as model sparsification and low-rank factorization. By leveraging these methods, it is possible to achieve similar performance levels with significantly fewer parameters and reduced resource consumption.\\n\\n### 2. Novel Architectures\\n\\nExploring novel neural network architectures may offer pathways to more efficient models. Researchers could investigate architectures that go beyond the traditional transformer models, potentially incorporating elements like recurrent mechanisms or hybrid models that combine the strengths of different neural network types. Such innovations could lead to improvements in both processing speed and accuracy.\\n\\n### 3. Scalability and Distributed Systems\\n\\nAs models grow larger, the need for scalable and efficient distributed training systems becomes apparent. Future directions could include developing more robust frameworks for distributed computing, which would enable faster training times by efficiently utilizing multiple devices. This approach not only ensures scalability but also reduces the environmental impact of training massive models.\\n\\n### 4. Transfer Learning and Adaptation\\n\\nEnhancing the ability of LLMs to transfer and adapt knowledge across different domains could further improve their versatility. Research in this area could focus on meta-learning techniques and continual learning methodologies, enabling models to learn new tasks more efficiently without forgetting previously acquired knowledge. This flexibility would be invaluable in dynamic environments where the model's capabilities need to evolve rapidly.\\n\\n### 5. Interpretability and Explainability\\n\\nImproving the interpretability and explainability of LLMs remains a critical area of research. Future work could explore methods to make the decision-making processes of these models more transparent, thus increasing trust and accountability. Techniques such as attention visualization and feature attribution could be refined to provide clearer insights into model behavior.\\n\\n### 6. Ethical and Responsible AI\\n\\nAddressing ethical considerations and ensuring responsible AI deployment are paramount as LLMs become more integrated into society. Future research could develop frameworks that incorporate fairness, accountability, and transparency into the design and deployment of LLMs. This includes creating models that mitigate biases and ensure equitable outcomes across diverse user groups.\\n\\n### 7. Energy Efficiency\\n\\nReducing the energy footprint of LLMs is crucial for sustainability. Future research could focus on energy-efficient hardware and software solutions, such as leveraging specialized accelerators like TPUs or developing algorithms that optimize power usage. Innovations in this area would contribute to more sustainable AI practices.\\n\\nIn conclusion, the future of LLM scaling laws presents a rich landscape of opportunities for innovation. By addressing current limitations and focusing on efficiency, scalability, and ethical considerations, researchers can unlock the full potential of LLMs, making them more powerful, practical, and responsible tools for the future.\"]}})\n",
      "('updates', {'llm_call': {'completed_sections': [\"## Empirical Evidence\\n\\nIn recent years, the scaling laws for large language models (LLMs) have been rigorously examined and validated through various empirical studies and experiments. These studies have provided critical insights into how performance metrics such as accuracy, generalization, and efficiency improve as models scale in terms of parameters, computational resources, and data.\\n\\n### OpenAI's GPT-3 Scaling Analysis\\n\\nOne of the most notable empirical validations of LLM scaling laws comes from OpenAI's development of GPT-3, which demonstrated a clear correlation between the size of the model and its performance across a wide array of tasks. OpenAI's research showed that as the number of parameters increased from 1.5 billion in GPT-2 to 175 billion in GPT-3, there was a significant improvement in the model's ability to generate coherent and contextually relevant text. The scaling laws predicted that larger models would require less training data to achieve similar performance, a hypothesis confirmed by GPT-3's ability to perform few-shot learning tasks with minimal examples.\\n\\n### DeepMind's Chinchilla Project\\n\\nDeepMind's Chinchilla project further investigated scaling laws by exploring the balance between model size and training data volume. The experiments revealed that for a fixed computational budget, smaller models trained with more data could outperform larger models trained with less data. This finding refined the understanding of scaling laws by emphasizing the importance of data efficiency alongside model size. The Chinchilla project underscored that optimal performance is achieved not merely by increasing model parameters but by aligning model size with the available data scale.\\n\\n### Meta's OPT Models\\n\\nMeta's OPT series of models provided additional empirical evidence supporting scaling laws. The research involved training models ranging from 125 million to 175 billion parameters and measuring their performance on standard benchmarks. The results consistently showed improvements in language understanding and generation as model size increased. The OPT models also highlighted the diminishing returns at extreme scales, aligning with theoretical predictions that suggest a logarithmic relationship between model size and performance gains.\\n\\n### Google's Pathways Language Model (PaLM)\\n\\nGoogle's Pathways Language Model (PaLM) explored the impacts of scaling not just parameter count but also the diversity of data sources. Empirical results from PaLM indicated that scaling models with diverse and high-quality data led to significant improvements in tasks that require reasoning and comprehension. The study validated the premise that scaling laws extend beyond model size, encompassing data diversity and quality as crucial factors for enhancing model capabilities.\\n\\n### Cross-Domain Scaling Studies\\n\\nSeveral cross-domain studies have examined the generalizability of scaling laws beyond language modeling. For instance, experiments in vision-language models demonstrated that scaling principles apply similarly, with larger models achieving better performance in tasks such as image captioning and visual question answering. These findings suggest that the scaling laws are not domain-specific but rather inherent properties of deep learning architectures when applied to large datasets.\\n\\nIn conclusion, empirical evidence from various studies consistently supports the validity of LLM scaling laws, demonstrating that careful scaling of model parameters, computational resources, and training data can lead to substantial performance improvements. These findings continue to shape the development of future AI systems, guiding researchers and practitioners in optimizing resources for maximum efficacy.\"]}})\n",
      "('updates', {'llm_call': {'completed_sections': ['### Applications and Implications\\n\\nThe scaling laws of large language models (LLMs) fundamentally influence both the design and deployment of AI systems. As these models are scaled in terms of parameters and data, their performance tends to improve across a wide array of tasks, leading to transformative applications in various sectors. This section explores the practical applications enabled by LLM scaling laws and examines the broader implications for future model development.\\n\\n#### Impact on Design and Deployment\\n\\n1. **Performance Optimization**: The scaling laws suggest that increasing the size of LLMs, in terms of both model parameters and training data, yields better performance on a multitude of language tasks. This understanding drives the design of more sophisticated models that can handle complex linguistic nuances, improve context understanding, and enhance generative capabilities.\\n\\n2. **Resource Allocation**: Scaling laws inform decisions about resource allocation, guiding researchers and developers on the trade-offs between computational cost and expected model performance. This influences how organizations budget for hardware, energy, and time during model training and deployment phases.\\n\\n3. **Model Architecture**: As models scale, there is a need for more efficient architectures that can support the increased complexity without exponentially growing resource demands. Techniques such as sparsity, model pruning, and more advanced neural network architectures are being explored to sustain scaling benefits.\\n\\n#### Practical Applications\\n\\n1. **Natural Language Processing (NLP)**: Enhanced LLMs have revolutionized NLP tasks, including translation, summarization, sentiment analysis, and question-answering systems. These applications are now more accessible and accurate, making them invaluable tools in industries like customer service, content creation, and data analysis.\\n\\n2. **Conversational Agents**: The development of chatbots and virtual assistants has greatly benefited from LLM scaling, resulting in more natural and engaging interactions. These agents are now deployed in diverse fields, including healthcare, finance, and e-commerce, enhancing user experience and operational efficiency.\\n\\n3. **Creative Content Generation**: Larger models have shown remarkable prowess in creative tasks such as writing, music composition, and art generation, enabling new forms of digital content creation and entertainment options.\\n\\n#### Future Implications\\n\\n1. **Ethical Considerations**: As LLMs scale, the potential for misuse grows, raising ethical concerns about bias, misinformation, and the impact on employment. Developers must prioritize ethical guidelines and fairness in model training and deployment to mitigate these risks.\\n\\n2. **Sustainability Challenges**: The environmental impact of training large models is a growing concern. Future development must focus on sustainable AI practices, including energy-efficient training methods, carbon offsetting, and the development of smaller, yet effective, models.\\n\\n3. **Innovation in AI Research**: The insights gained from scaling laws are likely to fuel further innovations in AI research. New theories and methodologies may emerge to overcome the current limitations of scaling, leading to breakthroughs in understanding and replicating human-like intelligence.\\n\\nIn summary, LLM scaling laws have significant applications and implications for AI development, guiding both the practical deployment of systems and the strategic direction of future research. As the field evolves, balancing performance with ethical and sustainable practices will be crucial to harnessing the full potential of these powerful models.']}})\n",
      "('updates', {'llm_call': {'completed_sections': ['## Challenges and Limitations\\n\\nThe development and scaling of large language models (LLMs) are accompanied by several significant challenges and limitations. As researchers and organizations continue to push the boundaries of what these models can achieve, they encounter issues related to computational costs, energy consumption, and diminishing returns in performance improvements.\\n\\n### Computational Costs\\n\\nScaling LLMs requires substantial computational resources. The training of these models involves complex algorithms running on high-performance hardware, often necessitating the use of specialized accelerators like GPUs or TPUs. The financial cost associated with acquiring and maintaining such hardware can be prohibitive, especially for smaller research institutions and companies. Additionally, the computational demand scales disproportionately with the size of the model, leading to exponentially higher costs as models grow larger.\\n\\n### Energy Consumption\\n\\nThe energy required to train and deploy large language models is another significant concern. Recent studies have highlighted the environmental impact of AI development, with LLMs being among the most energy-intensive processes. The carbon footprint associated with training these models is substantial, raising ethical and sustainability issues. As the demand for larger and more powerful models increases, addressing the energy efficiency of these systems becomes imperative to reduce their environmental impact.\\n\\n### Diminishing Returns\\n\\nAs LLMs scale, they often encounter diminishing returns in terms of performance improvements. Initially, increasing model size and complexity can lead to significant gains in accuracy and capability. However, beyond a certain point, these gains tend to plateau, requiring disproportionately larger models for marginal improvements. This phenomenon poses a challenge for researchers, as it necessitates careful consideration of the trade-off between model size and the tangible benefits it offers.\\n\\n### Data Limitations\\n\\nAnother challenge is the availability and quality of training data. As models scale, they require vast amounts of diverse data to train effectively. However, sourcing and curating high-quality datasets that are representative of the real-world scenarios these models will encounter remains a complex task. Furthermore, issues such as data bias and privacy concerns add layers of complexity to the data acquisition process.\\n\\n### Scalability Constraints\\n\\nThere are inherent scalability constraints due to the architectural limits of existing models. As models grow, they become more complex to manage and require sophisticated strategies for distributed training and optimization. This complexity can lead to inefficiencies and bottlenecks, hindering the ability to quickly iterate and improve models.\\n\\nIn summary, while scaling laws provide a framework for understanding the growth and potential of LLMs, they come with significant challenges that must be addressed. Balancing the trade-offs between computational costs, energy consumption, and the practical benefits of larger models is crucial for the sustainable advancement of language technologies. Researchers must continue to innovate in model efficiency, data utilization, and training methodologies to overcome these limitations and fully realize the potential of LLMs.']}})\n",
      "('updates', {'llm_call': {'completed_sections': ['## Mathematical Foundations\\n\\nThe mathematical foundations of scaling laws in large language models (LLMs) are rooted in a variety of theories and principles from computational learning theory, information theory, and statistical mechanics. These scaling laws provide a framework to understand how the performance of language models improves as a function of their size and the amount of training data. This section discusses the key mathematical concepts and models that underpin these scaling laws, emphasizing their predictive capabilities and limitations.\\n\\n### Power Laws in Scaling\\n\\nA central concept in LLM scaling laws is the power law relationship, which describes how error rates or other measures of performance decrease as a function of model size or data quantity. The general form of a power law is:\\n\\n\\\\[ E(N) \\\\approx C N^{-\\\\alpha} \\\\]\\n\\nwhere \\\\( E(N) \\\\) represents the error rate or a similar metric, \\\\( N \\\\) is the model size or the amount of training data, \\\\( C \\\\) is a constant, and \\\\( \\\\alpha \\\\) is the scaling exponent. This equation suggests that as the model size \\\\( N \\\\) increases, the error \\\\( E(N) \\\\) decreases at a rate determined by the exponent \\\\( \\\\alpha \\\\).\\n\\n### Theoretical Justifications\\n\\nThe emergence of power laws in LLM scaling is often justified through theories from statistical learning. One such theory is the Vapnik-Chervonenkis (VC) theory, which provides a framework to estimate the generalization error of a model based on its complexity and the number of training samples. According to VC theory, larger models with more parameters have a higher capacity to fit complex patterns, thus potentially reducing error rates given sufficient data.\\n\\nAdditionally, information-theoretic approaches explain scaling laws by considering the entropy and mutual information between the model parameters and the training data. These methods suggest that the information captured by larger models allows for more accurate predictions, aligning with observed scaling behaviors.\\n\\n### Empirical Models\\n\\nEmpirical studies have validated these theoretical insights by fitting scaling law models to performance data from experiments with LLMs. For instance, Kaplan et al. (2020) demonstrated that the performance of a wide range of transformer-based models follows predictable scaling laws when plotted against model size, dataset size, and computational budget.\\n\\nThe empirical model proposed by Kaplan et al. is often expressed as:\\n\\n\\\\[ L(N, D) = A (N^{-b} + D^{-c}) + L_{\\\\infty} \\\\]\\n\\nwhere \\\\( L(N, D) \\\\) is the loss function, \\\\( N \\\\) is the number of parameters, \\\\( D \\\\) is the dataset size, \\\\( A \\\\), \\\\( b \\\\), and \\\\( c \\\\) are constants derived from fitting to empirical data, and \\\\( L_{\\\\infty} \\\\) is the irreducible loss.\\n\\n### Limitations and Considerations\\n\\nWhile scaling laws provide a useful tool for predicting model performance, they are not without limitations. The assumption of infinitely scalable models and datasets is often impractical. Real-world constraints on computational resources and data availability can lead to deviations from predicted performance improvements. Furthermore, these models typically do not account for architectural innovations or changes in training algorithms that can significantly influence performance.\\n\\nIn conclusion, the mathematical foundations of LLM scaling laws offer crucial insights into the interplay between model size, data, and performance. Through a combination of theoretical and empirical approaches, these scaling laws serve as a guiding principle in the development and optimization of language models, although with careful consideration of their assumptions and limitations.']}})\n",
      "('updates', {'synthesizer': {'final_report': \"## Introduction to LLM Scaling Laws\\n\\nLarge Language Model (LLM) scaling laws are a set of principles that describe how the performance and capabilities of large language models improve as they are scaled in size. These laws provide a theoretical framework for understanding how increasing the number of parameters and the amount of training data in language models leads to enhanced performance in a variety of tasks. The significance of LLM scaling laws lies in their ability to guide researchers and developers in efficiently designing and deploying more powerful language models, thereby pushing the boundaries of what these models can achieve.\\n\\nThe concept of scaling laws was first introduced in the context of neural networks and machine learning as researchers sought to understand the relationship between model size and performance. Initially, scaling laws were applied to relatively simple models, and their implications were limited to specific tasks and datasets. However, with the advent of transformers and the subsequent development of large language models, the scope and applicability of these laws have expanded significantly.\\n\\nThe discovery of LLM scaling laws can be traced back to the early 2010s, with foundational work on neural network scaling. Notably, in 2019, researchers at OpenAI published a seminal paper on scaling laws for neural language models, which demonstrated that the performance of these models followed predictable patterns as they were scaled up in terms of parameters, data, and compute resources. This work laid the groundwork for further exploration into the scalability of language models.\\n\\nAs language models grew in size, from millions to billions of parameters, the understanding of scaling laws evolved. Researchers discovered that certain performance metrics, such as perplexity and accuracy on downstream tasks, improved logarithmically with increases in model scale. These findings have been crucial in the development of state-of-the-art models like GPT-3, which exemplify the practical application of scaling laws in producing highly capable language models.\\n\\nIn conclusion, LLM scaling laws have played a pivotal role in advancing the field of natural language processing by providing a roadmap for building larger and more efficient models. Their discovery and continued refinement have enabled researchers to optimize model architectures and training regimes, ultimately leading to breakthroughs in the capabilities of language models across diverse applications.\\n\\n---\\n\\n## Mathematical Foundations\\n\\nThe mathematical foundations of scaling laws in large language models (LLMs) are rooted in a variety of theories and principles from computational learning theory, information theory, and statistical mechanics. These scaling laws provide a framework to understand how the performance of language models improves as a function of their size and the amount of training data. This section discusses the key mathematical concepts and models that underpin these scaling laws, emphasizing their predictive capabilities and limitations.\\n\\n### Power Laws in Scaling\\n\\nA central concept in LLM scaling laws is the power law relationship, which describes how error rates or other measures of performance decrease as a function of model size or data quantity. The general form of a power law is:\\n\\n\\\\[ E(N) \\\\approx C N^{-\\\\alpha} \\\\]\\n\\nwhere \\\\( E(N) \\\\) represents the error rate or a similar metric, \\\\( N \\\\) is the model size or the amount of training data, \\\\( C \\\\) is a constant, and \\\\( \\\\alpha \\\\) is the scaling exponent. This equation suggests that as the model size \\\\( N \\\\) increases, the error \\\\( E(N) \\\\) decreases at a rate determined by the exponent \\\\( \\\\alpha \\\\).\\n\\n### Theoretical Justifications\\n\\nThe emergence of power laws in LLM scaling is often justified through theories from statistical learning. One such theory is the Vapnik-Chervonenkis (VC) theory, which provides a framework to estimate the generalization error of a model based on its complexity and the number of training samples. According to VC theory, larger models with more parameters have a higher capacity to fit complex patterns, thus potentially reducing error rates given sufficient data.\\n\\nAdditionally, information-theoretic approaches explain scaling laws by considering the entropy and mutual information between the model parameters and the training data. These methods suggest that the information captured by larger models allows for more accurate predictions, aligning with observed scaling behaviors.\\n\\n### Empirical Models\\n\\nEmpirical studies have validated these theoretical insights by fitting scaling law models to performance data from experiments with LLMs. For instance, Kaplan et al. (2020) demonstrated that the performance of a wide range of transformer-based models follows predictable scaling laws when plotted against model size, dataset size, and computational budget.\\n\\nThe empirical model proposed by Kaplan et al. is often expressed as:\\n\\n\\\\[ L(N, D) = A (N^{-b} + D^{-c}) + L_{\\\\infty} \\\\]\\n\\nwhere \\\\( L(N, D) \\\\) is the loss function, \\\\( N \\\\) is the number of parameters, \\\\( D \\\\) is the dataset size, \\\\( A \\\\), \\\\( b \\\\), and \\\\( c \\\\) are constants derived from fitting to empirical data, and \\\\( L_{\\\\infty} \\\\) is the irreducible loss.\\n\\n### Limitations and Considerations\\n\\nWhile scaling laws provide a useful tool for predicting model performance, they are not without limitations. The assumption of infinitely scalable models and datasets is often impractical. Real-world constraints on computational resources and data availability can lead to deviations from predicted performance improvements. Furthermore, these models typically do not account for architectural innovations or changes in training algorithms that can significantly influence performance.\\n\\nIn conclusion, the mathematical foundations of LLM scaling laws offer crucial insights into the interplay between model size, data, and performance. Through a combination of theoretical and empirical approaches, these scaling laws serve as a guiding principle in the development and optimization of language models, although with careful consideration of their assumptions and limitations.\\n\\n---\\n\\n## Empirical Evidence\\n\\nIn recent years, the scaling laws for large language models (LLMs) have been rigorously examined and validated through various empirical studies and experiments. These studies have provided critical insights into how performance metrics such as accuracy, generalization, and efficiency improve as models scale in terms of parameters, computational resources, and data.\\n\\n### OpenAI's GPT-3 Scaling Analysis\\n\\nOne of the most notable empirical validations of LLM scaling laws comes from OpenAI's development of GPT-3, which demonstrated a clear correlation between the size of the model and its performance across a wide array of tasks. OpenAI's research showed that as the number of parameters increased from 1.5 billion in GPT-2 to 175 billion in GPT-3, there was a significant improvement in the model's ability to generate coherent and contextually relevant text. The scaling laws predicted that larger models would require less training data to achieve similar performance, a hypothesis confirmed by GPT-3's ability to perform few-shot learning tasks with minimal examples.\\n\\n### DeepMind's Chinchilla Project\\n\\nDeepMind's Chinchilla project further investigated scaling laws by exploring the balance between model size and training data volume. The experiments revealed that for a fixed computational budget, smaller models trained with more data could outperform larger models trained with less data. This finding refined the understanding of scaling laws by emphasizing the importance of data efficiency alongside model size. The Chinchilla project underscored that optimal performance is achieved not merely by increasing model parameters but by aligning model size with the available data scale.\\n\\n### Meta's OPT Models\\n\\nMeta's OPT series of models provided additional empirical evidence supporting scaling laws. The research involved training models ranging from 125 million to 175 billion parameters and measuring their performance on standard benchmarks. The results consistently showed improvements in language understanding and generation as model size increased. The OPT models also highlighted the diminishing returns at extreme scales, aligning with theoretical predictions that suggest a logarithmic relationship between model size and performance gains.\\n\\n### Google's Pathways Language Model (PaLM)\\n\\nGoogle's Pathways Language Model (PaLM) explored the impacts of scaling not just parameter count but also the diversity of data sources. Empirical results from PaLM indicated that scaling models with diverse and high-quality data led to significant improvements in tasks that require reasoning and comprehension. The study validated the premise that scaling laws extend beyond model size, encompassing data diversity and quality as crucial factors for enhancing model capabilities.\\n\\n### Cross-Domain Scaling Studies\\n\\nSeveral cross-domain studies have examined the generalizability of scaling laws beyond language modeling. For instance, experiments in vision-language models demonstrated that scaling principles apply similarly, with larger models achieving better performance in tasks such as image captioning and visual question answering. These findings suggest that the scaling laws are not domain-specific but rather inherent properties of deep learning architectures when applied to large datasets.\\n\\nIn conclusion, empirical evidence from various studies consistently supports the validity of LLM scaling laws, demonstrating that careful scaling of model parameters, computational resources, and training data can lead to substantial performance improvements. These findings continue to shape the development of future AI systems, guiding researchers and practitioners in optimizing resources for maximum efficacy.\\n\\n---\\n\\n### Applications and Implications\\n\\nThe scaling laws of large language models (LLMs) fundamentally influence both the design and deployment of AI systems. As these models are scaled in terms of parameters and data, their performance tends to improve across a wide array of tasks, leading to transformative applications in various sectors. This section explores the practical applications enabled by LLM scaling laws and examines the broader implications for future model development.\\n\\n#### Impact on Design and Deployment\\n\\n1. **Performance Optimization**: The scaling laws suggest that increasing the size of LLMs, in terms of both model parameters and training data, yields better performance on a multitude of language tasks. This understanding drives the design of more sophisticated models that can handle complex linguistic nuances, improve context understanding, and enhance generative capabilities.\\n\\n2. **Resource Allocation**: Scaling laws inform decisions about resource allocation, guiding researchers and developers on the trade-offs between computational cost and expected model performance. This influences how organizations budget for hardware, energy, and time during model training and deployment phases.\\n\\n3. **Model Architecture**: As models scale, there is a need for more efficient architectures that can support the increased complexity without exponentially growing resource demands. Techniques such as sparsity, model pruning, and more advanced neural network architectures are being explored to sustain scaling benefits.\\n\\n#### Practical Applications\\n\\n1. **Natural Language Processing (NLP)**: Enhanced LLMs have revolutionized NLP tasks, including translation, summarization, sentiment analysis, and question-answering systems. These applications are now more accessible and accurate, making them invaluable tools in industries like customer service, content creation, and data analysis.\\n\\n2. **Conversational Agents**: The development of chatbots and virtual assistants has greatly benefited from LLM scaling, resulting in more natural and engaging interactions. These agents are now deployed in diverse fields, including healthcare, finance, and e-commerce, enhancing user experience and operational efficiency.\\n\\n3. **Creative Content Generation**: Larger models have shown remarkable prowess in creative tasks such as writing, music composition, and art generation, enabling new forms of digital content creation and entertainment options.\\n\\n#### Future Implications\\n\\n1. **Ethical Considerations**: As LLMs scale, the potential for misuse grows, raising ethical concerns about bias, misinformation, and the impact on employment. Developers must prioritize ethical guidelines and fairness in model training and deployment to mitigate these risks.\\n\\n2. **Sustainability Challenges**: The environmental impact of training large models is a growing concern. Future development must focus on sustainable AI practices, including energy-efficient training methods, carbon offsetting, and the development of smaller, yet effective, models.\\n\\n3. **Innovation in AI Research**: The insights gained from scaling laws are likely to fuel further innovations in AI research. New theories and methodologies may emerge to overcome the current limitations of scaling, leading to breakthroughs in understanding and replicating human-like intelligence.\\n\\nIn summary, LLM scaling laws have significant applications and implications for AI development, guiding both the practical deployment of systems and the strategic direction of future research. As the field evolves, balancing performance with ethical and sustainable practices will be crucial to harnessing the full potential of these powerful models.\\n\\n---\\n\\n## Challenges and Limitations\\n\\nThe development and scaling of large language models (LLMs) are accompanied by several significant challenges and limitations. As researchers and organizations continue to push the boundaries of what these models can achieve, they encounter issues related to computational costs, energy consumption, and diminishing returns in performance improvements.\\n\\n### Computational Costs\\n\\nScaling LLMs requires substantial computational resources. The training of these models involves complex algorithms running on high-performance hardware, often necessitating the use of specialized accelerators like GPUs or TPUs. The financial cost associated with acquiring and maintaining such hardware can be prohibitive, especially for smaller research institutions and companies. Additionally, the computational demand scales disproportionately with the size of the model, leading to exponentially higher costs as models grow larger.\\n\\n### Energy Consumption\\n\\nThe energy required to train and deploy large language models is another significant concern. Recent studies have highlighted the environmental impact of AI development, with LLMs being among the most energy-intensive processes. The carbon footprint associated with training these models is substantial, raising ethical and sustainability issues. As the demand for larger and more powerful models increases, addressing the energy efficiency of these systems becomes imperative to reduce their environmental impact.\\n\\n### Diminishing Returns\\n\\nAs LLMs scale, they often encounter diminishing returns in terms of performance improvements. Initially, increasing model size and complexity can lead to significant gains in accuracy and capability. However, beyond a certain point, these gains tend to plateau, requiring disproportionately larger models for marginal improvements. This phenomenon poses a challenge for researchers, as it necessitates careful consideration of the trade-off between model size and the tangible benefits it offers.\\n\\n### Data Limitations\\n\\nAnother challenge is the availability and quality of training data. As models scale, they require vast amounts of diverse data to train effectively. However, sourcing and curating high-quality datasets that are representative of the real-world scenarios these models will encounter remains a complex task. Furthermore, issues such as data bias and privacy concerns add layers of complexity to the data acquisition process.\\n\\n### Scalability Constraints\\n\\nThere are inherent scalability constraints due to the architectural limits of existing models. As models grow, they become more complex to manage and require sophisticated strategies for distributed training and optimization. This complexity can lead to inefficiencies and bottlenecks, hindering the ability to quickly iterate and improve models.\\n\\nIn summary, while scaling laws provide a framework for understanding the growth and potential of LLMs, they come with significant challenges that must be addressed. Balancing the trade-offs between computational costs, energy consumption, and the practical benefits of larger models is crucial for the sustainable advancement of language technologies. Researchers must continue to innovate in model efficiency, data utilization, and training methodologies to overcome these limitations and fully realize the potential of LLMs.\\n\\n---\\n\\n## Future Directions\\n\\nAs the field of large language models (LLMs) continues to evolve, several promising avenues for future research have emerged that could address existing limitations and enhance model efficiency. These directions not only aim to push the boundaries of what LLMs can achieve but also to make them more accessible and sustainable.\\n\\n### 1. Efficient Training Algorithms\\n\\nDeveloping more efficient training algorithms is crucial for reducing the computational overhead associated with LLMs. Future research could focus on optimizing training processes through techniques such as model sparsification and low-rank factorization. By leveraging these methods, it is possible to achieve similar performance levels with significantly fewer parameters and reduced resource consumption.\\n\\n### 2. Novel Architectures\\n\\nExploring novel neural network architectures may offer pathways to more efficient models. Researchers could investigate architectures that go beyond the traditional transformer models, potentially incorporating elements like recurrent mechanisms or hybrid models that combine the strengths of different neural network types. Such innovations could lead to improvements in both processing speed and accuracy.\\n\\n### 3. Scalability and Distributed Systems\\n\\nAs models grow larger, the need for scalable and efficient distributed training systems becomes apparent. Future directions could include developing more robust frameworks for distributed computing, which would enable faster training times by efficiently utilizing multiple devices. This approach not only ensures scalability but also reduces the environmental impact of training massive models.\\n\\n### 4. Transfer Learning and Adaptation\\n\\nEnhancing the ability of LLMs to transfer and adapt knowledge across different domains could further improve their versatility. Research in this area could focus on meta-learning techniques and continual learning methodologies, enabling models to learn new tasks more efficiently without forgetting previously acquired knowledge. This flexibility would be invaluable in dynamic environments where the model's capabilities need to evolve rapidly.\\n\\n### 5. Interpretability and Explainability\\n\\nImproving the interpretability and explainability of LLMs remains a critical area of research. Future work could explore methods to make the decision-making processes of these models more transparent, thus increasing trust and accountability. Techniques such as attention visualization and feature attribution could be refined to provide clearer insights into model behavior.\\n\\n### 6. Ethical and Responsible AI\\n\\nAddressing ethical considerations and ensuring responsible AI deployment are paramount as LLMs become more integrated into society. Future research could develop frameworks that incorporate fairness, accountability, and transparency into the design and deployment of LLMs. This includes creating models that mitigate biases and ensure equitable outcomes across diverse user groups.\\n\\n### 7. Energy Efficiency\\n\\nReducing the energy footprint of LLMs is crucial for sustainability. Future research could focus on energy-efficient hardware and software solutions, such as leveraging specialized accelerators like TPUs or developing algorithms that optimize power usage. Innovations in this area would contribute to more sustainable AI practices.\\n\\nIn conclusion, the future of LLM scaling laws presents a rich landscape of opportunities for innovation. By addressing current limitations and focusing on efficiency, scalability, and ethical considerations, researchers can unlock the full potential of LLMs, making them more powerful, practical, and responsible tools for the future.\\n\\n---\\n\\n## Conclusion\\n\\nIn conclusion, this report has explored the significant role of Large Language Model (LLM) scaling laws in the field of artificial intelligence. The scaling laws, which describe how performance metrics such as accuracy and efficiency improve with increased model size, dataset size, and computational power, are pivotal in guiding the development of more advanced AI systems.\\n\\nKey points highlighted in this report include the observation that larger models consistently outperform smaller ones, provided there is sufficient data and compute resources. This scaling behavior underscores the importance of continuing to invest in expanding the datasets and computational capabilities available for training AI models. Moreover, LLM scaling laws have opened new avenues for research, fostering a better understanding of how model capabilities evolve and how to optimize resource allocation during the training process.\\n\\nThe implications of LLM scaling laws extend beyond mere performance improvements. They offer insights into the theoretical underpinnings of AI, helping researchers predict the potential boundaries of model capabilities. This understanding is crucial for setting realistic expectations for AI advancements and for planning long-term research and investment strategies.\\n\\nAs AI continues to integrate into various sectors, driving innovations and efficiencies, the role of LLM scaling laws will only grow in importance. They provide a roadmap for achieving breakthroughs in AI performance, enabling the creation of more intelligent, versatile, and capable systems. The potential of these laws to shape future advancements in AI is vast, promising developments that could redefine the landscape of technology and its applications across industries.\\n\\nBy harnessing the insights offered by LLM scaling laws, the AI community can strategically focus its efforts on areas with the highest potential for impact, ensuring that future advancements are both significant and sustainable. As we look ahead, the continued exploration and application of these scaling laws will be instrumental in unlocking the next wave of AI innovations, driving progress and setting the stage for a future enriched by intelligent technologies.\"}})\n"
     ]
    }
   ],
   "source": [
    "# Invoke\n",
    "for chunk in orchestrator_worker.stream({\"topic\": \"Create a report on LLM scaling laws\"}, stream_mode=[\"updates\"]):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[0;32m----> 3\u001b[0m Markdown(\u001b[43mstate\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_report\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "\n",
    "\n",
    "# Schema for structured output to use in planning\n",
    "class SearchQuery(BaseModel):\n",
    "    query: str = Field(None, description=\"Query that is optimized for web search.\")\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SearchQueries(BaseModel):\n",
    "    queries: List[SearchQuery] = Field(\n",
    "        description=\"List of search queries and their justifications.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Reference(BaseModel):\n",
    "    \"\"\"Model for a reference\"\"\"\n",
    "\n",
    "    title: str = Field(description=\"The title of the reference.\")\n",
    "    url: str = Field(description=\"The url of the reference.\")\n",
    "    content: str = Field(description=\"The content of the reference.\")\n",
    "    summary: str = Field(description=\"The summary of the reference.\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str  # The difficult question to answer\n",
    "    queries: List[SearchQuery]  # List of generated search queries\n",
    "    references: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # Aggregated search results from tavily tool\n",
    "    final_answer: str  # Final synthesized answer\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "planner = llm.with_structured_output(SearchQueries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send, START, END\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    query: SearchQuery  # The search query for this worker\n",
    "    completed_results: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # Shared list for aggregating results\n",
    "\n",
    "\n",
    "# Node: Orchestrator\n",
    "def orchestrator(state: State) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a set of search queries based on the difficult question\n",
    "\n",
    "    - Use the planner LLM to generate queries\n",
    "    - Return the generated queries list under key 'queries'\n",
    "    \"\"\"\n",
    "    generated = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Generate a list of search queries that are required to answer the difficult question\"\n",
    "            ),\n",
    "            HumanMessage(content=f\"Here is the question: {state['question']}\"),\n",
    "        ]\n",
    "    )\n",
    "    # Assume that the planner returns an object with an attribute 'queries' that is a list of Query\n",
    "    return {\"queries\": generated.queries}\n",
    "\n",
    "\n",
    "# Node: Worker using the tavily tool\n",
    "def web_search(state: WorkerState) -> dict:\n",
    "    \"\"\"\n",
    "    Execute a search for the provided query using the tavily tool\n",
    "\n",
    "    - Extract the query text from the state\n",
    "    - Invoke the tavily search tool with the query\n",
    "    - Return the search result as part of completed_results\n",
    "    \"\"\"\n",
    "    query_text = state[\"query\"].query  # Use attribute access instead of subscripting\n",
    "    search_result = tavily_tool.invoke(query_text)\n",
    "    references = List(Reference())\n",
    "    for search in search_result:\n",
    "        references.append(\n",
    "            Reference(\n",
    "                title=search.title,\n",
    "                url=search.url,\n",
    "                content=search.content,\n",
    "            )\n",
    "        )\n",
    "    return {\"references\": references}\n",
    "\n",
    "\n",
    "async def summarization_node(state: WorkerState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    The summarization node is responsible for extracting and summarizing information from a web search.\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "This is the result of the search:\n",
    "\n",
    "Please summarize ONLY the result of the search and include all relevant information from the search and reference links.\n",
    "DO NOT INCLUDE ANY EXTRA INFORMATION. ALL OF THE INFORMATION YOU ARE LOOKING FOR IS IN THE SEARCH RESULTS.\n",
    "\n",
    "DO NOT answer the user's query yet. Just summarize the search results.\n",
    "\n",
    "Use markdown formatting and put the references inline and the links at the end.\n",
    "Like this:\n",
    "This is a sentence with a reference to a source [source 1][1] and another reference [source 2][2].\n",
    "[1]: http://example.com/source1 \"Title of Source 1\"\n",
    "[2]: http://example.com/source2 \"Title of Source 2\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Node: Synthesizer\n",
    "def synthesizer(state: State) -> dict:\n",
    "    \"\"\"\n",
    "    Synthesize the final answer from aggregated search results\n",
    "\n",
    "    - Combine the search results into a single context string\n",
    "    - Use the llm to summarize the search results and answer the question\n",
    "    - Return the final answer\n",
    "    \"\"\"\n",
    "    summary = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Summarize the following search results to answer the difficult question\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Search results:\\n{state['completed_results']}\\n\\nQuestion: {state['question']}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {\"final_answer\": summary.content}\n",
    "\n",
    "\n",
    "# Conditional edge: Assign a web_search worker for each generated query\n",
    "def assign_workers(state: State) -> List[Send]:\n",
    "    \"\"\"\n",
    "    Assign a web_search worker for each query in the generated plan\n",
    "\n",
    "    - Iterate over each query in state['queries']\n",
    "    - For each query, send a task to the web_search worker\n",
    "    \"\"\"\n",
    "    return [Send(\"web_search\", {\"query\": q}) for q in state[\"queries\"]]\n",
    "\n",
    "\n",
    "# Build the workflow\n",
    "workflow_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes to the workflow\n",
    "workflow_builder.add_node(\"orchestrator\", orchestrator)\n",
    "workflow_builder.add_node(\"web_search\", web_search)\n",
    "workflow_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Connect nodes with edges\n",
    "workflow_builder.add_edge(START, \"orchestrator\")\n",
    "workflow_builder.add_conditional_edges(\"orchestrator\", assign_workers, [\"web_search\"])\n",
    "workflow_builder.add_edge(\"web_search\", \"synthesizer\")\n",
    "workflow_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "workflow = workflow_builder.compile()\n",
    "\n",
    "# Optionally, display the workflow graph (if running in a Jupyter environment)\n",
    "from IPython.display import Image\n",
    "\n",
    "display(Image(workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Invoke the workflow with a difficult question\n",
    "initial_state: State = {\n",
    "    \"question\": \"How does quantum computing impact cryptography in a post-quantum world\",\n",
    "    \"queries\": [],\n",
    "    \"completed_results\": [],\n",
    "    \"final_answer\": \"\",\n",
    "}\n",
    "\n",
    "final_state = workflow.stream(initial_state, stream_mode=[\"updates\", \"messages\"])\n",
    "for state in final_state:\n",
    "    pprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the final answer using Markdown\n",
    "from IPython.display import Markdown\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    joke: str\n",
    "    topic: str\n",
    "    feedback: str\n",
    "    funny_or_not: str\n",
    "\n",
    "\n",
    "# Schema for structured output to use in evaluation\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"] = Field(\n",
    "        description=\"Decide if the joke is funny or not.\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"If the joke is not funny, provide feedback on how to improve it.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "evaluator = llm.with_structured_output(Feedback)\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def llm_call_generator(state: State):\n",
    "    \"\"\"LLM generates a joke\"\"\"\n",
    "\n",
    "    if state.get(\"feedback\"):\n",
    "        msg = llm.invoke(\n",
    "            f\"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "def llm_call_evaluator(state: State):\n",
    "    \"\"\"LLM evaluates the joke\"\"\"\n",
    "\n",
    "    grade = evaluator.invoke(f\"Grade the joke {state['joke']}\")\n",
    "    return {\"funny_or_not\": grade.grade, \"feedback\": grade.feedback}\n",
    "\n",
    "\n",
    "# Conditional edge function to route back to joke generator or end based upon feedback from the evaluator\n",
    "def route_joke(state: State):\n",
    "    \"\"\"Route back to joke generator or end based upon feedback from the evaluator\"\"\"\n",
    "\n",
    "    if state[\"funny_or_not\"] == \"funny\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"funny_or_not\"] == \"not funny\":\n",
    "        return \"Rejected + Feedback\"\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "optimizer_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "optimizer_builder.add_node(\"llm_call_generator\", llm_call_generator)\n",
    "optimizer_builder.add_node(\"llm_call_evaluator\", llm_call_evaluator)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "optimizer_builder.add_edge(START, \"llm_call_generator\")\n",
    "optimizer_builder.add_edge(\"llm_call_generator\", \"llm_call_evaluator\")\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"llm_call_evaluator\",\n",
    "    route_joke,\n",
    "    {  # Name returned by route_joke : Name of next node to visit\n",
    "        \"Accepted\": END,\n",
    "        \"Rejected + Feedback\": \"llm_call_generator\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the workflow\n",
    "optimizer_workflow = optimizer_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(optimizer_workflow.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "state = optimizer_workflow.invoke({\"topic\": \"Cats\"})\n",
    "print(state[\"joke\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Augment the LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"environment\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # Name returned by should_continue : Name of next node to visit\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Pass in:\n",
    "# (1) the augmented LLM with tools\n",
    "# (2) the tools list (which is used to create the tool node)\n",
    "pre_built_agent = create_react_agent(llm, tools=tools)\n",
    "\n",
    "# Show the agent\n",
    "display(Image(pre_built_agent.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = pre_built_agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-F0L5SJfm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
