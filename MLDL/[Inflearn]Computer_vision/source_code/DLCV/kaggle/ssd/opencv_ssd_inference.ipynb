{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### OpenCV DNN을 이용하여 SSD 기반 Object Detection 수행\n* Tensorflow 에서 Pretrained 된 모델 파일을 OpenCV에서 로드하여 이미지와 영상에 대한 Object Detection 수행.\n* SSD+Inception과 SSD+MobileNet v3 를 모두 테스트\n* CPU기반 환경에서 SSD의 Inference 속도 주시. ","metadata":{"id":"AWqDbzXReMkX"}},{"cell_type":"markdown","source":"#### 입력 이미지로 사용될 이미지 다운로드\n","metadata":{"id":"WrzQFh2heMka"}},{"cell_type":"code","source":"!mkdir /kaggle/working/data\n!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg","metadata":{"id":"CP7z351geMkc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Tensorflow에서 Pretrained 된 Inference모델(Frozen graph)와 환경파일을 다운로드 받은 후 이를 이용해 OpenCV에서 Inference 모델 생성\n* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음.\n* pretrained 모델은 http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz 에서 다운로드 후 압축 해제\n* pretrained 모델을 위한 환경 파일은 https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_inception_v2_coco_2017_11_17.pbtxt 에서 다운로드 \n* download된 모델 파일과 config 파일을 인자로 하여 inference 모델을 DNN에서 로딩함. \n","metadata":{"id":"2uqlttIJeMkp"}},{"cell_type":"code","source":"!mkdir ./pretrained\n\n!wget -O ./pretrained/ssd_inception_v2_coco_2017_11_17.tar.gz http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz \n!wget -O ./pretrained/ssd_config_01.pbtxt  https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/ssd_inception_v2_coco_2017_11_17.pbtxt\n\n!tar -xvf ./pretrained/ssd_inception*.tar.gz -C ./pretrained ","metadata":{"id":"fu8VV9p91LLw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd\n!ls -lia ./pretrained/ssd_inception*","metadata":{"id":"hrNcBdWY1uoN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dnn에서 readNetFromTensorflow()로 tensorflow inference 모델을 로딩","metadata":{"id":"3C6Gtw-v2GDk"}},{"cell_type":"code","source":"import cv2\n\ncv_net = cv2.dnn.readNetFromTensorflow('/kaggle/working/pretrained/ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb',\n                                      '/kaggle/working/pretrained/ssd_config_01.pbtxt')","metadata":{"id":"DQbnBcUdeMk5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### coco 데이터 세트의 클래스id별 클래스명 지정. ","metadata":{"id":"jbSAASzdeMlA"}},{"cell_type":"code","source":"labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n                    91:'hair brush'}\n","metadata":{"id":"3spingJOtXJF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 이미지를 preprocessing 수행하여 Network에 입력하고 Object Detection 수행 후 결과를 이미지에 시각화 ","metadata":{"id":"U0BYbmG0eMlI"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n\nimg = cv2.imread('/kaggle/working/data/beatles01.jpg')\n\n# 원본 이미지 (633, 806)를 네트웍에 입력시에는 (300, 300)로 resize 함. \n# 이후 결과가 출력되면 resize된 이미지 기반으로 bounding box 위치가 예측 되므로 이를 다시 원복하기 위해 원본 이미지 shape정보 필요\nrows = img.shape[0]\ncols = img.shape[1]\n# cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \ndraw_img = img.copy()\n\n# 원본 이미지 배열을 사이즈 (300, 300)으로, BGR을 RGB로 변환하여 배열 입력\ncv_net.setInput(cv2.dnn.blobFromImage(img,  size=(300, 300), swapRB=True, crop=False))\n# Object Detection 수행하여 결과를 cv_out으로 반환 \ncv_out = cv_net.forward()\nprint(cv_out.shape)\n\n# bounding box의 테두리와 caption 글자색 지정\ngreen_color=(0, 255, 0)\nred_color=(0, 0, 255)\n\n# detected 된 object들을 iteration 하면서 정보 추출\nfor detection in cv_out[0,0,:,:]:\n    score = float(detection[2])\n    class_id = int(detection[1])\n    # detected된 object들의 score가 0.4 이상만 추출\n    if score > 0.4:\n        # detected된 object들은 image 크기가 (300, 300)으로 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n        left = detection[3] * cols\n        top = detection[4] * rows\n        right = detection[5] * cols\n        bottom = detection[6] * rows\n        # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n        \n        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 2)\n        print(caption, class_id)\n\nimg_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(img_rgb)","metadata":{"id":"GIOyisS3eMlK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 단일 이미지의 object detection을 함수로 생성","metadata":{"id":"KSoSkTexeMlP"}},{"cell_type":"code","source":"import time\n\ndef get_detected_img(cv_net, img_array, score_threshold, is_print=True):\n    \n    rows = img_array.shape[0]\n    cols = img_array.shape[1]\n    \n    draw_img = img_array.copy()\n    \n    cv_net.setInput(cv2.dnn.blobFromImage(img_array, size=(300, 300), swapRB=True, crop=False))\n    \n    start = time.time()\n    cv_out = cv_net.forward()\n    \n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n\n    # detected 된 object들을 iteration 하면서 정보 추출\n    for detection in cv_out[0,0,:,:]:\n        score = float(detection[2])\n        class_id = int(detection[1])\n        # detected된 object들의 score가 0.4 이상만 추출\n        if score > score_threshold:\n            # detected된 object들은 image 크기가 (300, 300)으로 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n            left = detection[3] * cols\n            top = detection[4] * rows\n            right = detection[5] * cols\n            bottom = detection[6] * rows\n            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n            caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n\n            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 2)\n    if is_print:\n        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n\n    return draw_img","metadata":{"id":"qk9sOZnteMlQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image 로드 \nimg = cv2.imread('/kaggle/working/data/beatles01.jpg')\n\n#coco dataset 클래스명 매핑\n\n# Object Detetion 수행 후 시각화 \ndraw_img = get_detected_img(cv_net, img, score_threshold=0.4, is_print=True)\n\nimg_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(img_rgb)","metadata":{"id":"H9yHawXneMlV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg\n\nimg = cv2.imread('/kaggle/working/data/baseball01.jpg')\n\n#coco dataset 클래스명 매핑\n\n# Object Detetion 수행 후 시각화 \ndraw_img = get_detected_img(cv_net, img, score_threshold=0.4, is_print=True)\n\nimg_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(img_rgb)","metadata":{"id":"hVbhU-1ol-bO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Video Object Detection 수행","metadata":{"id":"E4dXqj8MeMla"}},{"cell_type":"code","source":"!wget -O ./data/Jonh_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true","metadata":{"id":"6ItMwC_WeMld","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### VideoCapture와 VideoWriter 설정하고 Video Detection용 전용 함수 생성\n* VideoCapture를 이용하여 Video를 frame별로 capture 할 수 있도록 설정\n* VideoCapture의 속성을 이용하여 Video Frame의 크기 및 FPS 설정. \n* VideoWriter를 위한 인코딩 코덱 설정 및 영상 write를 위한 설정\n총 Frame 별로 iteration 하면서 Object Detection 수행. 개별 frame별로 단일 이미지 Object Detection과 유사 ","metadata":{"id":"XxRe2zVGeMlj"}},{"cell_type":"code","source":"def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n    \n    cap = cv2.VideoCapture(input_path)\n\n    codec = cv2.VideoWriter_fourcc(*'XVID')\n\n    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n\n    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n\n    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    print('총 Frame 갯수:', frame_cnt, )\n\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n    while True:\n        hasFrame, img_frame = cap.read()\n        if not hasFrame:\n            print('더 이상 처리할 frame이 없습니다.')\n            break\n        \n        returned_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n        vid_writer.write(returned_frame)\n    # end of while loop\n\n    vid_writer.release()\n    cap.release()","metadata":{"id":"EWQOFbS3eMll","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_detected_video(cv_net, '/kaggle/working/data/Jonh_Wick_small.mp4', './data/John_Wick_small_incept.mp4', 0.2, False)","metadata":{"id":"ASFbf8eGeMlr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"pUC5ExKBeMl1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SSD+Mobilenet v3 Object Detection 수행. \n* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음. \n* weight파일은 http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz 에서 다운로드\n* SSD + Mobilenet v3 backbone은 opencv dnn 모듈이 아니라 dnn_DetectionModel() 함수로 생성 가능하며, 이를 사용하기 위해서는 Opencv의 버전을 Upgrade해야함. ","metadata":{"id":"Pe73Mt-IeMl8"}},{"cell_type":"code","source":"!mkdir ./pretrained\n!wget -O ./pretrained/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz\n!wget -O ./pretrained/ssd_config_02.pbtxt https://gist.githubusercontent.com/dkurt/54a8e8b51beb3bd3f770b79e56927bd7/raw/2a20064a9d33b893dd95d2567da126d0ecd03e85/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\n\n!!tar -xvf ./pretrained/ssd_mobilenet*.tar.gz -C ./pretrained ","metadata":{"id":"q54TjunD40Il","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cv2.__version__)","metadata":{"id":"u2WaUaiM6sfJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### opencv의 버전을 Upgrade한 후 dnn_DetectionModel() 사용.\n* https://github.com/opencv/opencv/pull/16760 \n* dnn_DetectionModel()은 dnn_Model 객체 반환\n* 해당 SSD 모델은 image pixel값을 -1 ~ 1 사이로 정규화하고 image size는 320, 320으로 설정.\n","metadata":{"id":"oROmSOsKgMQI"}},{"cell_type":"code","source":"!pip install opencv-python==4.5.2.54","metadata":{"id":"3s2sRyw45xOy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\ncv_net_m = cv2.dnn_DetectionModel('/kaggle/working/pretrained/ssd_mobilenet_v3_large_coco_2020_01_14/frozen_inference_graph.pb',\n                                      '/kaggle/working/pretrained/ssd_config_02.pbtxt')\ncv_net_m.setInputSize(320, 320)\ncv_net_m.setInputScale(1.0 / 127.5)\ncv_net_m.setInputMean((127.5, 127.5, 127.5))\ncv_net_m.setInputSwapRB(True)","metadata":{"id":"NnCRqxpq60sh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### dnn_Model 객체의 detect() 메소드는 입력 이미지를 받아서 특정 confidence threshold 이상의 모든 object inference 결과를 반환. \n* class id값, confidence score값, bbox 좌표값이 arrary로 반환됨.\n* bbox 좌표값의 경우 0~1사이 값이 아니라 정수형의 위치값이 반환됨. 단 xmin, ymin, width, height 형태로 반환되므로 유의 필요. ","metadata":{"id":"-5rBoplnjdo2"}},{"cell_type":"code","source":"img = cv2.imread('/kaggle/working/data/beatles01.jpg')\ndraw_img = img.copy()\n\nclasses, confidences, boxes = cv_net_m.detect(img, confThreshold=0.5)","metadata":{"id":"99q1mZKB7I8u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes, confidences, boxes","metadata":{"id":"kpUuSqC-7Lv6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes.shape, confidences.shape, boxes.shape","metadata":{"id":"wDhtxZKpwctv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n                    91:'hair brush'}","metadata":{"id":"Cp5wUqcOk6QL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ngreen_color=(0, 255, 0)\nred_color=(0, 0, 255)\n\nfor class_id, confidence_score, box in zip(classes.flatten(), confidences.flatten(), boxes):\n    if confidence_score > 0.5:\n        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], confidence_score)\n        # box 반환 좌표값은 정수형 위치 좌표임. xmin, ymin, width, height임에 유의 \n        cv2.rectangle(draw_img, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), color=green_color, thickness=2)\n        cv2.putText(draw_img, caption, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, red_color, 2)\n        print(caption, class_id, box)  \n\ndraw_img = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(12, 12))\nplt.imshow(draw_img)","metadata":{"id":"PZCWo0fe7ObC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 단일 이미지의 object detection을 함수로 생성","metadata":{"id":"WuIOcDu1k-1i"}},{"cell_type":"code","source":"import time \n\ndef get_detected_img_renew(cv_net, img_array, score_threshold, is_print=True):\n    \n    draw_img = img_array.copy()\n\n    start = time.time()\n\n    classes, confidences, boxes = cv_net.detect(img_array, confThreshold=0.5)\n\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n\n    # detected 된 object들을 iteration 하면서 정보 추출\n    for class_id, confidence_score, box in zip(classes.flatten(), confidences.flatten(), boxes):\n        if confidence_score > 0.5:\n            caption = \"{}: {:.4f}\".format(labels_to_names[class_id], confidence_score)\n            cv2.rectangle(draw_img, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), color=green_color, thickness=2)\n            cv2.putText(draw_img, caption, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, red_color, 2)\n            print(caption)\n\n        if is_print:\n            print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n\n    return draw_img","metadata":{"id":"hNvGnp5pSX4q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8NRItwDJkrdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## dnn_Model을 만드는 함수 생성. \ndef get_cv_detection_model(pretrained_path, config_path):\n    cv_net = cv2.dnn_DetectionModel(pretrained_path, config_path)\n    cv_net.setInputSize(320, 320)\n    cv_net.setInputScale(1.0 / 127.5)\n    cv_net.setInputMean((127.5, 127.5, 127.5))\n    cv_net.setInputSwapRB(True)\n\n    return cv_net\n\ncv_net_m = get_cv_detection_model('/kaggle/working/pretrained/ssd_mobilenet_v3_large_coco_2020_01_14/frozen_inference_graph.pb',\n                       '/kaggle/working/pretrained/ssd_config_02.pbtxt')","metadata":{"id":"pfIWJ-DyUHlH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread('./data/beatles01.jpg')\n\n# Object Detetion 수행 후 시각화 \ndraw_img = get_detected_img_renew(cv_net_m, img, score_threshold=0.5,  is_print=True)\n\nimg_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(img_rgb)","metadata":{"id":"luJDB3RxUV7P","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg\n\nimg = cv2.imread('./data/baseball01.jpg')\n\n# Object Detetion 수행 후 시각화 \ndraw_img = get_detected_img_renew(cv_net_m, img, score_threshold=0.5,  is_print=True)\n\nimg_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(img_rgb)","metadata":{"id":"krsSCI33lwFR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Video Inferece 수행.","metadata":{"id":"7Eulfo4tmSu-"}},{"cell_type":"code","source":"!wget -O ./data/Jonh_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true","metadata":{"id":"ORMFN4TYmYoO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_detected_video_renew(cv_net, input_path, output_path, score_threshold, is_print):\n    \n    cap = cv2.VideoCapture(input_path)\n\n    codec = cv2.VideoWriter_fourcc(*'XVID')\n\n    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n\n    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n\n    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    print('총 Frame 갯수:', frame_cnt, )\n\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n    while True:\n        hasFrame, img_frame = cap.read()\n        if not hasFrame:\n            print('더 이상 처리할 frame이 없습니다.')\n            break\n        \n        returned_frame = get_detected_img_renew(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n        vid_writer.write(returned_frame)\n    # end of while loop\n\n    vid_writer.release()\n    cap.release()","metadata":{"id":"zdJAMIEKU-T3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_detected_video_renew(cv_net_m, '/kaggle/working/data/Jonh_Wick_small.mp4', './data/John_Wick_small_m3.mp4', 0.2, False)","metadata":{"id":"4IG-L2h8VCMl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"7ztd0lsr2F8L"},"execution_count":null,"outputs":[]}]}