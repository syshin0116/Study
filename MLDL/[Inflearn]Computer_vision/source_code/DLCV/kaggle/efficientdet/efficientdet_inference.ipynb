{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Google automl의 Efficientdet 다운로드 및 설치\n* efficientdet package는 tensorflow용 구현 모듈과 tf.keras용 구현 모듈이 별도로 구성됨. \n* tf.keras용 구현 API 들이 ./automl/efficientdt/keras 디렉토리에 위치(tensorflow의 tf.keras binary가 아니라 tf.keras로 efficientdet을 구현한 API가 모여있는 디렉토리임). Colab에서 기본 설치된 keras모듈과 namespace가 충돌 되므로 keras 모듈을 삭제.  ","metadata":{"id":"VwGTdG6iIGAc"}},{"cell_type":"code","source":"!git clone --depth 1 https://github.com/google/automl","metadata":{"id":"0kC38OqwWjH_","executionInfo":{"status":"ok","timestamp":1624907804774,"user_tz":-540,"elapsed":3907,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"147ac0f4-3411-47a6-8f97-58feea870d2d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/automl/efficientdet; pip install -r requirements.txt","metadata":{"id":"qjnDA7oxq6SX","executionInfo":{"status":"ok","timestamp":1624907817269,"user_tz":-540,"elapsed":12506,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"29cb727a-cbf0-4007-b6c7-1aab24a77191","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y keras","metadata":{"id":"PdE55IuKV4Bw","executionInfo":{"status":"ok","timestamp":1624908211989,"user_tz":-540,"elapsed":1043,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"c08d1175-704f-4b01-d83f-b67e17da8005","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"id":"Go_HO6CPH1ni","executionInfo":{"status":"ok","timestamp":1624908213140,"user_tz":-540,"elapsed":2,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"d1993a84-0c90-4ec5-a63d-61fbb00253eb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"LunNfqZyJCWN","executionInfo":{"status":"ok","timestamp":1624908215392,"user_tz":-540,"elapsed":619,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"16444215-7cfe-499c-c7f7-6b1396762991","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### efficientdet 수행을 위한 Library path 설정. \n* efficientdet을 setup을 하지 않고, 소스코드를 sys.path.append('/content/automl/efficientdet')로 library path 설정. ","metadata":{"id":"n6bdjw4dJZLg"}},{"cell_type":"code","source":"import os\nimport sys\nimport tensorflow.compat.v1 as tf","metadata":{"id":"RF8Ry1aJqZgq","executionInfo":{"status":"ok","timestamp":1624908217880,"user_tz":-540,"elapsed":5,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('/kaggle/working/automl/efficientdet')","metadata":{"id":"t03c-FmuqgyR","executionInfo":{"status":"ok","timestamp":1624908219847,"user_tz":-540,"elapsed":7,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# /kaggle/working/automl/efficient 으로 library path가 정상적으로 잡히면 아래 모듈 import가 되어야함. \nimport hparams_config\nfrom keras import anchors\nfrom model_inspect import ModelInspector","metadata":{"id":"xZuN4cDkVdHs","executionInfo":{"status":"ok","timestamp":1624908221936,"user_tz":-540,"elapsed":602,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### COCO 데이터로 Pretrained된 efficientdet-d0 모델을 다운로드","metadata":{"id":"E410TjdvKL8u"}},{"cell_type":"code","source":"MODEL = 'efficientdet-d0' \n\ndef download(m):\n    if m not in os.listdir():\n        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n        !tar zxf {m}.tar.gz\n    ckpt_path = os.path.join(os.getcwd(), m)\n    \n    return ckpt_path\n\n# Download checkpoint.\nckpt_path = download(MODEL)\nprint('Use model in {}'.format(ckpt_path))","metadata":{"id":"kBxJQq8brE1P","executionInfo":{"status":"ok","timestamp":1624908227658,"user_tz":-540,"elapsed":3110,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"75387e2c-aca8-4f56-c865-d3e5ba7fd0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ./data\n!wget -O ./data/img01.png https://user-images.githubusercontent.com/11736571/77320690-099af300-6d37-11ea-9d86-24f14dc2d540.png","metadata":{"id":"CJkiI9aRFDla","executionInfo":{"status":"ok","timestamp":1624908227658,"user_tz":-540,"elapsed":10,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"d0b0eb79-d15d-417f-e7c3-d8e4d7c3fff3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nimage_array = cv2.cvtColor(cv2.imread('/kaggle/working/data/img01.png'), cv2.COLOR_BGR2RGB)\nprint(image_array.shape)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(image_array)","metadata":{"id":"HZC-dVRI3yrJ","executionInfo":{"status":"ok","timestamp":1624908231518,"user_tz":-540,"elapsed":2841,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"440353b5-7eca-485e-f659-bebf3f4290ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pretrained efficientdet 모델로 Inference 를 수행하기 위한 환경 설정\n* hparams_config.Config 객체를 통해 모델 환경 설정. ","metadata":{"id":"XTmE4k96K0Po"}},{"cell_type":"code","source":"class INFER_CFG:\n    model_name = 'efficientdet-d0' # efficientdet 모델명\n    model_dir = '/kaggle/working/efficientdet-d0' # pretrained checkpoint 파일이 있는 디렉토리\n    hparams = '' # csv 형식의 k=v 쌍 또는 yaml file","metadata":{"id":"ayvtZM_pG6ao","executionInfo":{"status":"ok","timestamp":1624908231952,"user_tz":-540,"elapsed":16,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport tensorflow as tf\n\nimport hparams_config\nimport inference\nfrom keras import efficientdet_keras","metadata":{"id":"_x8LNnyoUlrQ","executionInfo":{"status":"ok","timestamp":1624908231956,"user_tz":-540,"elapsed":17,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#efficientdet-d0의 기본 config 확인. \nconfig = hparams_config.get_efficientdet_config(INFER_CFG.model_name)\nprint('config type:', type(config))\nprint(config)","metadata":{"id":"Ol3voDSvUp-D","executionInfo":{"status":"ok","timestamp":1624908233477,"user_tz":-540,"elapsed":8,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"2934e160-0bd0-4098-d0e8-23acfb6d81c0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config의 특정 항목을 update\nconfig.is_training_bn = False\n#config.image_size = '1920x1280'\nconfig.nms_configs.score_thresh = 0.4\nconfig.nms_configs.max_output_size = 100\n\nconfig.override(INFER_CFG.hparams)","metadata":{"id":"6ZuHewaAUqB5","executionInfo":{"status":"ok","timestamp":1624908234839,"user_tz":-540,"elapsed":4,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# P100 GPU Card에서는 아래 수행하지 말것. V100 GPU 시에는 mixed_float16으로 mixed_precision 설정. \n\n#policy = tf.keras.mixed_precision.Policy('mixed_float16')\n#tf.keras.mixed_precision.set_global_policy(policy)\n#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n#tf.config.run_functions_eagerly(MODEL_CONFIG.debug)","metadata":{"id":"SEu9PzS2UqFA","executionInfo":{"status":"ok","timestamp":1624908236372,"user_tz":-540,"elapsed":3,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-H6neLkZe0d0","executionInfo":{"status":"ok","timestamp":1624908237841,"user_tz":-540,"elapsed":5,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pretrained 모델 생성 후 Inference 수행\n* config인자로 하여 EfficientDetModel생성  \n* 만들어진 모델에 다운로드 된 Pretrained Weight 파일의 weight값을 model.load_weights()로 입력  ","metadata":{"id":"cyYXy4AYLeWk"}},{"cell_type":"code","source":"INFER_CFG.model_dir","metadata":{"id":"Qv7EGZq-SxKG","executionInfo":{"status":"ok","timestamp":1624908239772,"user_tz":-540,"elapsed":9,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9f313321-3459-4314-edb8-1724e7b23e69","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import inference\nfrom keras import efficientdet_keras\n\nmodel = efficientdet_keras.EfficientDetModel(config=config)\nmodel.build((None, None, None, 3))\nprint('#### checkpoint name:', tf.train.latest_checkpoint(INFER_CFG.model_dir))\nmodel.load_weights(tf.train.latest_checkpoint(INFER_CFG.model_dir))\nmodel.summary()","metadata":{"id":"GIYQBVAgUqHx","executionInfo":{"status":"ok","timestamp":1624908250973,"user_tz":-540,"elapsed":9837,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"3d4a8b1d-cee5-497a-e08e-dd855c61cdf9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport cv2\n\n# image는 4차원 array, Tensor 모두 가능.  \nimgs = [np.array(Image.open('/kaggle/working/data/img01.png'))]\nimgs = tf.convert_to_tensor(imgs, dtype=tf.uint8)\n\n### 아래와 같이 numpy array도 모델에 입력되는 이미지 값으로 가능. \n''' \nimg = cv2.cvtColor(cv2.imread('/kaggle/working/data/img01.png'), cv2.COLOR_BGR2RGB)\nimgs= img[np.newaxis, ...]\nboxes, scores, classes, valid_len = model(imgs, training=False, post_mode='global')\n'''\nprint()","metadata":{"id":"FKsOePtH2rFt","executionInfo":{"status":"ok","timestamp":1624908253859,"user_tz":-540,"elapsed":2915,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"3409a5eb-32d7-4ea0-8afb-764cdc0ec59f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Inference 수행하고 수행 시간을 측정. \nstart_time = time.time()\nboxes, scores, classes, valid_len = model(imgs, training=False, post_mode='global')\nprint('elapsed time:', time.time() - start_time)","metadata":{"id":"gzFTFy0GKRSO","executionInfo":{"status":"ok","timestamp":1624908273512,"user_tz":-540,"elapsed":420,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"6379f405-4a7b-4b7e-8db6-0a7225851134","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference 반환 결과 살펴보고 API로 시각화 하기\n* inference model에 image tensor를 입력하여 반환된 결과는 모두 tensor이며, bounding box의 좌표, confidence score, class id 값, valid한 갯수가 반환됨. \n* config에 max_instances_per_image이 100으로 설정되었으므로 기본적으로 inference결과는 100개의 object들의 Detection 결과를 가지게 됨. \n* 이들 중 valid한 갯수(valid_len)은 이들중 의미있는 object detection 갯수를 의미함.(0 부터 valid_len-1 까지의 index를 가진 array결과가 의미있는 detection 결과임)\n* inference.visualize_image()로 반화 결과를 입력하여 시각화 적용","metadata":{"id":"n3KNsTk4PH7s"}},{"cell_type":"code","source":"boxes","metadata":{"id":"7Db1e_bWrlJD","executionInfo":{"status":"ok","timestamp":1624911683922,"user_tz":-540,"elapsed":506,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"750e85d7-a29a-4596-93ae-1fb67eb9594e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(valid_len.numpy())\nboxes.shape, scores.shape, classes.shape","metadata":{"id":"6CsvLHOOWjZN","executionInfo":{"status":"ok","timestamp":1624911875777,"user_tz":-540,"elapsed":446,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"a87cc3a7-74ca-4058-b621-c0f8f70df355","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores","metadata":{"id":"_MhlCBn-VLDj","executionInfo":{"status":"ok","timestamp":1624911893295,"user_tz":-540,"elapsed":435,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9d552196-466f-4f29-ff1c-2dd897122ea8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('##bboxes:', boxes[0, :10], '\\n##scores:', scores[0, :10], '\\n##classes:', classes[0, :10])","metadata":{"id":"1Agdgi5qxfQC","executionInfo":{"status":"ok","timestamp":1624911957318,"user_tz":-540,"elapsed":582,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"1fb44bd3-9e83-41b2-f739-e1262b4a9de7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/working/data_output","metadata":{"id":"0BeubApvPKZh","executionInfo":{"status":"ok","timestamp":1624912033175,"user_tz":-540,"elapsed":409,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, img in enumerate(imgs):\n    length = valid_len[i]\n\n    img = inference.visualize_image(\n      img,\n      boxes[i].numpy()[:length],\n      classes[i].numpy().astype(np.int)[:length],\n      scores[i].numpy()[:length],\n      label_map=config.label_map,\n      min_score_thresh=config.nms_configs.score_thresh,\n      max_boxes_to_draw=config.nms_configs.max_output_size)\n  \n    output_image_path = os.path.join('/kaggle/working/data_output', str(i) + '.jpg')\n    Image.fromarray(img).save(output_image_path)\n    print('writing annotated image to %s' % output_image_path)","metadata":{"id":"vFoyZNcCYJMi","executionInfo":{"status":"ok","timestamp":1624912124708,"user_tz":-540,"elapsed":442,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"5688bf3c-2c91-456b-9de3-a31d7b0d902e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Static Graph mode(Non eager mode)로 Inference 수행 성능 향상 시키기\n* @tf.function을 이용하여 static mode로 inference를 수행할 수 있도록 ExportModel 클래스 생성\n* inference 수행 시 ExportModel의 @tf.function이 적용된 메소드를 호출할 수 있도록 함. ","metadata":{"id":"Hk_o4Me0NU3Q"}},{"cell_type":"code","source":"import time\n\nclass ExportModel(tf.Module):\n\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    @tf.function\n    def f(self, imgs):\n        #model(imgs, training=False, post_mode='global')\n        return self.model(imgs, training=False, post_mode='global')\n\nexport_model = ExportModel(model)","metadata":{"id":"5dMXulIe3q82","executionInfo":{"status":"ok","timestamp":1624912589788,"user_tz":-540,"elapsed":417,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# p100에서 image 1920x1280일 경우 74ms, v100에서 image 512x512일 경우 24ms\n\nstart_time = time.time()\nboxes, scores, classes, valid_len = export_model.f(imgs)\n\nprint('elapsed time:', time.time() - start_time)","metadata":{"id":"mZSnxXgXLBlv","executionInfo":{"status":"ok","timestamp":1624912629505,"user_tz":-540,"elapsed":433,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"6f69cfff-be21-47bb-da93-418b354f5f75","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 시각화 함수 생성하고 inference 결과를 시각화","metadata":{"id":"xKoPIm8j3Y4s"}},{"cell_type":"code","source":"labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n                    91:'hair brush'}","metadata":{"id":"OaeXSSIS3TaH","executionInfo":{"status":"ok","timestamp":1624912646741,"user_tz":-540,"elapsed":421,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_detected_img(export_model, img_array, is_print=True):   \n    # automl efficent은 반환 bbox 좌표값이 원본 이미지 좌표값으로 되어 있으므로 별도의 scaling작업 필요 없음. \n    '''\n    height = img_array.shape[0]\n    width = img_array.shape[1]\n    '''\n    # cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n    draw_img = img_array.copy()\n\n    # bounding box의 테두리와 caption 글자색 지정\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n\n    # cv2로 만들어진 numpy image array를 tensor로 변환\n    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.uint8)[tf.newaxis, ...]\n    #img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)[tf.newaxis, ...]\n\n    # efficientdet 모델을 다운로드 한 뒤 inference 수행. \n    start_time = time.time()\n    # automl efficientdet 모델은 boxes, score, classes, num_detections를 각각 Tensor로 반환. \n    boxes, scores, classes, valid_len = export_model.f(img_tensor)\n    # Tensor값을 시각화를 위해 numpy 로 변환. \n    boxes = boxes.numpy()\n    scores = scores.numpy()\n    classes = classes.numpy()\n    valid_len = valid_len.numpy()\n  \n    # detected 된 object들을 iteration 하면서 정보 추출. detect된 object의 갯수는 100개\n    for i in range(valid_len[0]):\n        # detection score를 iteration시 마다 높은 순으로 추출하고 SCORE_THRESHOLD보다 낮으면 loop 중단. \n        score = scores[0, i]\n\n        # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n        box = boxes[0, i]\n\n        ''' **** 주의 ******\n        box는 ymin, xmin, ymax, xmax 순서로 되어 있음. 또한 원본 좌표값으로 되어 있음. '''\n        left = box[1]\n        top = box[0] \n        right = box[3] \n        bottom = box[2] \n\n        # class id 추출하고 class 명으로 매핑\n        class_id = classes[0, i]\n        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n        print(caption)\n        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n\n    if is_print:\n        print('Detection 수행시간:',round(time.time() - start_time, 2),\"초\")\n\n    return draw_img","metadata":{"id":"FD_WA4zswphb","executionInfo":{"status":"ok","timestamp":1624912730774,"user_tz":-540,"elapsed":413,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimg_array = cv2.cvtColor(cv2.imread('/kaggle/working/data/img01.png'), cv2.COLOR_BGR2RGB)\n\ndraw_img = get_detected_img(export_model, img_array, is_print=True)\nplt.figure(figsize=(16, 16))\nplt.imshow(draw_img)","metadata":{"id":"KY3koJcGFLtm","executionInfo":{"status":"ok","timestamp":1624912747059,"user_tz":-540,"elapsed":3937,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"14f42b1e-f4a4-41ba-a255-01b3a0c76557","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg\n!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg","metadata":{"id":"SzH8vTu2eZmg","executionInfo":{"status":"ok","timestamp":1624912773820,"user_tz":-540,"elapsed":986,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"788866b3-4f58-4586-b534-cc38d3d7ba74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimg_array = cv2.cvtColor(cv2.imread('/kaggle/working/data/beatles01.jpg'), cv2.COLOR_BGR2RGB)\nprint(img_array.shape)\n\ndraw_img = get_detected_img(export_model, img_array, is_print=True)\nplt.figure(figsize=(12, 12))\nplt.imshow(draw_img)","metadata":{"id":"CJK0Ge3ueYGJ","executionInfo":{"status":"ok","timestamp":1624912806787,"user_tz":-540,"elapsed":6894,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"33e07513-93d9-46b1-adcb-90507deb8331","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### pretrained된 last checkpoint 모델의 weight를 다시 load_weight() 적용시 런타임 재시작을 적용해야 함.\n* 이를 위해 앞의 로직을 아래 셀에서 모두 일괄 정리함 ","metadata":{"id":"-phe82jMOPsV"}},{"cell_type":"code","source":"import os\nimport sys\nimport tensorflow.compat.v1 as tf\nimport numpy as np\n\nsys.path.append('/kaggle/working/automl/efficientdet')\n\nimport hparams_config\nfrom keras import anchors\nfrom model_inspect import ModelInspector\n\nclass INFER_CFG:\n    model_name = 'efficientdet-d0' # efficientdet 모델명\n    model_dir = '/kaggle/working/efficientdet-d0' # pretrained checkpoint 파일이 있는 디렉토리\n    hparams = '' # csv 형식의 k=v 쌍 또는 yaml file\n\nconfig = hparams_config.get_efficientdet_config(INFER_CFG.model_name)\nconfig.is_training_bn = False\n# config의 image_size를 원본 이미지 사이즈로 재 조정. config의 image_size에 가로x세로 형식으로 문자열 입력 \nconfig.image_size = '1920x1280'\nconfig.nms_configs.score_thresh = 0.4\nconfig.nms_configs.max_output_size = 100\nconfig.override(INFER_CFG.hparams)\n\nimport inference\nfrom keras import efficientdet_keras\n\nmodel = efficientdet_keras.EfficientDetModel(config=config)\nmodel.build((None, None, None, 3))\nprint('#### checkpoint name:', tf.train.latest_checkpoint(INFER_CFG.model_dir))\n# pretrained된 last checkpoint 모델의 weight를 다시 load_weight() 적용시 런타임 재시작을 적용해야 함. \nmodel.load_weights(tf.train.latest_checkpoint(INFER_CFG.model_dir))\nmodel.summary()\n\nclass ExportModel(tf.Module):\n\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    @tf.function\n    def f(self, imgs):\n        return self.model(imgs, training=False, post_mode='global')\n\nexport_model = ExportModel(model)","metadata":{"id":"8WP9KjEXfxoo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# p100에서 image 1920x1280일 경우 74ms, image 512x512일 경우 27ms, v100에서 image 512x512일 경우 24ms\nimport time\nimport cv2 \n\nimg = cv2.cvtColor(cv2.imread('/kaggle/working/data/img01.png'), cv2.COLOR_BGR2RGB)\nimgs= img[np.newaxis, ...]\n\nstart_time = time.time()\nboxes, scores, classes, valid_len = export_model.f(imgs)\n\nprint('elapsed time:', time.time() - start_time)","metadata":{"id":"8R7DdOaQJQca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n                    91:'hair brush'}","metadata":{"id":"JEMSBZxbiBXl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_detected_img(export_model, img_array, is_print=True):   \n    # automl efficent은 반환 bbox 좌표값이 원본 이미지 좌표값으로 되어 있으므로 별도의 scaling작업 필요 없음. \n    '''\n    height = img_array.shape[0]\n    width = img_array.shape[1]\n    '''\n    # cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n    draw_img = img_array.copy()\n\n    # bounding box의 테두리와 caption 글자색 지정\n    green_color=(0, 255, 0)\n    red_color=(0, 0, 255)\n\n    # cv2로 만들어진 numpy image array를 tensor로 변환\n    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.uint8)[tf.newaxis, ...]\n    #img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)[tf.newaxis, ...]\n\n    # efficientdet 모델을 다운로드 한 뒤 inference 수행. \n    start_time = time.time()\n    # automl efficientdet 모델은 boxes, score, classes, num_detections를 각각 Tensor로 반환. \n    boxes, scores, classes, valid_len = export_model.f(img_tensor)\n    # Tensor값을 시각화를 위해 numpy 로 변환. \n    boxes = boxes.numpy()\n    scores = scores.numpy()\n    classes = classes.numpy()\n    valid_len = valid_len.numpy()\n  \n    # detected 된 object들을 iteration 하면서 정보 추출. detect된 object의 갯수는 100개\n    for i in range(valid_len[0]):\n        # detection score를 iteration시 마다 높은 순으로 추출하고 SCORE_THRESHOLD보다 낮으면 loop 중단. \n        score = scores[0, i]\n\n        # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n        box = boxes[0, i]\n\n        ''' **** 주의 ******\n        box는 ymin, xmin, ymax, xmax 순서로 되어 있음. 또한 원본 좌표값으로 되어 있음. '''\n        left = box[1]\n        top = box[0] \n        right = box[3] \n        bottom = box[2] \n\n        # class id 추출하고 class 명으로 매핑\n        class_id = classes[0, i]\n        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n        print(caption)\n        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n\n    if is_print:\n        print('Detection 수행시간:',round(time.time() - start_time, 2),\"초\")\n\n    return draw_img","metadata":{"id":"9k32essBY59b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg\n!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg","metadata":{"id":"D8sTUSp5dgOM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nimg_array = cv2.cvtColor(cv2.imread('/kaggle/working/data/img01.png'), cv2.COLOR_BGR2RGB)\n\ndraw_img = get_detected_img(export_model, img_array, is_print=True)\nplt.figure(figsize=(16, 16))\nplt.imshow(draw_img)","metadata":{"id":"6pQMnVGzdzuF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Zgk_Em3veI4g"},"execution_count":null,"outputs":[]}]}